{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para realizar la predicción a 15 días utilizando una red de capa única de 512 neuronas con variables de entrada Bitcoin, EOS, Qtum, OmiseGo y ZCash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leandro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criptomoneda procesada: bitcoin\n",
      "Criptomoneda procesada: eos\n",
      "Criptomoneda procesada: qtum\n",
      "Criptomoneda procesada: omisego\n",
      "Criptomoneda procesada: zcash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1046 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1046/1046 [==============================] - 4s 3ms/step - loss: 0.0020 - val_loss: 0.0928\n",
      "Epoch 2/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0871\n",
      "Epoch 3/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 0.0820\n",
      "Epoch 4/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 0.0014 - val_loss: 0.0776\n",
      "Epoch 5/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0738\n",
      "Epoch 6/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0705\n",
      "Epoch 7/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0677\n",
      "Epoch 8/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0014 - val_loss: 0.0652\n",
      "Epoch 9/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0014 - val_loss: 0.0630\n",
      "Epoch 10/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0609\n",
      "Epoch 11/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0590\n",
      "Epoch 12/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0013 - val_loss: 0.0572\n",
      "Epoch 13/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 0.0013 - val_loss: 0.0555\n",
      "Epoch 14/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 0.0013 - val_loss: 0.0538\n",
      "Epoch 15/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0522\n",
      "Epoch 16/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 0.0507\n",
      "Epoch 17/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 0.0011 - val_loss: 0.0492\n",
      "Epoch 18/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0477\n",
      "Epoch 19/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0011 - val_loss: 0.0462\n",
      "Epoch 20/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0010 - val_loss: 0.0448\n",
      "Epoch 21/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 0.0435\n",
      "Epoch 22/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 9.7551e-04 - val_loss: 0.0421\n",
      "Epoch 23/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 9.4391e-04 - val_loss: 0.0408\n",
      "Epoch 24/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.1343e-04 - val_loss: 0.0395\n",
      "Epoch 25/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 8.8409e-04 - val_loss: 0.0383\n",
      "Epoch 26/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 8.5591e-04 - val_loss: 0.0371\n",
      "Epoch 27/300\n",
      "1046/1046 [==============================] - 0s 22us/step - loss: 8.2890e-04 - val_loss: 0.0360\n",
      "Epoch 28/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.0308e-04 - val_loss: 0.0348\n",
      "Epoch 29/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.7843e-04 - val_loss: 0.0337\n",
      "Epoch 30/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 7.5497e-04 - val_loss: 0.0327\n",
      "Epoch 31/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.3268e-04 - val_loss: 0.0317\n",
      "Epoch 32/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.1156e-04 - val_loss: 0.0307\n",
      "Epoch 33/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.9159e-04 - val_loss: 0.0298\n",
      "Epoch 34/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.7276e-04 - val_loss: 0.0289\n",
      "Epoch 35/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.5505e-04 - val_loss: 0.0280\n",
      "Epoch 36/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.3844e-04 - val_loss: 0.0272\n",
      "Epoch 37/300\n",
      "1046/1046 [==============================] - ETA: 0s - loss: 6.0727e-0 - 0s 35us/step - loss: 6.2291e-04 - val_loss: 0.0264\n",
      "Epoch 38/300\n",
      "1046/1046 [==============================] - 0s 22us/step - loss: 6.0843e-04 - val_loss: 0.0257\n",
      "Epoch 39/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.9498e-04 - val_loss: 0.0250\n",
      "Epoch 40/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.8252e-04 - val_loss: 0.0243\n",
      "Epoch 41/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 5.7102e-04 - val_loss: 0.0236\n",
      "Epoch 42/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 5.6046e-04 - val_loss: 0.0230\n",
      "Epoch 43/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 5.5079e-04 - val_loss: 0.0225\n",
      "Epoch 44/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 5.4198e-04 - val_loss: 0.0219\n",
      "Epoch 45/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 5.3399e-04 - val_loss: 0.0214\n",
      "Epoch 46/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 5.2679e-04 - val_loss: 0.0209\n",
      "Epoch 47/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.2033e-04 - val_loss: 0.0204\n",
      "Epoch 48/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 5.1458e-04 - val_loss: 0.0200\n",
      "Epoch 49/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.0950e-04 - val_loss: 0.0196\n",
      "Epoch 50/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.0504e-04 - val_loss: 0.0192\n",
      "Epoch 51/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 5.0118e-04 - val_loss: 0.0188\n",
      "Epoch 52/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.9787e-04 - val_loss: 0.0185\n",
      "Epoch 53/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 4.9506e-04 - val_loss: 0.0182\n",
      "Epoch 54/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 4.9274e-04 - val_loss: 0.0179\n",
      "Epoch 55/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 4.9085e-04 - val_loss: 0.0176\n",
      "Epoch 56/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8936e-04 - val_loss: 0.0173\n",
      "Epoch 57/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.8824e-04 - val_loss: 0.0171\n",
      "Epoch 58/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 4.8745e-04 - val_loss: 0.0168\n",
      "Epoch 59/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 4.8697e-04 - val_loss: 0.0166\n",
      "Epoch 60/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8676e-04 - val_loss: 0.0164\n",
      "Epoch 61/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8679e-04 - val_loss: 0.0163\n",
      "Epoch 62/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8703e-04 - val_loss: 0.0161\n",
      "Epoch 63/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8746e-04 - val_loss: 0.0159\n",
      "Epoch 64/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8805e-04 - val_loss: 0.0158\n",
      "Epoch 65/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8878e-04 - val_loss: 0.0156\n",
      "Epoch 66/300\n",
      "1046/1046 [==============================] - 0s 56us/step - loss: 4.8962e-04 - val_loss: 0.0155\n",
      "Epoch 67/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.9057e-04 - val_loss: 0.0154\n",
      "Epoch 68/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 4.9159e-04 - val_loss: 0.0153\n",
      "Epoch 69/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 4.9267e-04 - val_loss: 0.0152\n",
      "Epoch 70/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.9380e-04 - val_loss: 0.0151\n",
      "Epoch 71/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 4.9495e-04 - val_loss: 0.0150\n",
      "Epoch 72/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.9612e-04 - val_loss: 0.0149\n",
      "Epoch 73/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 4.9730e-04 - val_loss: 0.0148\n",
      "Epoch 74/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.9847e-04 - val_loss: 0.0148\n",
      "Epoch 75/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 4.9963e-04 - val_loss: 0.0147\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.0076e-04 - val_loss: 0.0146\n",
      "Epoch 77/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 5.0186e-04 - val_loss: 0.0146\n",
      "Epoch 78/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 5.0292e-04 - val_loss: 0.0145\n",
      "Epoch 79/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0393e-04 - val_loss: 0.0145\n",
      "Epoch 80/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 5.0490e-04 - val_loss: 0.0144\n",
      "Epoch 81/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0581e-04 - val_loss: 0.0144\n",
      "Epoch 82/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 5.0667e-04 - val_loss: 0.0143\n",
      "Epoch 83/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 5.0747e-04 - val_loss: 0.0143\n",
      "Epoch 84/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0821e-04 - val_loss: 0.0142\n",
      "Epoch 85/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.0889e-04 - val_loss: 0.0142\n",
      "Epoch 86/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.0951e-04 - val_loss: 0.0142\n",
      "Epoch 87/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 5.1006e-04 - val_loss: 0.0141\n",
      "Epoch 88/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 5.1054e-04 - val_loss: 0.0141\n",
      "Epoch 89/300\n",
      "1046/1046 [==============================] - 0s 16us/step - loss: 5.1096e-04 - val_loss: 0.0141\n",
      "Epoch 90/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 5.1132e-04 - val_loss: 0.0141\n",
      "Epoch 91/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.1162e-04 - val_loss: 0.0140\n",
      "Epoch 92/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 5.1185e-04 - val_loss: 0.0140\n",
      "Epoch 93/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 5.1202e-04 - val_loss: 0.0140\n",
      "Epoch 94/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.1213e-04 - val_loss: 0.0139\n",
      "Epoch 95/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.1219e-04 - val_loss: 0.0139\n",
      "Epoch 96/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 5.1218e-04 - val_loss: 0.0139\n",
      "Epoch 97/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 5.1212e-04 - val_loss: 0.0139\n",
      "Epoch 98/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 5.1201e-04 - val_loss: 0.0138\n",
      "Epoch 99/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 5.1185e-04 - val_loss: 0.0138\n",
      "Epoch 100/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 5.1163e-04 - val_loss: 0.0138\n",
      "Epoch 101/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 5.1137e-04 - val_loss: 0.0138\n",
      "Epoch 102/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 5.1106e-04 - val_loss: 0.0138\n",
      "Epoch 103/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.1070e-04 - val_loss: 0.0137\n",
      "Epoch 104/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 5.1031e-04 - val_loss: 0.0137\n",
      "Epoch 105/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 5.0987e-04 - val_loss: 0.0137\n",
      "Epoch 106/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.0939e-04 - val_loss: 0.0137\n",
      "Epoch 107/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.0887e-04 - val_loss: 0.0137\n",
      "Epoch 108/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 5.0832e-04 - val_loss: 0.0136\n",
      "Epoch 109/300\n",
      "1046/1046 [==============================] - 0s 73us/step - loss: 5.0774e-04 - val_loss: 0.0136\n",
      "Epoch 110/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 5.0712e-04 - val_loss: 0.0136\n",
      "Epoch 111/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 5.0647e-04 - val_loss: 0.0136\n",
      "Epoch 112/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0579e-04 - val_loss: 0.0136\n",
      "Epoch 113/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 5.0508e-04 - val_loss: 0.0135\n",
      "Epoch 114/300\n",
      "1046/1046 [==============================] - 0s 16us/step - loss: 5.0434e-04 - val_loss: 0.0135\n",
      "Epoch 115/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.0358e-04 - val_loss: 0.0135\n",
      "Epoch 116/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 5.0280e-04 - val_loss: 0.0135\n",
      "Epoch 117/300\n",
      "1046/1046 [==============================] - 0s 14us/step - loss: 5.0199e-04 - val_loss: 0.0135\n",
      "Epoch 118/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0116e-04 - val_loss: 0.0134\n",
      "Epoch 119/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0031e-04 - val_loss: 0.0134\n",
      "Epoch 120/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 4.9944e-04 - val_loss: 0.0134\n",
      "Epoch 121/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.9855e-04 - val_loss: 0.0134\n",
      "Epoch 122/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.9764e-04 - val_loss: 0.0134\n",
      "Epoch 123/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.9672e-04 - val_loss: 0.0134\n",
      "Epoch 124/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 4.9578e-04 - val_loss: 0.0133\n",
      "Epoch 125/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 4.9483e-04 - val_loss: 0.0133\n",
      "Epoch 126/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.9386e-04 - val_loss: 0.0133\n",
      "Epoch 127/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.9288e-04 - val_loss: 0.0133\n",
      "Epoch 128/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.9189e-04 - val_loss: 0.0133\n",
      "Epoch 129/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 4.9089e-04 - val_loss: 0.0132\n",
      "Epoch 130/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 4.8987e-04 - val_loss: 0.0132\n",
      "Epoch 131/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.8885e-04 - val_loss: 0.0132\n",
      "Epoch 132/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.8781e-04 - val_loss: 0.0132\n",
      "Epoch 133/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.8676e-04 - val_loss: 0.0132\n",
      "Epoch 134/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 4.8571e-04 - val_loss: 0.0132\n",
      "Epoch 135/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.8465e-04 - val_loss: 0.0131\n",
      "Epoch 136/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 4.8358e-04 - val_loss: 0.0131\n",
      "Epoch 137/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.8250e-04 - val_loss: 0.0131\n",
      "Epoch 138/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.8142e-04 - val_loss: 0.0131\n",
      "Epoch 139/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.8032e-04 - val_loss: 0.0131\n",
      "Epoch 140/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.7923e-04 - val_loss: 0.0130\n",
      "Epoch 141/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.7812e-04 - val_loss: 0.0130\n",
      "Epoch 142/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.7702e-04 - val_loss: 0.0130\n",
      "Epoch 143/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 4.7590e-04 - val_loss: 0.0130\n",
      "Epoch 144/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 4.7478e-04 - val_loss: 0.0130\n",
      "Epoch 145/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 4.7366e-04 - val_loss: 0.0129\n",
      "Epoch 146/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.7253e-04 - val_loss: 0.0129\n",
      "Epoch 147/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 4.7140e-04 - val_loss: 0.0129\n",
      "Epoch 148/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.7027e-04 - val_loss: 0.0129\n",
      "Epoch 149/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 4.6913e-04 - val_loss: 0.0129\n",
      "Epoch 150/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 4.6799e-04 - val_loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "1046/1046 [==============================] - 0s 56us/step - loss: 4.6684e-04 - val_loss: 0.0128\n",
      "Epoch 152/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 4.6569e-04 - val_loss: 0.0128\n",
      "Epoch 153/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 4.6454e-04 - val_loss: 0.0128\n",
      "Epoch 154/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.6339e-04 - val_loss: 0.0128\n",
      "Epoch 155/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.6223e-04 - val_loss: 0.0128\n",
      "Epoch 156/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 4.6107e-04 - val_loss: 0.0127\n",
      "Epoch 157/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.5991e-04 - val_loss: 0.0127\n",
      "Epoch 158/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.5874e-04 - val_loss: 0.0127\n",
      "Epoch 159/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 4.5758e-04 - val_loss: 0.0127\n",
      "Epoch 160/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.5641e-04 - val_loss: 0.0127\n",
      "Epoch 161/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.5524e-04 - val_loss: 0.0126\n",
      "Epoch 162/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 4.5407e-04 - val_loss: 0.0126\n",
      "Epoch 163/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 4.5290e-04 - val_loss: 0.0126\n",
      "Epoch 164/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 4.5173e-04 - val_loss: 0.0126\n",
      "Epoch 165/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 4.5055e-04 - val_loss: 0.0126\n",
      "Epoch 166/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 4.4938e-04 - val_loss: 0.0125\n",
      "Epoch 167/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.4820e-04 - val_loss: 0.0125\n",
      "Epoch 168/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.4702e-04 - val_loss: 0.0125\n",
      "Epoch 169/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 4.4584e-04 - val_loss: 0.0125\n",
      "Epoch 170/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.4466e-04 - val_loss: 0.0125\n",
      "Epoch 171/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.4348e-04 - val_loss: 0.0125\n",
      "Epoch 172/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.4229e-04 - val_loss: 0.0124\n",
      "Epoch 173/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 4.4111e-04 - val_loss: 0.0124\n",
      "Epoch 174/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 4.3993e-04 - val_loss: 0.0124\n",
      "Epoch 175/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 4.3874e-04 - val_loss: 0.0124\n",
      "Epoch 176/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.3755e-04 - val_loss: 0.0124\n",
      "Epoch 177/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 4.3637e-04 - val_loss: 0.0123\n",
      "Epoch 178/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 4.3518e-04 - val_loss: 0.0123\n",
      "Epoch 179/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.3399e-04 - val_loss: 0.0123\n",
      "Epoch 180/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 4.3280e-04 - val_loss: 0.0123\n",
      "Epoch 181/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 4.3162e-04 - val_loss: 0.0123\n",
      "Epoch 182/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.3043e-04 - val_loss: 0.0122\n",
      "Epoch 183/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2924e-04 - val_loss: 0.0122\n",
      "Epoch 184/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2805e-04 - val_loss: 0.0122\n",
      "Epoch 185/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2686e-04 - val_loss: 0.0122\n",
      "Epoch 186/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2567e-04 - val_loss: 0.0122\n",
      "Epoch 187/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2448e-04 - val_loss: 0.0121\n",
      "Epoch 188/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2328e-04 - val_loss: 0.0121\n",
      "Epoch 189/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2209e-04 - val_loss: 0.0121\n",
      "Epoch 190/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 4.2090e-04 - val_loss: 0.0121\n",
      "Epoch 191/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.1971e-04 - val_loss: 0.0121\n",
      "Epoch 192/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 4.1852e-04 - val_loss: 0.0120\n",
      "Epoch 193/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 4.1733e-04 - val_loss: 0.0120\n",
      "Epoch 194/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 4.1613e-04 - val_loss: 0.0120\n",
      "Epoch 195/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 4.1494e-04 - val_loss: 0.0120\n",
      "Epoch 196/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 4.1375e-04 - val_loss: 0.0120\n",
      "Epoch 197/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 4.1256e-04 - val_loss: 0.0119\n",
      "Epoch 198/300\n",
      "1046/1046 [==============================] - 0s 19us/step - loss: 4.1136e-04 - val_loss: 0.0119\n",
      "Epoch 199/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.1017e-04 - val_loss: 0.0119\n",
      "Epoch 200/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0898e-04 - val_loss: 0.0119\n",
      "Epoch 201/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0779e-04 - val_loss: 0.0119\n",
      "Epoch 202/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0660e-04 - val_loss: 0.0118\n",
      "Epoch 203/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0540e-04 - val_loss: 0.0118\n",
      "Epoch 204/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0421e-04 - val_loss: 0.0118\n",
      "Epoch 205/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0302e-04 - val_loss: 0.0118\n",
      "Epoch 206/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.0183e-04 - val_loss: 0.0118\n",
      "Epoch 207/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 4.0064e-04 - val_loss: 0.0117\n",
      "Epoch 208/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 3.9944e-04 - val_loss: 0.0117\n",
      "Epoch 209/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 3.9825e-04 - val_loss: 0.0117\n",
      "Epoch 210/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 3.9706e-04 - val_loss: 0.0117\n",
      "Epoch 211/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9587e-04 - val_loss: 0.0116\n",
      "Epoch 212/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9468e-04 - val_loss: 0.0116\n",
      "Epoch 213/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9349e-04 - val_loss: 0.0116\n",
      "Epoch 214/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9230e-04 - val_loss: 0.0116\n",
      "Epoch 215/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9111e-04 - val_loss: 0.0116\n",
      "Epoch 216/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.8992e-04 - val_loss: 0.0115\n",
      "Epoch 217/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.8873e-04 - val_loss: 0.0115\n",
      "Epoch 218/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.8754e-04 - val_loss: 0.0115\n",
      "Epoch 219/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.8635e-04 - val_loss: 0.0115\n",
      "Epoch 220/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.8517e-04 - val_loss: 0.0115\n",
      "Epoch 221/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.8398e-04 - val_loss: 0.0114\n",
      "Epoch 222/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 3.8279e-04 - val_loss: 0.0114\n",
      "Epoch 223/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.8160e-04 - val_loss: 0.0114\n",
      "Epoch 224/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 3.8042e-04 - val_loss: 0.0114\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.7923e-04 - val_loss: 0.0114\n",
      "Epoch 226/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.7804e-04 - val_loss: 0.0113\n",
      "Epoch 227/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 3.7686e-04 - val_loss: 0.0113\n",
      "Epoch 228/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.7567e-04 - val_loss: 0.0113\n",
      "Epoch 229/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.7449e-04 - val_loss: 0.0113\n",
      "Epoch 230/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.7330e-04 - val_loss: 0.0113\n",
      "Epoch 231/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.7212e-04 - val_loss: 0.0112\n",
      "Epoch 232/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.7093e-04 - val_loss: 0.0112\n",
      "Epoch 233/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 3.6975e-04 - val_loss: 0.0112\n",
      "Epoch 234/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 3.6857e-04 - val_loss: 0.0112\n",
      "Epoch 235/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 3.6739e-04 - val_loss: 0.0111\n",
      "Epoch 236/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 3.6621e-04 - val_loss: 0.0111\n",
      "Epoch 237/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 3.6503e-04 - val_loss: 0.0111\n",
      "Epoch 238/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.6385e-04 - val_loss: 0.0111\n",
      "Epoch 239/300\n",
      "1046/1046 [==============================] - 0s 18us/step - loss: 3.6267e-04 - val_loss: 0.0111\n",
      "Epoch 240/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.6149e-04 - val_loss: 0.0110\n",
      "Epoch 241/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.6031e-04 - val_loss: 0.0110\n",
      "Epoch 242/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.5913e-04 - val_loss: 0.0110\n",
      "Epoch 243/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.5795e-04 - val_loss: 0.0110\n",
      "Epoch 244/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.5678e-04 - val_loss: 0.0110\n",
      "Epoch 245/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 3.5560e-04 - val_loss: 0.0109\n",
      "Epoch 246/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 3.5442e-04 - val_loss: 0.0109\n",
      "Epoch 247/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 3.5325e-04 - val_loss: 0.0109\n",
      "Epoch 248/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.5207e-04 - val_loss: 0.0109\n",
      "Epoch 249/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.5090e-04 - val_loss: 0.0109\n",
      "Epoch 250/300\n",
      "1046/1046 [==============================] - 0s 26us/step - loss: 3.4973e-04 - val_loss: 0.0108\n",
      "Epoch 251/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 3.4856e-04 - val_loss: 0.0108\n",
      "Epoch 252/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.4738e-04 - val_loss: 0.0108\n",
      "Epoch 253/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.4621e-04 - val_loss: 0.0108\n",
      "Epoch 254/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.4504e-04 - val_loss: 0.0107\n",
      "Epoch 255/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.4387e-04 - val_loss: 0.0107\n",
      "Epoch 256/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.4270e-04 - val_loss: 0.0107\n",
      "Epoch 257/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.4154e-04 - val_loss: 0.0107\n",
      "Epoch 258/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 3.4037e-04 - val_loss: 0.0107\n",
      "Epoch 259/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.3920e-04 - val_loss: 0.0106\n",
      "Epoch 260/300\n",
      "1046/1046 [==============================] - 0s 26us/step - loss: 3.3804e-04 - val_loss: 0.0106\n",
      "Epoch 261/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.3687e-04 - val_loss: 0.0106\n",
      "Epoch 262/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 3.3571e-04 - val_loss: 0.0106\n",
      "Epoch 263/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.3454e-04 - val_loss: 0.0105\n",
      "Epoch 264/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.3338e-04 - val_loss: 0.0105\n",
      "Epoch 265/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.3222e-04 - val_loss: 0.0105\n",
      "Epoch 266/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.3106e-04 - val_loss: 0.0105\n",
      "Epoch 267/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.2990e-04 - val_loss: 0.0105\n",
      "Epoch 268/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.2874e-04 - val_loss: 0.0104\n",
      "Epoch 269/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.2758e-04 - val_loss: 0.0104\n",
      "Epoch 270/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.2642e-04 - val_loss: 0.0104\n",
      "Epoch 271/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.2527e-04 - val_loss: 0.0104\n",
      "Epoch 272/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.2411e-04 - val_loss: 0.0104\n",
      "Epoch 273/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 3.2296e-04 - val_loss: 0.0103\n",
      "Epoch 274/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 3.2180e-04 - val_loss: 0.0103\n",
      "Epoch 275/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.2065e-04 - val_loss: 0.0103\n",
      "Epoch 276/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.1950e-04 - val_loss: 0.0103\n",
      "Epoch 277/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.1835e-04 - val_loss: 0.0102\n",
      "Epoch 278/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.1720e-04 - val_loss: 0.0102\n",
      "Epoch 279/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 3.1605e-04 - val_loss: 0.0102\n",
      "Epoch 280/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.1490e-04 - val_loss: 0.0102\n",
      "Epoch 281/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.1375e-04 - val_loss: 0.0102\n",
      "Epoch 282/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.1260e-04 - val_loss: 0.0101\n",
      "Epoch 283/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.1146e-04 - val_loss: 0.0101\n",
      "Epoch 284/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.1031e-04 - val_loss: 0.0101\n",
      "Epoch 285/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.0917e-04 - val_loss: 0.0101\n",
      "Epoch 286/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 3.0803e-04 - val_loss: 0.0100\n",
      "Epoch 287/300\n",
      "1046/1046 [==============================] - 0s 18us/step - loss: 3.0689e-04 - val_loss: 0.0100\n",
      "Epoch 288/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 3.0574e-04 - val_loss: 0.0100\n",
      "Epoch 289/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.0460e-04 - val_loss: 0.0100\n",
      "Epoch 290/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 3.0347e-04 - val_loss: 0.0100\n",
      "Epoch 291/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.0233e-04 - val_loss: 0.0099\n",
      "Epoch 292/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.0119e-04 - val_loss: 0.0099\n",
      "Epoch 293/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.0006e-04 - val_loss: 0.0099\n",
      "Epoch 294/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 2.9892e-04 - val_loss: 0.0099\n",
      "Epoch 295/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 2.9779e-04 - val_loss: 0.0098\n",
      "Epoch 296/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 2.9666e-04 - val_loss: 0.0098\n",
      "Epoch 297/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 2.9553e-04 - val_loss: 0.0098\n",
      "Epoch 298/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 2.9440e-04 - val_loss: 0.0098\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 27us/step - loss: 2.9327e-04 - val_loss: 0.0098\n",
      "Epoch 300/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.9214e-04 - val_loss: 0.0097\n",
      "Entrenamiento f1 completo.\n",
      "[[7375.025 ]\n",
      " [7242.163 ]\n",
      " [7179.067 ]\n",
      " [6929.437 ]\n",
      " [6981.3853]\n",
      " [6885.065 ]\n",
      " [6651.6367]\n",
      " [6116.3633]\n",
      " [6361.5225]\n",
      " [5970.2837]\n",
      " [5938.402 ]\n",
      " [5925.9067]\n",
      " [5743.975 ]\n",
      " [5683.0293]\n",
      " [5751.16  ]\n",
      " [5763.392 ]\n",
      " [6231.83  ]\n",
      " [5993.979 ]\n",
      " [6094.186 ]\n",
      " [5785.0967]\n",
      " [5939.1475]\n",
      " [5782.806 ]\n",
      " [5935.7383]\n",
      " [6107.1313]\n",
      " [6112.9194]\n",
      " [6056.4683]\n",
      " [6298.6523]\n",
      " [6565.461 ]\n",
      " [6565.5527]\n",
      " [6491.354 ]]\n",
      "30\n",
      "Simulación f1 completa.\n",
      "Train on 1045 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1045/1045 [==============================] - 1s 919us/step - loss: 0.0070 - val_loss: 0.2505\n",
      "Epoch 2/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 0.0065 - val_loss: 0.2433\n",
      "Epoch 3/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 0.0061 - val_loss: 0.2363\n",
      "Epoch 4/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0057 - val_loss: 0.2297\n",
      "Epoch 5/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0055 - val_loss: 0.2235\n",
      "Epoch 6/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.2178\n",
      "Epoch 7/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0052 - val_loss: 0.2125\n",
      "Epoch 8/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0051 - val_loss: 0.2076\n",
      "Epoch 9/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.2030\n",
      "Epoch 10/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1987\n",
      "Epoch 11/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1947\n",
      "Epoch 12/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0049 - val_loss: 0.1909\n",
      "Epoch 13/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1873\n",
      "Epoch 14/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1840\n",
      "Epoch 15/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1808\n",
      "Epoch 16/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1778\n",
      "Epoch 17/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0050 - val_loss: 0.1749\n",
      "Epoch 18/300\n",
      "1045/1045 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.1721\n",
      "Epoch 19/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1695\n",
      "Epoch 20/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0050 - val_loss: 0.1669\n",
      "Epoch 21/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 0.0050 - val_loss: 0.1645\n",
      "Epoch 22/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0050 - val_loss: 0.1621\n",
      "Epoch 23/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0050 - val_loss: 0.1598\n",
      "Epoch 24/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1575\n",
      "Epoch 25/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1553\n",
      "Epoch 26/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1532\n",
      "Epoch 27/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1510\n",
      "Epoch 28/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1490\n",
      "Epoch 29/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1469\n",
      "Epoch 30/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0050 - val_loss: 0.1448\n",
      "Epoch 31/300\n",
      "1045/1045 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.1428\n",
      "Epoch 32/300\n",
      "1045/1045 [==============================] - 0s 51us/step - loss: 0.0050 - val_loss: 0.1408\n",
      "Epoch 33/300\n",
      "1045/1045 [==============================] - 0s 21us/step - loss: 0.0050 - val_loss: 0.1388\n",
      "Epoch 34/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1368\n",
      "Epoch 35/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 0.0049 - val_loss: 0.1348\n",
      "Epoch 36/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1328\n",
      "Epoch 37/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1309\n",
      "Epoch 38/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.1289\n",
      "Epoch 39/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.1269\n",
      "Epoch 40/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.1249\n",
      "Epoch 41/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0047 - val_loss: 0.1229\n",
      "Epoch 42/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0047 - val_loss: 0.1209\n",
      "Epoch 43/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0047 - val_loss: 0.1189\n",
      "Epoch 44/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 0.0046 - val_loss: 0.1169\n",
      "Epoch 45/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 0.0046 - val_loss: 0.1149\n",
      "Epoch 46/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0046 - val_loss: 0.1129\n",
      "Epoch 47/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0045 - val_loss: 0.1109\n",
      "Epoch 48/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 0.0045 - val_loss: 0.1089\n",
      "Epoch 49/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0044 - val_loss: 0.1069\n",
      "Epoch 50/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0044 - val_loss: 0.1049\n",
      "Epoch 51/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0044 - val_loss: 0.1028\n",
      "Epoch 52/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 0.0043 - val_loss: 0.1008\n",
      "Epoch 53/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0043 - val_loss: 0.0988\n",
      "Epoch 54/300\n",
      "1045/1045 [==============================] - 0s 66us/step - loss: 0.0042 - val_loss: 0.0967\n",
      "Epoch 55/300\n",
      "1045/1045 [==============================] - 0s 77us/step - loss: 0.0042 - val_loss: 0.0947\n",
      "Epoch 56/300\n",
      "1045/1045 [==============================] - 0s 65us/step - loss: 0.0041 - val_loss: 0.0927\n",
      "Epoch 57/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 0.0041 - val_loss: 0.0907\n",
      "Epoch 58/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0040 - val_loss: 0.0886\n",
      "Epoch 59/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0040 - val_loss: 0.0866\n",
      "Epoch 60/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0039 - val_loss: 0.0846\n",
      "Epoch 61/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0039 - val_loss: 0.0826\n",
      "Epoch 62/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0806\n",
      "Epoch 63/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 0.0038 - val_loss: 0.0786\n",
      "Epoch 64/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0037 - val_loss: 0.0767\n",
      "Epoch 65/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0747\n",
      "Epoch 66/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0036 - val_loss: 0.0727\n",
      "Epoch 67/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0036 - val_loss: 0.0708\n",
      "Epoch 68/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0035 - val_loss: 0.0689\n",
      "Epoch 69/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0035 - val_loss: 0.0670\n",
      "Epoch 70/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0651\n",
      "Epoch 71/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0632\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0614\n",
      "Epoch 73/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0596\n",
      "Epoch 74/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0578\n",
      "Epoch 75/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0032 - val_loss: 0.0561\n",
      "Epoch 76/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0031 - val_loss: 0.0544\n",
      "Epoch 77/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0030 - val_loss: 0.0527\n",
      "Epoch 78/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0030 - val_loss: 0.0510\n",
      "Epoch 79/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0494\n",
      "Epoch 80/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0029 - val_loss: 0.0478\n",
      "Epoch 81/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0028 - val_loss: 0.0463\n",
      "Epoch 82/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0028 - val_loss: 0.0447\n",
      "Epoch 83/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0027 - val_loss: 0.0433\n",
      "Epoch 84/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0027 - val_loss: 0.0418\n",
      "Epoch 85/300\n",
      "1045/1045 [==============================] - 0s 24us/step - loss: 0.0026 - val_loss: 0.0404\n",
      "Epoch 86/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0026 - val_loss: 0.0391\n",
      "Epoch 87/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 0.0025 - val_loss: 0.0377\n",
      "Epoch 88/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 0.0025 - val_loss: 0.0365\n",
      "Epoch 89/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0352\n",
      "Epoch 90/300\n",
      "1045/1045 [==============================] - 0s 24us/step - loss: 0.0024 - val_loss: 0.0340\n",
      "Epoch 91/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0329\n",
      "Epoch 92/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0318\n",
      "Epoch 93/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0308\n",
      "Epoch 94/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0298\n",
      "Epoch 95/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0288\n",
      "Epoch 96/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 97/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 0.0020 - val_loss: 0.0271\n",
      "Epoch 98/300\n",
      "1045/1045 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0263\n",
      "Epoch 99/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0255\n",
      "Epoch 100/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.0248\n",
      "Epoch 101/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0242\n",
      "Epoch 102/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0236\n",
      "Epoch 103/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0230\n",
      "Epoch 104/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0225\n",
      "Epoch 105/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0220\n",
      "Epoch 106/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.0216\n",
      "Epoch 107/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 0.0016 - val_loss: 0.0212\n",
      "Epoch 108/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0016 - val_loss: 0.0209\n",
      "Epoch 109/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0016 - val_loss: 0.0206\n",
      "Epoch 110/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0204\n",
      "Epoch 111/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0202\n",
      "Epoch 112/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0200\n",
      "Epoch 113/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0199\n",
      "Epoch 114/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 0.0014 - val_loss: 0.0198\n",
      "Epoch 115/300\n",
      "1045/1045 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 0.0198\n",
      "Epoch 116/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0198\n",
      "Epoch 117/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0198\n",
      "Epoch 118/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 0.0013 - val_loss: 0.0198\n",
      "Epoch 119/300\n",
      "1045/1045 [==============================] - 0s 17us/step - loss: 0.0013 - val_loss: 0.0199\n",
      "Epoch 120/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0200\n",
      "Epoch 121/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0202\n",
      "Epoch 122/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0204\n",
      "Epoch 123/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0206\n",
      "Epoch 124/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0208\n",
      "Epoch 125/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0210\n",
      "Epoch 126/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0213\n",
      "Epoch 00126: early stopping\n",
      "Entrenamiento f2 completo.\n",
      "[[6738.03  ]\n",
      " [6573.0234]\n",
      " [6339.7046]\n",
      " [6335.262 ]\n",
      " [6144.9126]\n",
      " [6226.77  ]\n",
      " [6157.2637]\n",
      " [5858.9897]\n",
      " [5184.3906]\n",
      " [5451.8105]\n",
      " [5012.89  ]\n",
      " [4861.127 ]\n",
      " [4821.2725]\n",
      " [4485.861 ]\n",
      " [4417.911 ]\n",
      " [4466.511 ]\n",
      " [4470.827 ]\n",
      " [5150.0625]\n",
      " [4823.4395]\n",
      " [4941.04  ]\n",
      " [4511.2183]\n",
      " [4654.588 ]\n",
      " [4466.0415]\n",
      " [4613.563 ]\n",
      " [4783.074 ]\n",
      " [4757.1177]\n",
      " [4691.555 ]\n",
      " [5023.06  ]\n",
      " [5363.5996]\n",
      " [5415.1943]]\n",
      "30\n",
      "Simulación f2 completa.\n",
      "Train on 1044 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: 0.0044 - val_loss: 0.2122\n",
      "Epoch 2/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0039 - val_loss: 0.1997\n",
      "Epoch 3/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0035 - val_loss: 0.1880\n",
      "Epoch 4/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 0.0032 - val_loss: 0.1775\n",
      "Epoch 5/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0030 - val_loss: 0.1682\n",
      "Epoch 6/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0030 - val_loss: 0.1599\n",
      "Epoch 7/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0029 - val_loss: 0.1525\n",
      "Epoch 8/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 0.0029 - val_loss: 0.1458\n",
      "Epoch 9/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0029 - val_loss: 0.1399\n",
      "Epoch 10/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.1345\n",
      "Epoch 11/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.1295\n",
      "Epoch 12/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.1250\n",
      "Epoch 13/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0029 - val_loss: 0.1207\n",
      "Epoch 14/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0028 - val_loss: 0.1168\n",
      "Epoch 15/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 0.0028 - val_loss: 0.1131\n",
      "Epoch 16/300\n",
      "1044/1044 [==============================] - 0s 18us/step - loss: 0.0028 - val_loss: 0.1095\n",
      "Epoch 17/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0027 - val_loss: 0.1062\n",
      "Epoch 18/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0027 - val_loss: 0.1030\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 51us/step - loss: 0.0026 - val_loss: 0.0999\n",
      "Epoch 20/300\n",
      "1044/1044 [==============================] - 0s 57us/step - loss: 0.0026 - val_loss: 0.0970\n",
      "Epoch 21/300\n",
      "1044/1044 [==============================] - 0s 58us/step - loss: 0.0026 - val_loss: 0.0941\n",
      "Epoch 22/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0025 - val_loss: 0.0914\n",
      "Epoch 23/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0025 - val_loss: 0.0887\n",
      "Epoch 24/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0861\n",
      "Epoch 25/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 0.0024 - val_loss: 0.0836\n",
      "Epoch 26/300\n",
      "1044/1044 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0812\n",
      "Epoch 27/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0788\n",
      "Epoch 28/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0765\n",
      "Epoch 29/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0743\n",
      "Epoch 30/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0721\n",
      "Epoch 31/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0700\n",
      "Epoch 32/300\n",
      "1044/1044 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0680\n",
      "Epoch 33/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0660\n",
      "Epoch 34/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0640\n",
      "Epoch 35/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0621\n",
      "Epoch 36/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 0.0018 - val_loss: 0.0603\n",
      "Epoch 37/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0018 - val_loss: 0.0585\n",
      "Epoch 38/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.0568\n",
      "Epoch 39/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0551\n",
      "Epoch 40/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0017 - val_loss: 0.0535\n",
      "Epoch 41/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0016 - val_loss: 0.0519\n",
      "Epoch 42/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 0.0016 - val_loss: 0.0504\n",
      "Epoch 43/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0489\n",
      "Epoch 44/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0474\n",
      "Epoch 45/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0460\n",
      "Epoch 46/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0447\n",
      "Epoch 47/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0434\n",
      "Epoch 48/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0421\n",
      "Epoch 49/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0014 - val_loss: 0.0409\n",
      "Epoch 50/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 0.0397\n",
      "Epoch 51/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 0.0013 - val_loss: 0.0386\n",
      "Epoch 52/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0013 - val_loss: 0.0375\n",
      "Epoch 53/300\n",
      "1044/1044 [==============================] - 0s 51us/step - loss: 0.0013 - val_loss: 0.0365\n",
      "Epoch 54/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0013 - val_loss: 0.0354\n",
      "Epoch 55/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 0.0012 - val_loss: 0.0345\n",
      "Epoch 56/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0012 - val_loss: 0.0335\n",
      "Epoch 57/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0326\n",
      "Epoch 58/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0318\n",
      "Epoch 59/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0310\n",
      "Epoch 60/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0302\n",
      "Epoch 61/300\n",
      "1044/1044 [==============================] - 0s 55us/step - loss: 0.0011 - val_loss: 0.0294\n",
      "Epoch 62/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0011 - val_loss: 0.0287\n",
      "Epoch 63/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0011 - val_loss: 0.0280\n",
      "Epoch 64/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0011 - val_loss: 0.0274\n",
      "Epoch 65/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0010 - val_loss: 0.0267\n",
      "Epoch 66/300\n",
      "1044/1044 [==============================] - 0s 18us/step - loss: 0.0010 - val_loss: 0.0261\n",
      "Epoch 67/300\n",
      "1044/1044 [==============================] - 0s 15us/step - loss: 0.0010 - val_loss: 0.0256\n",
      "Epoch 68/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0010 - val_loss: 0.0250\n",
      "Epoch 69/300\n",
      "1044/1044 [==============================] - 0s 21us/step - loss: 9.9223e-04 - val_loss: 0.0245\n",
      "Epoch 70/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.8117e-04 - val_loss: 0.0241\n",
      "Epoch 71/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.7076e-04 - val_loss: 0.0236\n",
      "Epoch 72/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 9.6099e-04 - val_loss: 0.0232\n",
      "Epoch 73/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.5183e-04 - val_loss: 0.0228\n",
      "Epoch 74/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.4327e-04 - val_loss: 0.0224\n",
      "Epoch 75/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.3529e-04 - val_loss: 0.0221\n",
      "Epoch 76/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 9.2786e-04 - val_loss: 0.0218\n",
      "Epoch 77/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 9.2096e-04 - val_loss: 0.0215\n",
      "Epoch 78/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 9.1457e-04 - val_loss: 0.0212\n",
      "Epoch 79/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.0867e-04 - val_loss: 0.0209\n",
      "Epoch 80/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.0324e-04 - val_loss: 0.0207\n",
      "Epoch 81/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.9825e-04 - val_loss: 0.0205\n",
      "Epoch 82/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.9369e-04 - val_loss: 0.0203\n",
      "Epoch 83/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.8953e-04 - val_loss: 0.0201\n",
      "Epoch 84/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.8576e-04 - val_loss: 0.0199\n",
      "Epoch 85/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.8235e-04 - val_loss: 0.0197\n",
      "Epoch 86/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.7929e-04 - val_loss: 0.0196\n",
      "Epoch 87/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.7655e-04 - val_loss: 0.0195\n",
      "Epoch 88/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.7411e-04 - val_loss: 0.0194\n",
      "Epoch 89/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 8.7196e-04 - val_loss: 0.0193\n",
      "Epoch 90/300\n",
      "1044/1044 [==============================] - 0s 19us/step - loss: 8.7007e-04 - val_loss: 0.0192\n",
      "Epoch 91/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6843e-04 - val_loss: 0.0191\n",
      "Epoch 92/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 8.6703e-04 - val_loss: 0.0190\n",
      "Epoch 93/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.6584e-04 - val_loss: 0.0190\n",
      "Epoch 94/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 8.6485e-04 - val_loss: 0.0189\n",
      "Epoch 95/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 8.6403e-04 - val_loss: 0.0189\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 41us/step - loss: 8.6339e-04 - val_loss: 0.0189\n",
      "Epoch 97/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 8.6290e-04 - val_loss: 0.0188\n",
      "Epoch 98/300\n",
      "1044/1044 [==============================] - 0s 29us/step - loss: 8.6254e-04 - val_loss: 0.0188\n",
      "Epoch 99/300\n",
      "1044/1044 [==============================] - 0s 19us/step - loss: 8.6231e-04 - val_loss: 0.0188\n",
      "Epoch 100/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6219e-04 - val_loss: 0.0188\n",
      "Epoch 101/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 8.6217e-04 - val_loss: 0.0188\n",
      "Epoch 102/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6223e-04 - val_loss: 0.0188\n",
      "Epoch 103/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6237e-04 - val_loss: 0.0188\n",
      "Epoch 104/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 8.6258e-04 - val_loss: 0.0189\n",
      "Epoch 105/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 8.6284e-04 - val_loss: 0.0189\n",
      "Epoch 106/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6315e-04 - val_loss: 0.0189\n",
      "Epoch 107/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6349e-04 - val_loss: 0.0189\n",
      "Epoch 108/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6386e-04 - val_loss: 0.0190\n",
      "Epoch 109/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6425e-04 - val_loss: 0.0190\n",
      "Epoch 110/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6466e-04 - val_loss: 0.0190\n",
      "Epoch 00110: early stopping\n",
      "Entrenamiento f3 completo.\n",
      "[[7049.4966]\n",
      " [6693.3003]\n",
      " [6533.8022]\n",
      " [6325.1616]\n",
      " [6293.151 ]\n",
      " [6099.699 ]\n",
      " [6172.6943]\n",
      " [6084.903 ]\n",
      " [5829.7993]\n",
      " [5249.041 ]\n",
      " [5521.1113]\n",
      " [5108.0376]\n",
      " [5005.1606]\n",
      " [4967.965 ]\n",
      " [4681.3315]\n",
      " [4602.102 ]\n",
      " [4655.451 ]\n",
      " [4684.5703]\n",
      " [5258.953 ]\n",
      " [4972.4214]\n",
      " [5070.106 ]\n",
      " [4688.745 ]\n",
      " [4834.534 ]\n",
      " [4654.523 ]\n",
      " [4795.5625]\n",
      " [4973.4175]\n",
      " [4949.7896]\n",
      " [4893.6865]\n",
      " [5188.0664]\n",
      " [5476.4897]]\n",
      "30\n",
      "Simulación f3 completa.\n",
      "            Close bitcoin           f1           f2           f3\n",
      "Date                                                            \n",
      "2015-01-01         314.25          NaN          NaN          NaN\n",
      "2015-01-02         315.03          NaN          NaN          NaN\n",
      "2015-01-03         281.08          NaN          NaN          NaN\n",
      "2015-01-04         264.20          NaN          NaN          NaN\n",
      "2015-01-05         274.47          NaN          NaN          NaN\n",
      "2015-01-06         286.19          NaN          NaN          NaN\n",
      "2015-01-07         294.34          NaN          NaN          NaN\n",
      "2015-01-08         283.35          NaN          NaN          NaN\n",
      "2015-01-09         290.41          NaN          NaN          NaN\n",
      "2015-01-10         274.80          NaN          NaN          NaN\n",
      "2015-01-11         265.66          NaN          NaN          NaN\n",
      "2015-01-12         267.80          NaN          NaN          NaN\n",
      "2015-01-13         225.86          NaN          NaN          NaN\n",
      "2015-01-14         178.10          NaN          NaN          NaN\n",
      "2015-01-15         209.84          NaN          NaN          NaN\n",
      "2015-01-16         208.10          NaN          NaN          NaN\n",
      "2015-01-17         199.26          NaN          NaN          NaN\n",
      "2015-01-18         210.34          NaN          NaN          NaN\n",
      "2015-01-19         214.86          NaN          NaN          NaN\n",
      "2015-01-20         211.32          NaN          NaN          NaN\n",
      "2015-01-21         226.90          NaN          NaN          NaN\n",
      "2015-01-22         233.41          NaN          NaN          NaN\n",
      "2015-01-23         232.88          NaN          NaN          NaN\n",
      "2015-01-24         247.85          NaN          NaN          NaN\n",
      "2015-01-25         253.72          NaN          NaN          NaN\n",
      "2015-01-26         273.47          NaN          NaN          NaN\n",
      "2015-01-27         263.48          NaN          NaN          NaN\n",
      "2015-01-28         233.91          NaN          NaN          NaN\n",
      "2015-01-29         233.51          NaN          NaN          NaN\n",
      "2015-01-30         226.43          NaN          NaN          NaN\n",
      "...                   ...          ...          ...          ...\n",
      "2018-08-02        7567.15  7375.024902  6738.029785  7049.496582\n",
      "2018-08-03        7434.39  7242.163086  6573.023438  6693.300293\n",
      "2018-08-04        7032.85  7179.066895  6339.704590  6533.802246\n",
      "2018-08-05        7068.48  6929.437012  6335.262207  6325.161621\n",
      "2018-08-06        6951.80  6981.385254  6144.912598  6293.150879\n",
      "2018-08-07        6753.12  6885.064941  6226.770020  6099.699219\n",
      "2018-08-08        6305.80  6651.636719  6157.263672  6172.694336\n",
      "2018-08-09        6568.23  6116.363281  5858.989746  6084.902832\n",
      "2018-08-10        6184.71  6361.522461  5184.390625  5829.799316\n",
      "2018-08-11        6295.73  5970.283691  5451.810547  5249.041016\n",
      "2018-08-12        6322.69  5938.401855  5012.890137  5521.111328\n",
      "2018-08-13        6297.57  5925.906738  4861.126953  5108.037598\n",
      "2018-08-14        6199.71  5743.975098  4821.272461  5005.160645\n",
      "2018-08-15        6308.52  5683.029297  4485.860840  4967.964844\n",
      "2018-08-16        6334.73  5751.160156  4417.911133  4681.331543\n",
      "2018-08-17        6580.63  5763.392090  4466.511230  4602.102051\n",
      "2018-08-18        6423.76  6231.830078  4470.827148  4655.451172\n",
      "2018-08-19        6506.07  5993.979004  5150.062500  4684.570312\n",
      "2018-08-20        6308.53  6094.186035  4823.439453  5258.953125\n",
      "2018-08-21        6488.76  5785.096680  4941.040039  4972.421387\n",
      "2018-08-22        6376.71  5939.147461  4511.218262  5070.105957\n",
      "2018-08-23        6534.88  5782.806152  4654.587891  4688.745117\n",
      "2018-08-24        6719.96  5935.738281  4466.041504  4834.534180\n",
      "2018-08-25        6763.19  6107.131348  4613.562988  4654.522949\n",
      "2018-08-26        6707.26  6112.919434  4783.074219  4795.562500\n",
      "2018-08-27        6884.64  6056.468262  4757.117676  4973.417480\n",
      "2018-08-28        7096.28  6298.652344  4691.555176  4949.789551\n",
      "2018-08-29        7047.16  6565.460938  5023.060059  4893.686523\n",
      "2018-08-30        6978.23  6565.552734  5363.599609  5188.066406\n",
      "2018-08-31        7037.58  6491.354004  5415.194336  5476.489746\n",
      "\n",
      "[1339 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leandro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\leandro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\leandro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs guardados: script/bitcoin/post/Predicciones entrenamiento rmses.csv\n",
      "Epochs guardados: script/bitcoin/post/Predicciones entrenamiento rmses.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criptomoneda procesada: ethereum\n",
      "Criptomoneda procesada: eos\n",
      "Criptomoneda procesada: qtum\n",
      "Criptomoneda procesada: omisego\n",
      "Criptomoneda procesada: zcash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1046 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1046/1046 [==============================] - 1s 1ms/step - loss: 0.0093 - val_loss: 0.3896\n",
      "Epoch 2/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0088 - val_loss: 0.3783\n",
      "Epoch 3/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0083 - val_loss: 0.3673\n",
      "Epoch 4/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 0.0079 - val_loss: 0.3570\n",
      "Epoch 5/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 0.0076 - val_loss: 0.3476\n",
      "Epoch 6/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 0.0074 - val_loss: 0.3389\n",
      "Epoch 7/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0072 - val_loss: 0.3309\n",
      "Epoch 8/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 0.0071 - val_loss: 0.3235\n",
      "Epoch 9/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0070 - val_loss: 0.3167\n",
      "Epoch 10/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 0.0069 - val_loss: 0.3104\n",
      "Epoch 11/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0069 - val_loss: 0.3045\n",
      "Epoch 12/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0068 - val_loss: 0.2990\n",
      "Epoch 13/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0068 - val_loss: 0.2938\n",
      "Epoch 14/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 0.0067 - val_loss: 0.2890\n",
      "Epoch 15/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0067 - val_loss: 0.2844\n",
      "Epoch 16/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0067 - val_loss: 0.2800\n",
      "Epoch 17/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0067 - val_loss: 0.2759\n",
      "Epoch 18/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 0.0066 - val_loss: 0.2719\n",
      "Epoch 19/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0066 - val_loss: 0.2681\n",
      "Epoch 20/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0066 - val_loss: 0.2644\n",
      "Epoch 21/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0065 - val_loss: 0.2609\n",
      "Epoch 22/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0065 - val_loss: 0.2574\n",
      "Epoch 23/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0065 - val_loss: 0.2541\n",
      "Epoch 24/300\n",
      "1046/1046 [==============================] - 0s 16us/step - loss: 0.0064 - val_loss: 0.2508\n",
      "Epoch 25/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0064 - val_loss: 0.2476\n",
      "Epoch 26/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 0.0064 - val_loss: 0.2444\n",
      "Epoch 27/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0063 - val_loss: 0.2414\n",
      "Epoch 28/300\n",
      "1046/1046 [==============================] - 0s 17us/step - loss: 0.0063 - val_loss: 0.2383\n",
      "Epoch 29/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 0.0062 - val_loss: 0.2353\n",
      "Epoch 30/300\n",
      "1046/1046 [==============================] - 0s 28us/step - loss: 0.0062 - val_loss: 0.2323\n",
      "Epoch 31/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0061 - val_loss: 0.2294\n",
      "Epoch 32/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0061 - val_loss: 0.2264\n",
      "Epoch 33/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0060 - val_loss: 0.2235\n",
      "Epoch 34/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 0.0060 - val_loss: 0.2206\n",
      "Epoch 35/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0059 - val_loss: 0.2177\n",
      "Epoch 36/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 0.0059 - val_loss: 0.2148\n",
      "Epoch 37/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0058 - val_loss: 0.2119\n",
      "Epoch 38/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0058 - val_loss: 0.2090\n",
      "Epoch 39/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0057 - val_loss: 0.2061\n",
      "Epoch 40/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 0.0057 - val_loss: 0.2032\n",
      "Epoch 41/300\n",
      "1046/1046 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 0.2003\n",
      "Epoch 42/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0055 - val_loss: 0.1974\n",
      "Epoch 43/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0055 - val_loss: 0.1945\n",
      "Epoch 44/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0054 - val_loss: 0.1916\n",
      "Epoch 45/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0054 - val_loss: 0.1887\n",
      "Epoch 46/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.1857\n",
      "Epoch 47/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0052 - val_loss: 0.1828\n",
      "Epoch 48/300\n",
      "1046/1046 [==============================] - 0s 16us/step - loss: 0.0052 - val_loss: 0.1798\n",
      "Epoch 49/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0051 - val_loss: 0.1769\n",
      "Epoch 50/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0050 - val_loss: 0.1739\n",
      "Epoch 51/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1709\n",
      "Epoch 52/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1679\n",
      "Epoch 53/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1649\n",
      "Epoch 54/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0048 - val_loss: 0.1619\n",
      "Epoch 55/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0047 - val_loss: 0.1589\n",
      "Epoch 56/300\n",
      "1046/1046 [==============================] - ETA: 0s - loss: 0.002 - 0s 39us/step - loss: 0.0047 - val_loss: 0.1559\n",
      "Epoch 57/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0046 - val_loss: 0.1529\n",
      "Epoch 58/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.1499\n",
      "Epoch 59/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 0.0044 - val_loss: 0.1468\n",
      "Epoch 60/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0044 - val_loss: 0.1438\n",
      "Epoch 61/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.1408\n",
      "Epoch 62/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0042 - val_loss: 0.1378\n",
      "Epoch 63/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0042 - val_loss: 0.1348\n",
      "Epoch 64/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.1318\n",
      "Epoch 65/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.1288\n",
      "Epoch 66/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 0.0040 - val_loss: 0.1258\n",
      "Epoch 67/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 0.0039 - val_loss: 0.1228\n",
      "Epoch 68/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0038 - val_loss: 0.1199\n",
      "Epoch 69/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.1169\n",
      "Epoch 70/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 0.0037 - val_loss: 0.1140\n",
      "Epoch 71/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 0.0036 - val_loss: 0.1111\n",
      "Epoch 72/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.1083\n",
      "Epoch 73/300\n",
      "1046/1046 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.1054\n",
      "Epoch 74/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.1026\n",
      "Epoch 75/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 0.0033 - val_loss: 0.0998\n",
      "Epoch 76/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0032 - val_loss: 0.0970\n",
      "Epoch 77/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0032 - val_loss: 0.0943\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0031 - val_loss: 0.0916\n",
      "Epoch 79/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0030 - val_loss: 0.0889\n",
      "Epoch 80/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0863\n",
      "Epoch 81/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.0837\n",
      "Epoch 82/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0812\n",
      "Epoch 83/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0787\n",
      "Epoch 84/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0027 - val_loss: 0.0762\n",
      "Epoch 85/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0026 - val_loss: 0.0738\n",
      "Epoch 86/300\n",
      "1046/1046 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0714\n",
      "Epoch 87/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0025 - val_loss: 0.0691\n",
      "Epoch 88/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0024 - val_loss: 0.0669\n",
      "Epoch 89/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0646\n",
      "Epoch 90/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0625\n",
      "Epoch 91/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0023 - val_loss: 0.0604\n",
      "Epoch 92/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0583\n",
      "Epoch 93/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0563\n",
      "Epoch 94/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0544\n",
      "Epoch 95/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0020 - val_loss: 0.0525\n",
      "Epoch 96/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0507\n",
      "Epoch 97/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0489\n",
      "Epoch 98/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0472\n",
      "Epoch 99/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0456\n",
      "Epoch 100/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0440\n",
      "Epoch 101/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0424\n",
      "Epoch 102/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0409\n",
      "Epoch 103/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0395\n",
      "Epoch 104/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0016 - val_loss: 0.0381\n",
      "Epoch 105/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0367\n",
      "Epoch 106/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0354\n",
      "Epoch 107/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0342\n",
      "Epoch 108/300\n",
      "1046/1046 [==============================] - 0s 57us/step - loss: 0.0015 - val_loss: 0.0330\n",
      "Epoch 109/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0014 - val_loss: 0.0319\n",
      "Epoch 110/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0014 - val_loss: 0.0308\n",
      "Epoch 111/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 0.0014 - val_loss: 0.0297\n",
      "Epoch 112/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0287\n",
      "Epoch 113/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 0.0013 - val_loss: 0.0278\n",
      "Epoch 114/300\n",
      "1046/1046 [==============================] - 0s 25us/step - loss: 0.0013 - val_loss: 0.0269\n",
      "Epoch 115/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0260\n",
      "Epoch 116/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0252\n",
      "Epoch 117/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0244\n",
      "Epoch 118/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0012 - val_loss: 0.0236\n",
      "Epoch 119/300\n",
      "1046/1046 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 0.0229\n",
      "Epoch 120/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0222\n",
      "Epoch 121/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0216\n",
      "Epoch 122/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0210\n",
      "Epoch 123/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0204\n",
      "Epoch 124/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 0.0011 - val_loss: 0.0199\n",
      "Epoch 125/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0194\n",
      "Epoch 126/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0189\n",
      "Epoch 127/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0184\n",
      "Epoch 128/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0180\n",
      "Epoch 129/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0176\n",
      "Epoch 130/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0010 - val_loss: 0.0172\n",
      "Epoch 131/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0010 - val_loss: 0.0168\n",
      "Epoch 132/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 0.0010 - val_loss: 0.0165\n",
      "Epoch 133/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 0.0010 - val_loss: 0.0162\n",
      "Epoch 134/300\n",
      "1046/1046 [==============================] - 0s 19us/step - loss: 0.0010 - val_loss: 0.0159\n",
      "Epoch 135/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.9749e-04 - val_loss: 0.0156\n",
      "Epoch 136/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.9025e-04 - val_loss: 0.0153\n",
      "Epoch 137/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.8338e-04 - val_loss: 0.0151\n",
      "Epoch 138/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.7685e-04 - val_loss: 0.0148\n",
      "Epoch 139/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 9.7064e-04 - val_loss: 0.0146\n",
      "Epoch 140/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.6471e-04 - val_loss: 0.0144\n",
      "Epoch 141/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 9.5905e-04 - val_loss: 0.0142\n",
      "Epoch 142/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.5363e-04 - val_loss: 0.0140\n",
      "Epoch 143/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 9.4843e-04 - val_loss: 0.0139\n",
      "Epoch 144/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 9.4343e-04 - val_loss: 0.0137\n",
      "Epoch 145/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.3861e-04 - val_loss: 0.0135\n",
      "Epoch 146/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.3396e-04 - val_loss: 0.0134\n",
      "Epoch 147/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 9.2946e-04 - val_loss: 0.0133\n",
      "Epoch 148/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 9.2509e-04 - val_loss: 0.0132\n",
      "Epoch 149/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 9.2085e-04 - val_loss: 0.0131\n",
      "Epoch 150/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 9.1672e-04 - val_loss: 0.0129\n",
      "Epoch 151/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.1269e-04 - val_loss: 0.0128\n",
      "Epoch 152/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 9.0876e-04 - val_loss: 0.0128\n",
      "Epoch 153/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 9.0490e-04 - val_loss: 0.0127\n",
      "Epoch 154/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 9.0112e-04 - val_loss: 0.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 8.9741e-04 - val_loss: 0.0125\n",
      "Epoch 156/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.9376e-04 - val_loss: 0.0125\n",
      "Epoch 157/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.9017e-04 - val_loss: 0.0124\n",
      "Epoch 158/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.8662e-04 - val_loss: 0.0123\n",
      "Epoch 159/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 8.8312e-04 - val_loss: 0.0123\n",
      "Epoch 160/300\n",
      "1046/1046 [==============================] - ETA: 0s - loss: 9.8818e-0 - 0s 49us/step - loss: 8.7966e-04 - val_loss: 0.0122\n",
      "Epoch 161/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 8.7623e-04 - val_loss: 0.0122\n",
      "Epoch 162/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 8.7284e-04 - val_loss: 0.0122\n",
      "Epoch 163/300\n",
      "1046/1046 [==============================] - 0s 56us/step - loss: 8.6949e-04 - val_loss: 0.0121\n",
      "Epoch 164/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 8.6615e-04 - val_loss: 0.0121\n",
      "Epoch 165/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 8.6285e-04 - val_loss: 0.0120\n",
      "Epoch 166/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.5957e-04 - val_loss: 0.0120\n",
      "Epoch 167/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 8.5631e-04 - val_loss: 0.0120\n",
      "Epoch 168/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 8.5307e-04 - val_loss: 0.0120\n",
      "Epoch 169/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 8.4985e-04 - val_loss: 0.0119\n",
      "Epoch 170/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 8.4665e-04 - val_loss: 0.0119\n",
      "Epoch 171/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 8.4346e-04 - val_loss: 0.0119\n",
      "Epoch 172/300\n",
      "1046/1046 [==============================] - 0s 65us/step - loss: 8.4029e-04 - val_loss: 0.0119\n",
      "Epoch 173/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 8.3714e-04 - val_loss: 0.0119\n",
      "Epoch 174/300\n",
      "1046/1046 [==============================] - 0s 73us/step - loss: 8.3400e-04 - val_loss: 0.0119\n",
      "Epoch 175/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 8.3087e-04 - val_loss: 0.0119\n",
      "Epoch 176/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 8.2775e-04 - val_loss: 0.0118\n",
      "Epoch 177/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 8.2465e-04 - val_loss: 0.0118\n",
      "Epoch 178/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 8.2156e-04 - val_loss: 0.0118\n",
      "Epoch 179/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 8.1848e-04 - val_loss: 0.0118\n",
      "Epoch 180/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 8.1541e-04 - val_loss: 0.0118\n",
      "Epoch 181/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 8.1236e-04 - val_loss: 0.0118\n",
      "Epoch 182/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 8.0931e-04 - val_loss: 0.0118\n",
      "Epoch 183/300\n",
      "1046/1046 [==============================] - 0s 94us/step - loss: 8.0628e-04 - val_loss: 0.0118\n",
      "Epoch 184/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 8.0325e-04 - val_loss: 0.0118\n",
      "Epoch 185/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 8.0024e-04 - val_loss: 0.0118\n",
      "Epoch 186/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 7.9724e-04 - val_loss: 0.0118\n",
      "Epoch 187/300\n",
      "1046/1046 [==============================] - 0s 58us/step - loss: 7.9424e-04 - val_loss: 0.0118\n",
      "Epoch 188/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 7.9126e-04 - val_loss: 0.0118\n",
      "Epoch 189/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 7.8828e-04 - val_loss: 0.0118\n",
      "Epoch 190/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 7.8532e-04 - val_loss: 0.0118\n",
      "Epoch 191/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 7.8237e-04 - val_loss: 0.0118\n",
      "Epoch 192/300\n",
      "1046/1046 [==============================] - 0s 80us/step - loss: 7.7942e-04 - val_loss: 0.0119\n",
      "Epoch 193/300\n",
      "1046/1046 [==============================] - 0s 64us/step - loss: 7.7649e-04 - val_loss: 0.0119\n",
      "Epoch 00193: early stopping\n",
      "Entrenamiento f1 completo.\n",
      "[[386.64783]\n",
      " [372.3105 ]\n",
      " [373.09396]\n",
      " [364.45578]\n",
      " [369.4574 ]\n",
      " [364.95874]\n",
      " [345.81503]\n",
      " [308.07877]\n",
      " [323.37906]\n",
      " [295.57538]\n",
      " [283.61438]\n",
      " [280.0884 ]\n",
      " [253.87456]\n",
      " [249.84927]\n",
      " [252.18747]\n",
      " [254.02467]\n",
      " [296.35944]\n",
      " [274.61285]\n",
      " [281.37152]\n",
      " [252.76648]\n",
      " [261.25885]\n",
      " [248.50096]\n",
      " [256.86655]\n",
      " [266.88034]\n",
      " [264.1496 ]\n",
      " [260.01938]\n",
      " [279.98392]\n",
      " [299.20477]\n",
      " [300.16086]\n",
      " [294.71188]]\n",
      "30\n",
      "Simulación f1 completa.\n",
      "Train on 1045 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1045/1045 [==============================] - 2s 2ms/step - loss: 0.0071 - val_loss: 0.2749\n",
      "Epoch 2/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0066 - val_loss: 0.2661\n",
      "Epoch 3/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0062 - val_loss: 0.2577\n",
      "Epoch 4/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0059 - val_loss: 0.2500\n",
      "Epoch 5/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0057 - val_loss: 0.2430\n",
      "Epoch 6/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 0.0055 - val_loss: 0.2367\n",
      "Epoch 7/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0054 - val_loss: 0.2310\n",
      "Epoch 8/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0053 - val_loss: 0.2258\n",
      "Epoch 9/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0053 - val_loss: 0.2211\n",
      "Epoch 10/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0052 - val_loss: 0.2168\n",
      "Epoch 11/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0052 - val_loss: 0.2129\n",
      "Epoch 12/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0052 - val_loss: 0.2092\n",
      "Epoch 13/300\n",
      "1045/1045 [==============================] - 0s 27us/step - loss: 0.0051 - val_loss: 0.2058\n",
      "Epoch 14/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0051 - val_loss: 0.2025\n",
      "Epoch 15/300\n",
      "1045/1045 [==============================] - 0s 21us/step - loss: 0.0051 - val_loss: 0.1995\n",
      "Epoch 16/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1966\n",
      "Epoch 17/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1938\n",
      "Epoch 18/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0050 - val_loss: 0.1912\n",
      "Epoch 19/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 0.0049 - val_loss: 0.1886\n",
      "Epoch 20/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0049 - val_loss: 0.1860\n",
      "Epoch 21/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 0.0048 - val_loss: 0.1836\n",
      "Epoch 22/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 0.0048 - val_loss: 0.1811\n",
      "Epoch 23/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0048 - val_loss: 0.1788\n",
      "Epoch 24/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 0.0047 - val_loss: 0.1764\n",
      "Epoch 25/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0047 - val_loss: 0.1741\n",
      "Epoch 26/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0046 - val_loss: 0.1717\n",
      "Epoch 27/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0045 - val_loss: 0.1694\n",
      "Epoch 28/300\n",
      "1045/1045 [==============================] - 0s 24us/step - loss: 0.0045 - val_loss: 0.1671\n",
      "Epoch 29/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 0.0044 - val_loss: 0.1648\n",
      "Epoch 30/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0044 - val_loss: 0.1625\n",
      "Epoch 31/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.1602\n",
      "Epoch 32/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.1579\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0042 - val_loss: 0.1555\n",
      "Epoch 34/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.1532\n",
      "Epoch 35/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.1509\n",
      "Epoch 36/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.1485\n",
      "Epoch 37/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 0.0040 - val_loss: 0.1462\n",
      "Epoch 38/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.1438\n",
      "Epoch 39/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.1414\n",
      "Epoch 40/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.1390\n",
      "Epoch 41/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.1366\n",
      "Epoch 42/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.1342\n",
      "Epoch 43/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.1318\n",
      "Epoch 44/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 0.0036 - val_loss: 0.1294\n",
      "Epoch 45/300\n",
      "1045/1045 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.1269\n",
      "Epoch 46/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.1245\n",
      "Epoch 47/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.1221\n",
      "Epoch 48/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.1196\n",
      "Epoch 49/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.1172\n",
      "Epoch 50/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.1147\n",
      "Epoch 51/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.1123\n",
      "Epoch 52/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.1098\n",
      "Epoch 53/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0030 - val_loss: 0.1074\n",
      "Epoch 54/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.1050\n",
      "Epoch 55/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.1025\n",
      "Epoch 56/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.1001\n",
      "Epoch 57/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0977\n",
      "Epoch 58/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0027 - val_loss: 0.0953\n",
      "Epoch 59/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0026 - val_loss: 0.0929\n",
      "Epoch 60/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0026 - val_loss: 0.0905\n",
      "Epoch 61/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 0.0025 - val_loss: 0.0881\n",
      "Epoch 62/300\n",
      "1045/1045 [==============================] - 0s 20us/step - loss: 0.0025 - val_loss: 0.0857\n",
      "Epoch 63/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0834\n",
      "Epoch 64/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0811\n",
      "Epoch 65/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0788\n",
      "Epoch 66/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0765\n",
      "Epoch 67/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0743\n",
      "Epoch 68/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0720\n",
      "Epoch 69/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0698\n",
      "Epoch 70/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0676\n",
      "Epoch 71/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0655\n",
      "Epoch 72/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0634\n",
      "Epoch 73/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0019 - val_loss: 0.0613\n",
      "Epoch 74/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0593\n",
      "Epoch 75/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0573\n",
      "Epoch 76/300\n",
      "1045/1045 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0553\n",
      "Epoch 77/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0533\n",
      "Epoch 78/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0514\n",
      "Epoch 79/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0016 - val_loss: 0.0496\n",
      "Epoch 80/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0478\n",
      "Epoch 81/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0460\n",
      "Epoch 82/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0442\n",
      "Epoch 83/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0426\n",
      "Epoch 84/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0409\n",
      "Epoch 85/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0393\n",
      "Epoch 86/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0013 - val_loss: 0.0377\n",
      "Epoch 87/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0362\n",
      "Epoch 88/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0348\n",
      "Epoch 89/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0333\n",
      "Epoch 90/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0320\n",
      "Epoch 91/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0306\n",
      "Epoch 92/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 0.0011 - val_loss: 0.0293\n",
      "Epoch 93/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 0.0281\n",
      "Epoch 94/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 0.0010 - val_loss: 0.0269\n",
      "Epoch 95/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.9984e-04 - val_loss: 0.0258\n",
      "Epoch 96/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.7384e-04 - val_loss: 0.0247\n",
      "Epoch 97/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.4897e-04 - val_loss: 0.0236\n",
      "Epoch 98/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.2521e-04 - val_loss: 0.0226\n",
      "Epoch 99/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.0255e-04 - val_loss: 0.0216\n",
      "Epoch 100/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.8095e-04 - val_loss: 0.0207\n",
      "Epoch 101/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.6040e-04 - val_loss: 0.0198\n",
      "Epoch 102/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.4086e-04 - val_loss: 0.0189\n",
      "Epoch 103/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.2232e-04 - val_loss: 0.0181\n",
      "Epoch 104/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.0473e-04 - val_loss: 0.0173\n",
      "Epoch 105/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.8808e-04 - val_loss: 0.0166\n",
      "Epoch 106/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 7.7232e-04 - val_loss: 0.0159\n",
      "Epoch 107/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.5743e-04 - val_loss: 0.0153\n",
      "Epoch 108/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 7.4337e-04 - val_loss: 0.0146\n",
      "Epoch 109/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 7.3010e-04 - val_loss: 0.0140\n",
      "Epoch 110/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 34us/step - loss: 7.1760e-04 - val_loss: 0.0135\n",
      "Epoch 111/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 7.0583e-04 - val_loss: 0.0129\n",
      "Epoch 112/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 6.9476e-04 - val_loss: 0.0124\n",
      "Epoch 113/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 6.8434e-04 - val_loss: 0.0120\n",
      "Epoch 114/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 6.7455e-04 - val_loss: 0.0115\n",
      "Epoch 115/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 6.6535e-04 - val_loss: 0.0111\n",
      "Epoch 116/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 6.5670e-04 - val_loss: 0.0107\n",
      "Epoch 117/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.4859e-04 - val_loss: 0.0103\n",
      "Epoch 118/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 6.4097e-04 - val_loss: 0.0100\n",
      "Epoch 119/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.3381e-04 - val_loss: 0.0097\n",
      "Epoch 120/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.2708e-04 - val_loss: 0.0094\n",
      "Epoch 121/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 6.2076e-04 - val_loss: 0.0091\n",
      "Epoch 122/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.1481e-04 - val_loss: 0.0088\n",
      "Epoch 123/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0922e-04 - val_loss: 0.0086\n",
      "Epoch 124/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0394e-04 - val_loss: 0.0083\n",
      "Epoch 125/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.9897e-04 - val_loss: 0.0081\n",
      "Epoch 126/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.9427e-04 - val_loss: 0.0079\n",
      "Epoch 127/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 5.8983e-04 - val_loss: 0.0077\n",
      "Epoch 128/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 5.8562e-04 - val_loss: 0.0075\n",
      "Epoch 129/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 5.8163e-04 - val_loss: 0.0074\n",
      "Epoch 130/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 5.7783e-04 - val_loss: 0.0072\n",
      "Epoch 131/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.7422e-04 - val_loss: 0.0071\n",
      "Epoch 132/300\n",
      "1045/1045 [==============================] - 0s 22us/step - loss: 5.7076e-04 - val_loss: 0.0069\n",
      "Epoch 133/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.6746e-04 - val_loss: 0.0068\n",
      "Epoch 134/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 5.6429e-04 - val_loss: 0.0067\n",
      "Epoch 135/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 5.6124e-04 - val_loss: 0.0066\n",
      "Epoch 136/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.5831e-04 - val_loss: 0.0065\n",
      "Epoch 137/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.5547e-04 - val_loss: 0.0064\n",
      "Epoch 138/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.5272e-04 - val_loss: 0.0063\n",
      "Epoch 139/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 5.5006e-04 - val_loss: 0.0062\n",
      "Epoch 140/300\n",
      "1045/1045 [==============================] - 0s 22us/step - loss: 5.4747e-04 - val_loss: 0.0061\n",
      "Epoch 141/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.4494e-04 - val_loss: 0.0060\n",
      "Epoch 142/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.4247e-04 - val_loss: 0.0060\n",
      "Epoch 143/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.4005e-04 - val_loss: 0.0059\n",
      "Epoch 144/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.3768e-04 - val_loss: 0.0058\n",
      "Epoch 145/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 5.3536e-04 - val_loss: 0.0058\n",
      "Epoch 146/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.3306e-04 - val_loss: 0.0057\n",
      "Epoch 147/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.3080e-04 - val_loss: 0.0057\n",
      "Epoch 148/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.2858e-04 - val_loss: 0.0056\n",
      "Epoch 149/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.2637e-04 - val_loss: 0.0056\n",
      "Epoch 150/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.2419e-04 - val_loss: 0.0056\n",
      "Epoch 151/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.2203e-04 - val_loss: 0.0055\n",
      "Epoch 152/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1989e-04 - val_loss: 0.0055\n",
      "Epoch 153/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1776e-04 - val_loss: 0.0054\n",
      "Epoch 154/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1565e-04 - val_loss: 0.0054\n",
      "Epoch 155/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1355e-04 - val_loss: 0.0054\n",
      "Epoch 156/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1146e-04 - val_loss: 0.0054\n",
      "Epoch 157/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0938e-04 - val_loss: 0.0053\n",
      "Epoch 158/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0731e-04 - val_loss: 0.0053\n",
      "Epoch 159/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0525e-04 - val_loss: 0.0053\n",
      "Epoch 160/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0319e-04 - val_loss: 0.0053\n",
      "Epoch 161/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0114e-04 - val_loss: 0.0052\n",
      "Epoch 162/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.9910e-04 - val_loss: 0.0052\n",
      "Epoch 163/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.9706e-04 - val_loss: 0.0052\n",
      "Epoch 164/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.9503e-04 - val_loss: 0.0052\n",
      "Epoch 165/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.9300e-04 - val_loss: 0.0052\n",
      "Epoch 166/300\n",
      "1045/1045 [==============================] - 0s 22us/step - loss: 4.9098e-04 - val_loss: 0.0051\n",
      "Epoch 167/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8896e-04 - val_loss: 0.0051\n",
      "Epoch 168/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8694e-04 - val_loss: 0.0051\n",
      "Epoch 169/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8493e-04 - val_loss: 0.0051\n",
      "Epoch 170/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8292e-04 - val_loss: 0.0051\n",
      "Epoch 171/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8091e-04 - val_loss: 0.0051\n",
      "Epoch 172/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 4.7891e-04 - val_loss: 0.0050\n",
      "Epoch 173/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 4.7691e-04 - val_loss: 0.0050\n",
      "Epoch 174/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.7491e-04 - val_loss: 0.0050\n",
      "Epoch 175/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.7292e-04 - val_loss: 0.0050\n",
      "Epoch 176/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.7092e-04 - val_loss: 0.0050\n",
      "Epoch 177/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6893e-04 - val_loss: 0.0050\n",
      "Epoch 178/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6695e-04 - val_loss: 0.0050\n",
      "Epoch 179/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6497e-04 - val_loss: 0.0050\n",
      "Epoch 180/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6299e-04 - val_loss: 0.0050\n",
      "Epoch 181/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6101e-04 - val_loss: 0.0049\n",
      "Epoch 182/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.5903e-04 - val_loss: 0.0049\n",
      "Epoch 183/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.5706e-04 - val_loss: 0.0049\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.5509e-04 - val_loss: 0.0049\n",
      "Epoch 185/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.5313e-04 - val_loss: 0.0049\n",
      "Epoch 186/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 4.5117e-04 - val_loss: 0.0049\n",
      "Epoch 187/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.4921e-04 - val_loss: 0.0049\n",
      "Epoch 188/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.4725e-04 - val_loss: 0.0049\n",
      "Epoch 189/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.4530e-04 - val_loss: 0.0049\n",
      "Epoch 190/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.4335e-04 - val_loss: 0.0049\n",
      "Epoch 191/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.4140e-04 - val_loss: 0.0049\n",
      "Epoch 192/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.3946e-04 - val_loss: 0.0049\n",
      "Epoch 193/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.3752e-04 - val_loss: 0.0048\n",
      "Epoch 194/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.3558e-04 - val_loss: 0.0048\n",
      "Epoch 195/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.3365e-04 - val_loss: 0.0048\n",
      "Epoch 196/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 4.3172e-04 - val_loss: 0.0048\n",
      "Epoch 197/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 4.2979e-04 - val_loss: 0.0048\n",
      "Epoch 198/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.2786e-04 - val_loss: 0.0048\n",
      "Epoch 199/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.2594e-04 - val_loss: 0.0048\n",
      "Epoch 200/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.2403e-04 - val_loss: 0.0048\n",
      "Epoch 201/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.2212e-04 - val_loss: 0.0048\n",
      "Epoch 202/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.2021e-04 - val_loss: 0.0048\n",
      "Epoch 203/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.1830e-04 - val_loss: 0.0048\n",
      "Epoch 204/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.1640e-04 - val_loss: 0.0048\n",
      "Epoch 205/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.1450e-04 - val_loss: 0.0048\n",
      "Epoch 206/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.1260e-04 - val_loss: 0.0048\n",
      "Epoch 207/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.1071e-04 - val_loss: 0.0048\n",
      "Epoch 208/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.0883e-04 - val_loss: 0.0048\n",
      "Epoch 209/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 4.0694e-04 - val_loss: 0.0048\n",
      "Epoch 210/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 4.0506e-04 - val_loss: 0.0047\n",
      "Epoch 211/300\n",
      "1045/1045 [==============================] - 0s 50us/step - loss: 4.0319e-04 - val_loss: 0.0047\n",
      "Epoch 212/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 4.0131e-04 - val_loss: 0.0047\n",
      "Epoch 213/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 3.9945e-04 - val_loss: 0.0047\n",
      "Epoch 214/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 3.9758e-04 - val_loss: 0.0047\n",
      "Epoch 215/300\n",
      "1045/1045 [==============================] - 0s 46us/step - loss: 3.9572e-04 - val_loss: 0.0047\n",
      "Epoch 216/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 3.9387e-04 - val_loss: 0.0047\n",
      "Epoch 217/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 3.9201e-04 - val_loss: 0.0047\n",
      "Epoch 218/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 3.9017e-04 - val_loss: 0.0047\n",
      "Epoch 219/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 3.8832e-04 - val_loss: 0.0047\n",
      "Epoch 220/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 3.8648e-04 - val_loss: 0.0047\n",
      "Epoch 221/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 3.8465e-04 - val_loss: 0.0047\n",
      "Epoch 222/300\n",
      "1045/1045 [==============================] - 0s 22us/step - loss: 3.8282e-04 - val_loss: 0.0047\n",
      "Epoch 223/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.8099e-04 - val_loss: 0.0047\n",
      "Epoch 224/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7917e-04 - val_loss: 0.0047\n",
      "Epoch 225/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7735e-04 - val_loss: 0.0047\n",
      "Epoch 226/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7554e-04 - val_loss: 0.0047\n",
      "Epoch 227/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7373e-04 - val_loss: 0.0047\n",
      "Epoch 228/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7192e-04 - val_loss: 0.0047\n",
      "Epoch 229/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7012e-04 - val_loss: 0.0047\n",
      "Epoch 230/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.6833e-04 - val_loss: 0.0047\n",
      "Epoch 231/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.6654e-04 - val_loss: 0.0047\n",
      "Epoch 232/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.6475e-04 - val_loss: 0.0047\n",
      "Epoch 233/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 3.6297e-04 - val_loss: 0.0047\n",
      "Epoch 234/300\n",
      "1045/1045 [==============================] - 0s 25us/step - loss: 3.6119e-04 - val_loss: 0.0047\n",
      "Epoch 235/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.5942e-04 - val_loss: 0.0047\n",
      "Epoch 236/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.5765e-04 - val_loss: 0.0047\n",
      "Epoch 237/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.5589e-04 - val_loss: 0.0046\n",
      "Epoch 238/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.5413e-04 - val_loss: 0.0046\n",
      "Epoch 239/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 3.5238e-04 - val_loss: 0.0046\n",
      "Epoch 240/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 3.5063e-04 - val_loss: 0.0046\n",
      "Epoch 241/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 3.4889e-04 - val_loss: 0.0046\n",
      "Epoch 242/300\n",
      "1045/1045 [==============================] - 0s 52us/step - loss: 3.4716e-04 - val_loss: 0.0046\n",
      "Epoch 243/300\n",
      "1045/1045 [==============================] - 0s 48us/step - loss: 3.4542e-04 - val_loss: 0.0046\n",
      "Epoch 244/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 3.4370e-04 - val_loss: 0.0046\n",
      "Epoch 245/300\n",
      "1045/1045 [==============================] - 0s 21us/step - loss: 3.4198e-04 - val_loss: 0.0046\n",
      "Epoch 246/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 3.4026e-04 - val_loss: 0.0046\n",
      "Epoch 247/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 3.3855e-04 - val_loss: 0.0046\n",
      "Epoch 248/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.3684e-04 - val_loss: 0.0046\n",
      "Epoch 249/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 3.3515e-04 - val_loss: 0.0046\n",
      "Epoch 250/300\n",
      "1045/1045 [==============================] - 0s 17us/step - loss: 3.3345e-04 - val_loss: 0.0046\n",
      "Epoch 251/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 3.3176e-04 - val_loss: 0.0046\n",
      "Epoch 252/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.3008e-04 - val_loss: 0.0046\n",
      "Epoch 253/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2840e-04 - val_loss: 0.0046\n",
      "Epoch 254/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2673e-04 - val_loss: 0.0046\n",
      "Epoch 255/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 3.2506e-04 - val_loss: 0.0046\n",
      "Epoch 256/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2340e-04 - val_loss: 0.0046\n",
      "Epoch 257/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2175e-04 - val_loss: 0.0046\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2010e-04 - val_loss: 0.0046\n",
      "Epoch 259/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1846e-04 - val_loss: 0.0046\n",
      "Epoch 260/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1682e-04 - val_loss: 0.0046\n",
      "Epoch 261/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1519e-04 - val_loss: 0.0046\n",
      "Epoch 262/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1357e-04 - val_loss: 0.0046\n",
      "Epoch 263/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1195e-04 - val_loss: 0.0046\n",
      "Epoch 264/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 3.1034e-04 - val_loss: 0.0046\n",
      "Epoch 265/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0874e-04 - val_loss: 0.0046\n",
      "Epoch 266/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0714e-04 - val_loss: 0.0046\n",
      "Epoch 267/300\n",
      "1045/1045 [==============================] - 0s 21us/step - loss: 3.0554e-04 - val_loss: 0.0046\n",
      "Epoch 268/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0396e-04 - val_loss: 0.0046\n",
      "Epoch 269/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0238e-04 - val_loss: 0.0046\n",
      "Epoch 270/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0081e-04 - val_loss: 0.0046\n",
      "Epoch 271/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9924e-04 - val_loss: 0.0046\n",
      "Epoch 272/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9768e-04 - val_loss: 0.0046\n",
      "Epoch 273/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9613e-04 - val_loss: 0.0046\n",
      "Epoch 274/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9458e-04 - val_loss: 0.0046\n",
      "Epoch 275/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9304e-04 - val_loss: 0.0046\n",
      "Epoch 276/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9151e-04 - val_loss: 0.0046\n",
      "Epoch 277/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8998e-04 - val_loss: 0.0046\n",
      "Epoch 278/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8846e-04 - val_loss: 0.0046\n",
      "Epoch 279/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8695e-04 - val_loss: 0.0046\n",
      "Epoch 280/300\n",
      "1045/1045 [==============================] - 0s 25us/step - loss: 2.8545e-04 - val_loss: 0.0046\n",
      "Epoch 281/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8395e-04 - val_loss: 0.0046\n",
      "Epoch 282/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8246e-04 - val_loss: 0.0046\n",
      "Epoch 283/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8098e-04 - val_loss: 0.0046\n",
      "Epoch 284/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 2.7950e-04 - val_loss: 0.0046\n",
      "Epoch 285/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 2.7803e-04 - val_loss: 0.0046\n",
      "Epoch 286/300\n",
      "1045/1045 [==============================] - 0s 15us/step - loss: 2.7657e-04 - val_loss: 0.0046\n",
      "Epoch 287/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.7512e-04 - val_loss: 0.0046\n",
      "Epoch 288/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.7367e-04 - val_loss: 0.0046\n",
      "Epoch 289/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.7223e-04 - val_loss: 0.0045\n",
      "Epoch 290/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.7080e-04 - val_loss: 0.0045\n",
      "Epoch 291/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6938e-04 - val_loss: 0.0045\n",
      "Epoch 292/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6796e-04 - val_loss: 0.0045\n",
      "Epoch 293/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6655e-04 - val_loss: 0.0045\n",
      "Epoch 294/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6515e-04 - val_loss: 0.0045\n",
      "Epoch 295/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6376e-04 - val_loss: 0.0045\n",
      "Epoch 296/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6238e-04 - val_loss: 0.0045\n",
      "Epoch 297/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6100e-04 - val_loss: 0.0045\n",
      "Epoch 298/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.5963e-04 - val_loss: 0.0045\n",
      "Epoch 299/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.5827e-04 - val_loss: 0.0045\n",
      "Epoch 300/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.5691e-04 - val_loss: 0.0045\n",
      "Entrenamiento f2 completo.\n",
      "[[388.44156]\n",
      " [377.8868 ]\n",
      " [364.51086]\n",
      " [366.46777]\n",
      " [356.6488 ]\n",
      " [362.24002]\n",
      " [359.64264]\n",
      " [336.74002]\n",
      " [300.38672]\n",
      " [311.82523]\n",
      " [284.45227]\n",
      " [271.74005]\n",
      " [268.7123 ]\n",
      " [241.24821]\n",
      " [238.95442]\n",
      " [241.2574 ]\n",
      " [242.89264]\n",
      " [279.09106]\n",
      " [257.00485]\n",
      " [263.28442]\n",
      " [236.89157]\n",
      " [244.3478 ]\n",
      " [233.52655]\n",
      " [240.00066]\n",
      " [246.93954]\n",
      " [244.93176]\n",
      " [240.15346]\n",
      " [256.81384]\n",
      " [273.41635]\n",
      " [273.12622]]\n",
      "30\n",
      "Simulación f2 completa.\n",
      "Train on 1044 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: 0.0074 - val_loss: 0.2468\n",
      "Epoch 2/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0069 - val_loss: 0.2402\n",
      "Epoch 3/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0066 - val_loss: 0.2340\n",
      "Epoch 4/300\n",
      "1044/1044 [==============================] - 0s 56us/step - loss: 0.0063 - val_loss: 0.2282\n",
      "Epoch 5/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0061 - val_loss: 0.2229\n",
      "Epoch 6/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 0.0059 - val_loss: 0.2181\n",
      "Epoch 7/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0058 - val_loss: 0.2138\n",
      "Epoch 8/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0057 - val_loss: 0.2098\n",
      "Epoch 9/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 0.0057 - val_loss: 0.2062\n",
      "Epoch 10/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0056 - val_loss: 0.2029\n",
      "Epoch 11/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0056 - val_loss: 0.1998\n",
      "Epoch 12/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0056 - val_loss: 0.1969\n",
      "Epoch 13/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0056 - val_loss: 0.1943\n",
      "Epoch 14/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 0.0056 - val_loss: 0.1918\n",
      "Epoch 15/300\n",
      "1044/1044 [==============================] - 0s 101us/step - loss: 0.0056 - val_loss: 0.1894\n",
      "Epoch 16/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0056 - val_loss: 0.1871\n",
      "Epoch 17/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0056 - val_loss: 0.1850\n",
      "Epoch 18/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0055 - val_loss: 0.1829\n",
      "Epoch 19/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0055 - val_loss: 0.1809\n",
      "Epoch 20/300\n",
      "1044/1044 [==============================] - 0s 57us/step - loss: 0.0055 - val_loss: 0.1789\n",
      "Epoch 21/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0055 - val_loss: 0.1770\n",
      "Epoch 22/300\n",
      "1044/1044 [==============================] - 0s 64us/step - loss: 0.0055 - val_loss: 0.1751\n",
      "Epoch 23/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0055 - val_loss: 0.1732\n",
      "Epoch 24/300\n",
      "1044/1044 [==============================] - 0s 64us/step - loss: 0.0054 - val_loss: 0.1714\n",
      "Epoch 25/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0054 - val_loss: 0.1695\n",
      "Epoch 26/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0054 - val_loss: 0.1676\n",
      "Epoch 27/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0054 - val_loss: 0.1658\n",
      "Epoch 28/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.1639\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.1620\n",
      "Epoch 30/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0053 - val_loss: 0.1600\n",
      "Epoch 31/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0052 - val_loss: 0.1581\n",
      "Epoch 32/300\n",
      "1044/1044 [==============================] - 0s 25us/step - loss: 0.0052 - val_loss: 0.1561\n",
      "Epoch 33/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0052 - val_loss: 0.1540\n",
      "Epoch 34/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0051 - val_loss: 0.1520\n",
      "Epoch 35/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0051 - val_loss: 0.1498\n",
      "Epoch 36/300\n",
      "1044/1044 [==============================] - ETA: 0s - loss: 0.002 - 0s 40us/step - loss: 0.0050 - val_loss: 0.1477\n",
      "Epoch 37/300\n",
      "1044/1044 [==============================] - 0s 22us/step - loss: 0.0050 - val_loss: 0.1455\n",
      "Epoch 38/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0049 - val_loss: 0.1432\n",
      "Epoch 39/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0049 - val_loss: 0.1409\n",
      "Epoch 40/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.1385\n",
      "Epoch 41/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.1361\n",
      "Epoch 42/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0047 - val_loss: 0.1336\n",
      "Epoch 43/300\n",
      "1044/1044 [==============================] - 0s 55us/step - loss: 0.0047 - val_loss: 0.1310\n",
      "Epoch 44/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0046 - val_loss: 0.1284\n",
      "Epoch 45/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0045 - val_loss: 0.1257\n",
      "Epoch 46/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0045 - val_loss: 0.1229\n",
      "Epoch 47/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0044 - val_loss: 0.1201\n",
      "Epoch 48/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0044 - val_loss: 0.1172\n",
      "Epoch 49/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0043 - val_loss: 0.1143\n",
      "Epoch 50/300\n",
      "1044/1044 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.1113\n",
      "Epoch 51/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.1082\n",
      "Epoch 52/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.1051\n",
      "Epoch 53/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.1019\n",
      "Epoch 54/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0039 - val_loss: 0.0987\n",
      "Epoch 55/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0038 - val_loss: 0.0955\n",
      "Epoch 56/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0037 - val_loss: 0.0922\n",
      "Epoch 57/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0037 - val_loss: 0.0889\n",
      "Epoch 58/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 0.0036 - val_loss: 0.0856\n",
      "Epoch 59/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0035 - val_loss: 0.0823\n",
      "Epoch 60/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0790\n",
      "Epoch 61/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0033 - val_loss: 0.0758\n",
      "Epoch 62/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0725\n",
      "Epoch 63/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0693\n",
      "Epoch 64/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0661\n",
      "Epoch 65/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0030 - val_loss: 0.0630\n",
      "Epoch 66/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.0599\n",
      "Epoch 67/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0028 - val_loss: 0.0569\n",
      "Epoch 68/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0028 - val_loss: 0.0539\n",
      "Epoch 69/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0027 - val_loss: 0.0511\n",
      "Epoch 70/300\n",
      "1044/1044 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0483\n",
      "Epoch 71/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0025 - val_loss: 0.0456\n",
      "Epoch 72/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0430\n",
      "Epoch 73/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 0.0024 - val_loss: 0.0405\n",
      "Epoch 74/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 0.0023 - val_loss: 0.0381\n",
      "Epoch 75/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 0.0022 - val_loss: 0.0358\n",
      "Epoch 76/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0336\n",
      "Epoch 77/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0316\n",
      "Epoch 78/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0296\n",
      "Epoch 79/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0277\n",
      "Epoch 80/300\n",
      "1044/1044 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0260\n",
      "Epoch 81/300\n",
      "1044/1044 [==============================] - 0s 15us/step - loss: 0.0019 - val_loss: 0.0244\n",
      "Epoch 82/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0228\n",
      "Epoch 83/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0214\n",
      "Epoch 84/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0201\n",
      "Epoch 85/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0188\n",
      "Epoch 86/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0017 - val_loss: 0.0177\n",
      "Epoch 87/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0167\n",
      "Epoch 88/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0157\n",
      "Epoch 89/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0148\n",
      "Epoch 90/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0016 - val_loss: 0.0140\n",
      "Epoch 91/300\n",
      "1044/1044 [==============================] - 0s 21us/step - loss: 0.0016 - val_loss: 0.0133\n",
      "Epoch 92/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 93/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0120\n",
      "Epoch 94/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0115\n",
      "Epoch 95/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0110\n",
      "Epoch 96/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 0.0105\n",
      "Epoch 97/300\n",
      "1044/1044 [==============================] - 0s 55us/step - loss: 0.0014 - val_loss: 0.0101\n",
      "Epoch 98/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 0.0098\n",
      "Epoch 99/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0014 - val_loss: 0.0095\n",
      "Epoch 100/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0014 - val_loss: 0.0092\n",
      "Epoch 101/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0014 - val_loss: 0.0089\n",
      "Epoch 102/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0014 - val_loss: 0.0087\n",
      "Epoch 103/300\n",
      "1044/1044 [==============================] - 0s 77us/step - loss: 0.0014 - val_loss: 0.0085\n",
      "Epoch 104/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 0.0013 - val_loss: 0.0083\n",
      "Epoch 105/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0013 - val_loss: 0.0082\n",
      "Epoch 106/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 0.0013 - val_loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 108/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 0.0013 - val_loss: 0.0078\n",
      "Epoch 109/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 110/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0013 - val_loss: 0.0076\n",
      "Epoch 111/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 112/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 113/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 114/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 115/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 116/300\n",
      "1044/1044 [==============================] - 0s 28us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 117/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 118/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 119/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 120/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 121/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 122/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 123/300\n",
      "1044/1044 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 124/300\n",
      "1044/1044 [==============================] - 0s 88us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 125/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 126/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 127/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 128/300\n",
      "1044/1044 [==============================] - 0s 53us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 129/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 130/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 131/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 132/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 133/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 00133: early stopping\n",
      "Entrenamiento f3 completo.\n",
      "[[364.87106]\n",
      " [342.91895]\n",
      " [332.3541 ]\n",
      " [318.01263]\n",
      " [317.3125 ]\n",
      " [310.2039 ]\n",
      " [314.88696]\n",
      " [308.9792 ]\n",
      " [292.483  ]\n",
      " [262.49097]\n",
      " [276.9055 ]\n",
      " [252.36206]\n",
      " [242.37492]\n",
      " [238.5441 ]\n",
      " [215.26637]\n",
      " [211.64767]\n",
      " [213.13702]\n",
      " [216.57573]\n",
      " [251.15742]\n",
      " [232.75346]\n",
      " [237.6993 ]\n",
      " [213.5299 ]\n",
      " [220.68294]\n",
      " [208.95474]\n",
      " [215.82706]\n",
      " [225.19078]\n",
      " [222.05849]\n",
      " [219.09918]\n",
      " [235.3504 ]\n",
      " [250.1938 ]]\n",
      "30\n",
      "Simulación f3 completa.\n",
      "            Close ethereum          f1          f2          f3\n",
      "Date                                                          \n",
      "2015-01-01            0.00         NaN         NaN         NaN\n",
      "2015-01-02            0.00         NaN         NaN         NaN\n",
      "2015-01-03            0.00         NaN         NaN         NaN\n",
      "2015-01-04            0.00         NaN         NaN         NaN\n",
      "2015-01-05            0.00         NaN         NaN         NaN\n",
      "2015-01-06            0.00         NaN         NaN         NaN\n",
      "2015-01-07            0.00         NaN         NaN         NaN\n",
      "2015-01-08            0.00         NaN         NaN         NaN\n",
      "2015-01-09            0.00         NaN         NaN         NaN\n",
      "2015-01-10            0.00         NaN         NaN         NaN\n",
      "2015-01-11            0.00         NaN         NaN         NaN\n",
      "2015-01-12            0.00         NaN         NaN         NaN\n",
      "2015-01-13            0.00         NaN         NaN         NaN\n",
      "2015-01-14            0.00         NaN         NaN         NaN\n",
      "2015-01-15            0.00         NaN         NaN         NaN\n",
      "2015-01-16            0.00         NaN         NaN         NaN\n",
      "2015-01-17            0.00         NaN         NaN         NaN\n",
      "2015-01-18            0.00         NaN         NaN         NaN\n",
      "2015-01-19            0.00         NaN         NaN         NaN\n",
      "2015-01-20            0.00         NaN         NaN         NaN\n",
      "2015-01-21            0.00         NaN         NaN         NaN\n",
      "2015-01-22            0.00         NaN         NaN         NaN\n",
      "2015-01-23            0.00         NaN         NaN         NaN\n",
      "2015-01-24            0.00         NaN         NaN         NaN\n",
      "2015-01-25            0.00         NaN         NaN         NaN\n",
      "2015-01-26            0.00         NaN         NaN         NaN\n",
      "2015-01-27            0.00         NaN         NaN         NaN\n",
      "2015-01-28            0.00         NaN         NaN         NaN\n",
      "2015-01-29            0.00         NaN         NaN         NaN\n",
      "2015-01-30            0.00         NaN         NaN         NaN\n",
      "...                    ...         ...         ...         ...\n",
      "2018-08-02          412.62  386.647827  388.441559  364.871063\n",
      "2018-08-03          418.26  372.310486  377.886810  342.918945\n",
      "2018-08-04          407.25  373.093964  364.510864  332.354095\n",
      "2018-08-05          410.52  364.455780  366.467773  318.012634\n",
      "2018-08-06          406.66  369.457397  356.648804  317.312500\n",
      "2018-08-07          380.21  364.958740  362.240021  310.203888\n",
      "2018-08-08          356.61  345.815033  359.642639  314.886963\n",
      "2018-08-09          365.59  308.078766  336.740021  308.979187\n",
      "2018-08-10          334.18  323.379059  300.386719  292.483002\n",
      "2018-08-11          322.11  295.575378  311.825226  262.490967\n",
      "2018-08-12          319.57  283.614380  284.452271  276.905487\n",
      "2018-08-13          286.50  280.088409  271.740051  252.362061\n",
      "2018-08-14          278.93  253.874557  268.712311  242.374924\n",
      "2018-08-15          282.36  249.849274  241.248215  238.544098\n",
      "2018-08-16          288.05  252.187469  238.954422  215.266373\n",
      "2018-08-17          315.73  254.024673  241.257401  211.647675\n",
      "2018-08-18          295.81  296.359436  242.892639  213.137024\n",
      "2018-08-19          300.83  274.612854  279.091064  216.575729\n",
      "2018-08-20          274.31  281.371521  257.004852  251.157425\n",
      "2018-08-21          281.94  252.766479  263.284424  232.753464\n",
      "2018-08-22          271.34  261.258850  236.891571  237.699295\n",
      "2018-08-23          277.10  248.500961  244.347794  213.529907\n",
      "2018-08-24          282.97  256.866547  233.526550  220.682938\n",
      "2018-08-25          279.65  266.880341  240.000656  208.954742\n",
      "2018-08-26          275.20  264.149597  246.939545  215.827057\n",
      "2018-08-27          285.60  260.019379  244.931763  225.190781\n",
      "2018-08-28          296.50  279.983917  240.153458  222.058487\n",
      "2018-08-29          289.31  299.204773  256.813843  219.099182\n",
      "2018-08-30          284.11  300.160858  273.416351  235.350403\n",
      "2018-08-31          283.00  294.711884  273.126221  250.193802\n",
      "\n",
      "[1339 rows x 4 columns]\n",
      "RMSEs guardados: script/ethereum/post/Predicciones entrenamiento rmses.csv\n",
      "Epochs guardados: script/ethereum/post/Predicciones entrenamiento rmses.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criptomoneda procesada: ripple\n",
      "Criptomoneda procesada: eos\n",
      "Criptomoneda procesada: qtum\n",
      "Criptomoneda procesada: omisego\n",
      "Criptomoneda procesada: zcash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1046 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1046/1046 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 0.0956\n",
      "Epoch 2/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 9.1977e-04 - val_loss: 0.0918\n",
      "Epoch 3/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 8.4222e-04 - val_loss: 0.0886\n",
      "Epoch 4/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.2109e-04 - val_loss: 0.0862\n",
      "Epoch 5/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.2490e-04 - val_loss: 0.0843\n",
      "Epoch 6/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 8.3286e-04 - val_loss: 0.0830\n",
      "Epoch 7/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 8.3621e-04 - val_loss: 0.0820\n",
      "Epoch 8/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 8.3353e-04 - val_loss: 0.0812\n",
      "Epoch 9/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 8.2634e-04 - val_loss: 0.0806\n",
      "Epoch 10/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.1663e-04 - val_loss: 0.0800\n",
      "Epoch 11/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.0589e-04 - val_loss: 0.0795\n",
      "Epoch 12/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 7.9501e-04 - val_loss: 0.0790\n",
      "Epoch 13/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 7.8445e-04 - val_loss: 0.0785\n",
      "Epoch 14/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.7435e-04 - val_loss: 0.0780\n",
      "Epoch 15/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 7.6474e-04 - val_loss: 0.0776\n",
      "Epoch 16/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.5559e-04 - val_loss: 0.0771\n",
      "Epoch 17/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.4682e-04 - val_loss: 0.0767\n",
      "Epoch 18/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 7.3838e-04 - val_loss: 0.0763\n",
      "Epoch 19/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.3021e-04 - val_loss: 0.0759\n",
      "Epoch 20/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 7.2227e-04 - val_loss: 0.0755\n",
      "Epoch 21/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 7.1452e-04 - val_loss: 0.0752\n",
      "Epoch 22/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 7.0694e-04 - val_loss: 0.0748\n",
      "Epoch 23/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.9950e-04 - val_loss: 0.0744\n",
      "Epoch 24/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.9217e-04 - val_loss: 0.0741\n",
      "Epoch 25/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 6.8494e-04 - val_loss: 0.0737\n",
      "Epoch 26/300\n",
      "1046/1046 [==============================] - 0s 19us/step - loss: 6.7778e-04 - val_loss: 0.0734\n",
      "Epoch 27/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 6.7067e-04 - val_loss: 0.0730\n",
      "Epoch 28/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 6.6360e-04 - val_loss: 0.0727\n",
      "Epoch 29/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 6.5655e-04 - val_loss: 0.0723\n",
      "Epoch 30/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 6.4949e-04 - val_loss: 0.0719\n",
      "Epoch 31/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 6.4242e-04 - val_loss: 0.0715\n",
      "Epoch 32/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 6.3531e-04 - val_loss: 0.0712\n",
      "Epoch 33/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 6.2816e-04 - val_loss: 0.0708\n",
      "Epoch 34/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 6.2094e-04 - val_loss: 0.0704\n",
      "Epoch 35/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 6.1365e-04 - val_loss: 0.0699\n",
      "Epoch 36/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 6.0627e-04 - val_loss: 0.0695\n",
      "Epoch 37/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 5.9880e-04 - val_loss: 0.0690\n",
      "Epoch 38/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 5.9123e-04 - val_loss: 0.0685\n",
      "Epoch 39/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 5.8354e-04 - val_loss: 0.0680\n",
      "Epoch 40/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.7574e-04 - val_loss: 0.0675\n",
      "Epoch 41/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 5.6782e-04 - val_loss: 0.0670\n",
      "Epoch 42/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 5.5977e-04 - val_loss: 0.0664\n",
      "Epoch 43/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 5.5160e-04 - val_loss: 0.0658\n",
      "Epoch 44/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 5.4330e-04 - val_loss: 0.0651\n",
      "Epoch 45/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 5.3487e-04 - val_loss: 0.0645\n",
      "Epoch 46/300\n",
      "1046/1046 [==============================] - 0s 22us/step - loss: 5.2632e-04 - val_loss: 0.0638\n",
      "Epoch 47/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 5.1765e-04 - val_loss: 0.0631\n",
      "Epoch 48/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 5.0887e-04 - val_loss: 0.0624\n",
      "Epoch 49/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 4.9997e-04 - val_loss: 0.0616\n",
      "Epoch 50/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 4.9097e-04 - val_loss: 0.0608\n",
      "Epoch 51/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.8188e-04 - val_loss: 0.0600\n",
      "Epoch 52/300\n",
      "1046/1046 [==============================] - 0s 18us/step - loss: 4.7270e-04 - val_loss: 0.0591\n",
      "Epoch 53/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.6344e-04 - val_loss: 0.0582\n",
      "Epoch 54/300\n",
      "1046/1046 [==============================] - 0s 17us/step - loss: 4.5413e-04 - val_loss: 0.0573\n",
      "Epoch 55/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.4476e-04 - val_loss: 0.0564\n",
      "Epoch 56/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 4.3536e-04 - val_loss: 0.0555\n",
      "Epoch 57/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.2594e-04 - val_loss: 0.0545\n",
      "Epoch 58/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.1651e-04 - val_loss: 0.0535\n",
      "Epoch 59/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 4.0709e-04 - val_loss: 0.0525\n",
      "Epoch 60/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.9770e-04 - val_loss: 0.0514\n",
      "Epoch 61/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.8835e-04 - val_loss: 0.0504\n",
      "Epoch 62/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 3.7906e-04 - val_loss: 0.0493\n",
      "Epoch 63/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.6985e-04 - val_loss: 0.0483\n",
      "Epoch 64/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.6074e-04 - val_loss: 0.0472\n",
      "Epoch 65/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.5174e-04 - val_loss: 0.0461\n",
      "Epoch 66/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.4288e-04 - val_loss: 0.0450\n",
      "Epoch 67/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.3416e-04 - val_loss: 0.0439\n",
      "Epoch 68/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 3.2560e-04 - val_loss: 0.0428\n",
      "Epoch 69/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 3.1722e-04 - val_loss: 0.0418\n",
      "Epoch 70/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.0904e-04 - val_loss: 0.0407\n",
      "Epoch 71/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 3.0106e-04 - val_loss: 0.0396\n",
      "Epoch 72/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.9331e-04 - val_loss: 0.0385\n",
      "Epoch 73/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 2.8579e-04 - val_loss: 0.0375\n",
      "Epoch 74/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.7851e-04 - val_loss: 0.0365\n",
      "Epoch 75/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 2.7148e-04 - val_loss: 0.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 2.6471e-04 - val_loss: 0.0344\n",
      "Epoch 77/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 2.5821e-04 - val_loss: 0.0335\n",
      "Epoch 78/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 2.5197e-04 - val_loss: 0.0325\n",
      "Epoch 79/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 2.4601e-04 - val_loss: 0.0316\n",
      "Epoch 80/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 2.4032e-04 - val_loss: 0.0307\n",
      "Epoch 81/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 2.3491e-04 - val_loss: 0.0298\n",
      "Epoch 82/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.2977e-04 - val_loss: 0.0289\n",
      "Epoch 83/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.2490e-04 - val_loss: 0.0281\n",
      "Epoch 84/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.2029e-04 - val_loss: 0.0273\n",
      "Epoch 85/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.1594e-04 - val_loss: 0.0265\n",
      "Epoch 86/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.1184e-04 - val_loss: 0.0257\n",
      "Epoch 87/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.0798e-04 - val_loss: 0.0250\n",
      "Epoch 88/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 2.0437e-04 - val_loss: 0.0243\n",
      "Epoch 89/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 2.0097e-04 - val_loss: 0.0237\n",
      "Epoch 90/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.9779e-04 - val_loss: 0.0230\n",
      "Epoch 91/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 1.9481e-04 - val_loss: 0.0224\n",
      "Epoch 92/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 1.9203e-04 - val_loss: 0.0218\n",
      "Epoch 93/300\n",
      "1046/1046 [==============================] - 0s 19us/step - loss: 1.8943e-04 - val_loss: 0.0213\n",
      "Epoch 94/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.8700e-04 - val_loss: 0.0208\n",
      "Epoch 95/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 1.8472e-04 - val_loss: 0.0203\n",
      "Epoch 96/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.8259e-04 - val_loss: 0.0198\n",
      "Epoch 97/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.8060e-04 - val_loss: 0.0193\n",
      "Epoch 98/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.7873e-04 - val_loss: 0.0189\n",
      "Epoch 99/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.7697e-04 - val_loss: 0.0185\n",
      "Epoch 100/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.7532e-04 - val_loss: 0.0181\n",
      "Epoch 101/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.7377e-04 - val_loss: 0.0177\n",
      "Epoch 102/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.7229e-04 - val_loss: 0.0174\n",
      "Epoch 103/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 1.7090e-04 - val_loss: 0.0171\n",
      "Epoch 104/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 1.6957e-04 - val_loss: 0.0168\n",
      "Epoch 105/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 1.6830e-04 - val_loss: 0.0165\n",
      "Epoch 106/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 1.6709e-04 - val_loss: 0.0162\n",
      "Epoch 107/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.6593e-04 - val_loss: 0.0159\n",
      "Epoch 108/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.6480e-04 - val_loss: 0.0157\n",
      "Epoch 109/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 1.6372e-04 - val_loss: 0.0154\n",
      "Epoch 110/300\n",
      "1046/1046 [==============================] - 0s 18us/step - loss: 1.6267e-04 - val_loss: 0.0152\n",
      "Epoch 111/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.6165e-04 - val_loss: 0.0150\n",
      "Epoch 112/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.6065e-04 - val_loss: 0.0148\n",
      "Epoch 113/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 1.5968e-04 - val_loss: 0.0146\n",
      "Epoch 114/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 1.5872e-04 - val_loss: 0.0144\n",
      "Epoch 115/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 1.5778e-04 - val_loss: 0.0143\n",
      "Epoch 116/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 1.5686e-04 - val_loss: 0.0141\n",
      "Epoch 117/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 1.5594e-04 - val_loss: 0.0139\n",
      "Epoch 118/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 1.5504e-04 - val_loss: 0.0138\n",
      "Epoch 119/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 1.5414e-04 - val_loss: 0.0136\n",
      "Epoch 120/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.5326e-04 - val_loss: 0.0135\n",
      "Epoch 121/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.5238e-04 - val_loss: 0.0134\n",
      "Epoch 122/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.5150e-04 - val_loss: 0.0132\n",
      "Epoch 123/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.5063e-04 - val_loss: 0.0131\n",
      "Epoch 124/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 1.4976e-04 - val_loss: 0.0130\n",
      "Epoch 125/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 1.4890e-04 - val_loss: 0.0129\n",
      "Epoch 126/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 1.4803e-04 - val_loss: 0.0128\n",
      "Epoch 127/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 1.4717e-04 - val_loss: 0.0127\n",
      "Epoch 128/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 1.4632e-04 - val_loss: 0.0125\n",
      "Epoch 129/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.4546e-04 - val_loss: 0.0124\n",
      "Epoch 130/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 1.4460e-04 - val_loss: 0.0123\n",
      "Epoch 131/300\n",
      "1046/1046 [==============================] - 0s 17us/step - loss: 1.4375e-04 - val_loss: 0.0122\n",
      "Epoch 132/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 1.4289e-04 - val_loss: 0.0122\n",
      "Epoch 133/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.4204e-04 - val_loss: 0.0121\n",
      "Epoch 134/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.4118e-04 - val_loss: 0.0120\n",
      "Epoch 135/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.4033e-04 - val_loss: 0.0119\n",
      "Epoch 136/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3948e-04 - val_loss: 0.0118\n",
      "Epoch 137/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 1.3862e-04 - val_loss: 0.0117\n",
      "Epoch 138/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 1.3777e-04 - val_loss: 0.0116\n",
      "Epoch 139/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3691e-04 - val_loss: 0.0115\n",
      "Epoch 140/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3606e-04 - val_loss: 0.0114\n",
      "Epoch 141/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3520e-04 - val_loss: 0.0114\n",
      "Epoch 142/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3435e-04 - val_loss: 0.0113\n",
      "Epoch 143/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.3349e-04 - val_loss: 0.0112\n",
      "Epoch 144/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 1.3264e-04 - val_loss: 0.0111\n",
      "Epoch 145/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 1.3178e-04 - val_loss: 0.0110\n",
      "Epoch 146/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 1.3092e-04 - val_loss: 0.0110\n",
      "Epoch 147/300\n",
      "1046/1046 [==============================] - 0s 19us/step - loss: 1.3007e-04 - val_loss: 0.0109\n",
      "Epoch 148/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2921e-04 - val_loss: 0.0108\n",
      "Epoch 149/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2835e-04 - val_loss: 0.0107\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2749e-04 - val_loss: 0.0107\n",
      "Epoch 151/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.2664e-04 - val_loss: 0.0106\n",
      "Epoch 152/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 1.2578e-04 - val_loss: 0.0105\n",
      "Epoch 153/300\n",
      "1046/1046 [==============================] - 0s 20us/step - loss: 1.2492e-04 - val_loss: 0.0104\n",
      "Epoch 154/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2406e-04 - val_loss: 0.0104\n",
      "Epoch 155/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2320e-04 - val_loss: 0.0103\n",
      "Epoch 156/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 1.2234e-04 - val_loss: 0.0102\n",
      "Epoch 157/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 1.2149e-04 - val_loss: 0.0101\n",
      "Epoch 158/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.2063e-04 - val_loss: 0.0101\n",
      "Epoch 159/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1977e-04 - val_loss: 0.0100\n",
      "Epoch 160/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1891e-04 - val_loss: 0.0099\n",
      "Epoch 161/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1805e-04 - val_loss: 0.0099\n",
      "Epoch 162/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 1.1720e-04 - val_loss: 0.0098\n",
      "Epoch 163/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 1.1634e-04 - val_loss: 0.0097\n",
      "Epoch 164/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 1.1548e-04 - val_loss: 0.0097\n",
      "Epoch 165/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 1.1463e-04 - val_loss: 0.0096\n",
      "Epoch 166/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1377e-04 - val_loss: 0.0095\n",
      "Epoch 167/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1291e-04 - val_loss: 0.0094\n",
      "Epoch 168/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1206e-04 - val_loss: 0.0094\n",
      "Epoch 169/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.1121e-04 - val_loss: 0.0093\n",
      "Epoch 170/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 1.1035e-04 - val_loss: 0.0092\n",
      "Epoch 171/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0950e-04 - val_loss: 0.0092\n",
      "Epoch 172/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0865e-04 - val_loss: 0.0091\n",
      "Epoch 173/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0780e-04 - val_loss: 0.0090\n",
      "Epoch 174/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0695e-04 - val_loss: 0.0090\n",
      "Epoch 175/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0610e-04 - val_loss: 0.0089\n",
      "Epoch 176/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0526e-04 - val_loss: 0.0088\n",
      "Epoch 177/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0441e-04 - val_loss: 0.0088\n",
      "Epoch 178/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 1.0357e-04 - val_loss: 0.0087\n",
      "Epoch 179/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.0273e-04 - val_loss: 0.0086\n",
      "Epoch 180/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 1.0189e-04 - val_loss: 0.0086\n",
      "Epoch 181/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 1.0105e-04 - val_loss: 0.0085\n",
      "Epoch 182/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 1.0022e-04 - val_loss: 0.0084\n",
      "Epoch 183/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 9.9382e-05 - val_loss: 0.0084\n",
      "Epoch 184/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 9.8551e-05 - val_loss: 0.0083\n",
      "Epoch 185/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 9.7722e-05 - val_loss: 0.0083\n",
      "Epoch 186/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 9.6895e-05 - val_loss: 0.0082\n",
      "Epoch 187/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 9.6070e-05 - val_loss: 0.0081\n",
      "Epoch 188/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 9.5249e-05 - val_loss: 0.0081\n",
      "Epoch 189/300\n",
      "1046/1046 [==============================] - 0s 29us/step - loss: 9.4430e-05 - val_loss: 0.0080\n",
      "Epoch 190/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 9.3614e-05 - val_loss: 0.0079\n",
      "Epoch 191/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 9.2800e-05 - val_loss: 0.0079\n",
      "Epoch 192/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 9.1990e-05 - val_loss: 0.0078\n",
      "Epoch 193/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 9.1183e-05 - val_loss: 0.0078\n",
      "Epoch 194/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 9.0379e-05 - val_loss: 0.0077\n",
      "Epoch 195/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 8.9579e-05 - val_loss: 0.0076\n",
      "Epoch 196/300\n",
      "1046/1046 [==============================] - 0s 26us/step - loss: 8.8782e-05 - val_loss: 0.0076\n",
      "Epoch 197/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.7989e-05 - val_loss: 0.0075\n",
      "Epoch 198/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 8.7200e-05 - val_loss: 0.0075\n",
      "Epoch 199/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 8.6414e-05 - val_loss: 0.0074\n",
      "Epoch 200/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 8.5633e-05 - val_loss: 0.0074\n",
      "Epoch 201/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 8.4856e-05 - val_loss: 0.0073\n",
      "Epoch 202/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 8.4082e-05 - val_loss: 0.0072\n",
      "Epoch 203/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 8.3313e-05 - val_loss: 0.0072\n",
      "Epoch 204/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 8.2549e-05 - val_loss: 0.0071\n",
      "Epoch 205/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 8.1789e-05 - val_loss: 0.0071\n",
      "Epoch 206/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 8.1034e-05 - val_loss: 0.0070\n",
      "Epoch 207/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 8.0283e-05 - val_loss: 0.0070\n",
      "Epoch 208/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 7.9538e-05 - val_loss: 0.0069\n",
      "Epoch 209/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 7.8797e-05 - val_loss: 0.0069\n",
      "Epoch 210/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 7.8061e-05 - val_loss: 0.0068\n",
      "Epoch 211/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 7.7331e-05 - val_loss: 0.0068\n",
      "Epoch 212/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 7.6605e-05 - val_loss: 0.0067\n",
      "Epoch 213/300\n",
      "1046/1046 [==============================] - 0s 15us/step - loss: 7.5885e-05 - val_loss: 0.0067\n",
      "Epoch 214/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.5171e-05 - val_loss: 0.0066\n",
      "Epoch 215/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.4462e-05 - val_loss: 0.0066\n",
      "Epoch 216/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.3758e-05 - val_loss: 0.0065\n",
      "Epoch 217/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.3061e-05 - val_loss: 0.0065\n",
      "Epoch 218/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.2369e-05 - val_loss: 0.0064\n",
      "Epoch 219/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.1683e-05 - val_loss: 0.0064\n",
      "Epoch 220/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.1003e-05 - val_loss: 0.0063\n",
      "Epoch 221/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 7.0328e-05 - val_loss: 0.0063\n",
      "Epoch 222/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.9660e-05 - val_loss: 0.0062\n",
      "Epoch 223/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 6.8998e-05 - val_loss: 0.0062\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 34us/step - loss: 6.8342e-05 - val_loss: 0.0061\n",
      "Epoch 225/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 6.7692e-05 - val_loss: 0.0061\n",
      "Epoch 226/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 6.7049e-05 - val_loss: 0.0060\n",
      "Epoch 227/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 6.6412e-05 - val_loss: 0.0060\n",
      "Epoch 228/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 6.5781e-05 - val_loss: 0.0060\n",
      "Epoch 229/300\n",
      "1046/1046 [==============================] - 0s 21us/step - loss: 6.5156e-05 - val_loss: 0.0059\n",
      "Epoch 230/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 6.4538e-05 - val_loss: 0.0059\n",
      "Epoch 231/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.3926e-05 - val_loss: 0.0058\n",
      "Epoch 232/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 6.3321e-05 - val_loss: 0.0058\n",
      "Epoch 233/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 6.2722e-05 - val_loss: 0.0057\n",
      "Epoch 234/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 6.2130e-05 - val_loss: 0.0057\n",
      "Epoch 235/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 6.1544e-05 - val_loss: 0.0057\n",
      "Epoch 236/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 6.0965e-05 - val_loss: 0.0056\n",
      "Epoch 237/300\n",
      "1046/1046 [==============================] - 0s 23us/step - loss: 6.0392e-05 - val_loss: 0.0056\n",
      "Epoch 238/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.9826e-05 - val_loss: 0.0056\n",
      "Epoch 239/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 5.9266e-05 - val_loss: 0.0055\n",
      "Epoch 240/300\n",
      "1046/1046 [==============================] - 0s 31us/step - loss: 5.8713e-05 - val_loss: 0.0055\n",
      "Epoch 241/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 5.8166e-05 - val_loss: 0.0055\n",
      "Epoch 242/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.7626e-05 - val_loss: 0.0054\n",
      "Epoch 243/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.7092e-05 - val_loss: 0.0054\n",
      "Epoch 244/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.6564e-05 - val_loss: 0.0054\n",
      "Epoch 245/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.6043e-05 - val_loss: 0.0053\n",
      "Epoch 246/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.5528e-05 - val_loss: 0.0053\n",
      "Epoch 247/300\n",
      "1046/1046 [==============================] - 0s 24us/step - loss: 5.5020e-05 - val_loss: 0.0053\n",
      "Epoch 248/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.4518e-05 - val_loss: 0.0052\n",
      "Epoch 249/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 5.4022e-05 - val_loss: 0.0052\n",
      "Epoch 250/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.3532e-05 - val_loss: 0.0052\n",
      "Epoch 251/300\n",
      "1046/1046 [==============================] - 0s 27us/step - loss: 5.3049e-05 - val_loss: 0.0051\n",
      "Epoch 252/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 5.2571e-05 - val_loss: 0.0051\n",
      "Epoch 253/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 5.2100e-05 - val_loss: 0.0051\n",
      "Epoch 254/300\n",
      "1046/1046 [==============================] - 0s 22us/step - loss: 5.1634e-05 - val_loss: 0.0051\n",
      "Epoch 255/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.1175e-05 - val_loss: 0.0050\n",
      "Epoch 256/300\n",
      "1046/1046 [==============================] - 0s 30us/step - loss: 5.0721e-05 - val_loss: 0.0050\n",
      "Epoch 257/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 5.0274e-05 - val_loss: 0.0050\n",
      "Epoch 258/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 4.9832e-05 - val_loss: 0.0050\n",
      "Epoch 259/300\n",
      "1046/1046 [==============================] - 0s 58us/step - loss: 4.9395e-05 - val_loss: 0.0049\n",
      "Epoch 260/300\n",
      "1046/1046 [==============================] - 0s 63us/step - loss: 4.8964e-05 - val_loss: 0.0049\n",
      "Epoch 261/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 4.8539e-05 - val_loss: 0.0049\n",
      "Epoch 262/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 4.8120e-05 - val_loss: 0.0049\n",
      "Epoch 263/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.7705e-05 - val_loss: 0.0048\n",
      "Epoch 264/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.7296e-05 - val_loss: 0.0048\n",
      "Epoch 265/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 4.6893e-05 - val_loss: 0.0048\n",
      "Epoch 266/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 4.6494e-05 - val_loss: 0.0048\n",
      "Epoch 267/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 4.6101e-05 - val_loss: 0.0048\n",
      "Epoch 268/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 4.5712e-05 - val_loss: 0.0047\n",
      "Epoch 269/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 4.5329e-05 - val_loss: 0.0047\n",
      "Epoch 270/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.4951e-05 - val_loss: 0.0047\n",
      "Epoch 271/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 4.4577e-05 - val_loss: 0.0047\n",
      "Epoch 272/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.4208e-05 - val_loss: 0.0047\n",
      "Epoch 273/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.3843e-05 - val_loss: 0.0047\n",
      "Epoch 274/300\n",
      "1046/1046 [==============================] - 0s 50us/step - loss: 4.3484e-05 - val_loss: 0.0046\n",
      "Epoch 275/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 4.3128e-05 - val_loss: 0.0046\n",
      "Epoch 276/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 4.2777e-05 - val_loss: 0.0046\n",
      "Epoch 277/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.2431e-05 - val_loss: 0.0046\n",
      "Epoch 278/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 4.2088e-05 - val_loss: 0.0046\n",
      "Epoch 279/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 4.1750e-05 - val_loss: 0.0046\n",
      "Epoch 280/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 4.1416e-05 - val_loss: 0.0046\n",
      "Epoch 281/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 4.1086e-05 - val_loss: 0.0046\n",
      "Epoch 282/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 4.0760e-05 - val_loss: 0.0046\n",
      "Epoch 283/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 4.0437e-05 - val_loss: 0.0045\n",
      "Epoch 284/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 4.0119e-05 - val_loss: 0.0045\n",
      "Epoch 285/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 3.9804e-05 - val_loss: 0.0045\n",
      "Epoch 286/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 3.9493e-05 - val_loss: 0.0045\n",
      "Epoch 287/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 3.9185e-05 - val_loss: 0.0045\n",
      "Epoch 288/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 3.8881e-05 - val_loss: 0.0045\n",
      "Epoch 289/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 3.8581e-05 - val_loss: 0.0045\n",
      "Epoch 290/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 3.8284e-05 - val_loss: 0.0045\n",
      "Epoch 291/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.7990e-05 - val_loss: 0.0045\n",
      "Epoch 292/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 3.7699e-05 - val_loss: 0.0045\n",
      "Epoch 293/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 3.7411e-05 - val_loss: 0.0045\n",
      "Epoch 294/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 3.7127e-05 - val_loss: 0.0045\n",
      "Epoch 295/300\n",
      "1046/1046 [==============================] - ETA: 0s - loss: 3.1855e-0 - 0s 59us/step - loss: 3.6845e-05 - val_loss: 0.0045\n",
      "Epoch 296/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.6567e-05 - val_loss: 0.0045\n",
      "Epoch 297/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.6291e-05 - val_loss: 0.0045\n",
      "Epoch 298/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.6019e-05 - val_loss: 0.0045\n",
      "Epoch 299/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.5749e-05 - val_loss: 0.0045\n",
      "Epoch 300/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.5482e-05 - val_loss: 0.0045\n",
      "Entrenamiento f1 completo.\n",
      "[[0.37746647]\n",
      " [0.36400416]\n",
      " [0.37036583]\n",
      " [0.35992137]\n",
      " [0.3653466 ]\n",
      " [0.35565424]\n",
      " [0.3299291 ]\n",
      " [0.28611788]\n",
      " [0.2976096 ]\n",
      " [0.2751657 ]\n",
      " [0.2599098 ]\n",
      " [0.25756517]\n",
      " [0.23863873]\n",
      " [0.23738907]\n",
      " [0.24271452]\n",
      " [0.2468924 ]\n",
      " [0.3021543 ]\n",
      " [0.2718738 ]\n",
      " [0.2840301 ]\n",
      " [0.26164946]\n",
      " [0.27296773]\n",
      " [0.26179245]\n",
      " [0.2682556 ]\n",
      " [0.26971996]\n",
      " [0.27041572]\n",
      " [0.26568106]\n",
      " [0.28022772]\n",
      " [0.29583308]\n",
      " [0.29490533]\n",
      " [0.28847462]]\n",
      "30\n",
      "Simulación f1 completa.\n",
      "Train on 1045 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1045/1045 [==============================] - 2s 2ms/step - loss: 7.9591e-04 - val_loss: 0.0669\n",
      "Epoch 2/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 6.6606e-04 - val_loss: 0.0641\n",
      "Epoch 3/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 6.2528e-04 - val_loss: 0.0619\n",
      "Epoch 4/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 6.3040e-04 - val_loss: 0.0605\n",
      "Epoch 5/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 6.4120e-04 - val_loss: 0.0596\n",
      "Epoch 6/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.4261e-04 - val_loss: 0.0589\n",
      "Epoch 7/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.3536e-04 - val_loss: 0.0585\n",
      "Epoch 8/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.2402e-04 - val_loss: 0.0580\n",
      "Epoch 9/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.1191e-04 - val_loss: 0.0575\n",
      "Epoch 10/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0048e-04 - val_loss: 0.0569\n",
      "Epoch 11/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.9006e-04 - val_loss: 0.0563\n",
      "Epoch 12/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.8049e-04 - val_loss: 0.0556\n",
      "Epoch 13/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.7150e-04 - val_loss: 0.0549\n",
      "Epoch 14/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.6282e-04 - val_loss: 0.0542\n",
      "Epoch 15/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.5428e-04 - val_loss: 0.0535\n",
      "Epoch 16/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.4580e-04 - val_loss: 0.0528\n",
      "Epoch 17/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 5.3735e-04 - val_loss: 0.0520\n",
      "Epoch 18/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 5.2894e-04 - val_loss: 0.0513\n",
      "Epoch 19/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 5.2057e-04 - val_loss: 0.0505\n",
      "Epoch 20/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 5.1226e-04 - val_loss: 0.0497\n",
      "Epoch 21/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.0402e-04 - val_loss: 0.0489\n",
      "Epoch 22/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.9586e-04 - val_loss: 0.0480\n",
      "Epoch 23/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.8777e-04 - val_loss: 0.0472\n",
      "Epoch 24/300\n",
      "1045/1045 [==============================] - 0s 52us/step - loss: 4.7977e-04 - val_loss: 0.0463\n",
      "Epoch 25/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.7186e-04 - val_loss: 0.0455\n",
      "Epoch 26/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.6404e-04 - val_loss: 0.0446\n",
      "Epoch 27/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.5632e-04 - val_loss: 0.0438\n",
      "Epoch 28/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 4.4871e-04 - val_loss: 0.0429\n",
      "Epoch 29/300\n",
      "1045/1045 [==============================] - 0s 19us/step - loss: 4.4122e-04 - val_loss: 0.0420\n",
      "Epoch 30/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.3386e-04 - val_loss: 0.0412\n",
      "Epoch 31/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.2663e-04 - val_loss: 0.0403\n",
      "Epoch 32/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 4.1954e-04 - val_loss: 0.0394\n",
      "Epoch 33/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.1261e-04 - val_loss: 0.0386\n",
      "Epoch 34/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 4.0583e-04 - val_loss: 0.0378\n",
      "Epoch 35/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.9922e-04 - val_loss: 0.0369\n",
      "Epoch 36/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.9278e-04 - val_loss: 0.0361\n",
      "Epoch 37/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 3.8651e-04 - val_loss: 0.0353\n",
      "Epoch 38/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 3.8042e-04 - val_loss: 0.0345\n",
      "Epoch 39/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.7451e-04 - val_loss: 0.0338\n",
      "Epoch 40/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.6878e-04 - val_loss: 0.0330\n",
      "Epoch 41/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.6323e-04 - val_loss: 0.0323\n",
      "Epoch 42/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 3.5786e-04 - val_loss: 0.0316\n",
      "Epoch 43/300\n",
      "1045/1045 [==============================] - 0s 52us/step - loss: 3.5266e-04 - val_loss: 0.0309\n",
      "Epoch 44/300\n",
      "1045/1045 [==============================] - 0s 50us/step - loss: 3.4763e-04 - val_loss: 0.0303\n",
      "Epoch 45/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 3.4277e-04 - val_loss: 0.0297\n",
      "Epoch 46/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.3807e-04 - val_loss: 0.0291\n",
      "Epoch 47/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.3352e-04 - val_loss: 0.0285\n",
      "Epoch 48/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 3.2912e-04 - val_loss: 0.0280\n",
      "Epoch 49/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2485e-04 - val_loss: 0.0275\n",
      "Epoch 50/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.2072e-04 - val_loss: 0.0270\n",
      "Epoch 51/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1671e-04 - val_loss: 0.0265\n",
      "Epoch 52/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.1281e-04 - val_loss: 0.0261\n",
      "Epoch 53/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 3.0901e-04 - val_loss: 0.0257\n",
      "Epoch 54/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 3.0531e-04 - val_loss: 0.0253\n",
      "Epoch 55/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 3.0171e-04 - val_loss: 0.0249\n",
      "Epoch 56/300\n",
      "1045/1045 [==============================] - 0s 28us/step - loss: 2.9818e-04 - val_loss: 0.0246\n",
      "Epoch 57/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.9473e-04 - val_loss: 0.0243\n",
      "Epoch 58/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.9136e-04 - val_loss: 0.0240\n",
      "Epoch 59/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 2.8805e-04 - val_loss: 0.0237\n",
      "Epoch 60/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.8480e-04 - val_loss: 0.0234\n",
      "Epoch 61/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 2.8160e-04 - val_loss: 0.0232\n",
      "Epoch 62/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.7846e-04 - val_loss: 0.0229\n",
      "Epoch 63/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 2.7537e-04 - val_loss: 0.0227\n",
      "Epoch 64/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 2.7233e-04 - val_loss: 0.0225\n",
      "Epoch 65/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 2.6933e-04 - val_loss: 0.0223\n",
      "Epoch 66/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6637e-04 - val_loss: 0.0221\n",
      "Epoch 67/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.6345e-04 - val_loss: 0.0219\n",
      "Epoch 68/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 57us/step - loss: 2.6057e-04 - val_loss: 0.0218\n",
      "Epoch 69/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 2.5773e-04 - val_loss: 0.0216\n",
      "Epoch 70/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 2.5492e-04 - val_loss: 0.0214\n",
      "Epoch 71/300\n",
      "1045/1045 [==============================] - 0s 19us/step - loss: 2.5216e-04 - val_loss: 0.0213\n",
      "Epoch 72/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.4942e-04 - val_loss: 0.0211\n",
      "Epoch 73/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.4672e-04 - val_loss: 0.0210\n",
      "Epoch 74/300\n",
      "1045/1045 [==============================] - 0s 46us/step - loss: 2.4405e-04 - val_loss: 0.0209\n",
      "Epoch 75/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4142e-04 - val_loss: 0.0207\n",
      "Epoch 76/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 2.3882e-04 - val_loss: 0.0206\n",
      "Epoch 77/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.3625e-04 - val_loss: 0.0205\n",
      "Epoch 78/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.3371e-04 - val_loss: 0.0203\n",
      "Epoch 79/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 2.3120e-04 - val_loss: 0.0202\n",
      "Epoch 80/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.2873e-04 - val_loss: 0.0201\n",
      "Epoch 81/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.2629e-04 - val_loss: 0.0200\n",
      "Epoch 82/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.2388e-04 - val_loss: 0.0199\n",
      "Epoch 83/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.2150e-04 - val_loss: 0.0198\n",
      "Epoch 84/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 2.1914e-04 - val_loss: 0.0197\n",
      "Epoch 85/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.1683e-04 - val_loss: 0.0195\n",
      "Epoch 86/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.1454e-04 - val_loss: 0.0194\n",
      "Epoch 87/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.1228e-04 - val_loss: 0.0193\n",
      "Epoch 88/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 2.1005e-04 - val_loss: 0.0192\n",
      "Epoch 89/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.0785e-04 - val_loss: 0.0191\n",
      "Epoch 90/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 2.0568e-04 - val_loss: 0.0190\n",
      "Epoch 91/300\n",
      "1045/1045 [==============================] - 0s 23us/step - loss: 2.0353e-04 - val_loss: 0.0189\n",
      "Epoch 92/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 2.0142e-04 - val_loss: 0.0188\n",
      "Epoch 93/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.9934e-04 - val_loss: 0.0187\n",
      "Epoch 94/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.9728e-04 - val_loss: 0.0186\n",
      "Epoch 95/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.9526e-04 - val_loss: 0.0185\n",
      "Epoch 96/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.9326e-04 - val_loss: 0.0184\n",
      "Epoch 97/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 1.9129e-04 - val_loss: 0.0183\n",
      "Epoch 98/300\n",
      "1045/1045 [==============================] - 0s 52us/step - loss: 1.8934e-04 - val_loss: 0.0182\n",
      "Epoch 99/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 1.8742e-04 - val_loss: 0.0181\n",
      "Epoch 100/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 1.8553e-04 - val_loss: 0.0181\n",
      "Epoch 101/300\n",
      "1045/1045 [==============================] - 0s 49us/step - loss: 1.8367e-04 - val_loss: 0.0180\n",
      "Epoch 102/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 1.8183e-04 - val_loss: 0.0179\n",
      "Epoch 103/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 1.8001e-04 - val_loss: 0.0178\n",
      "Epoch 104/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 1.7822e-04 - val_loss: 0.0177\n",
      "Epoch 105/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 1.7646e-04 - val_loss: 0.0176\n",
      "Epoch 106/300\n",
      "1045/1045 [==============================] - 0s 48us/step - loss: 1.7472e-04 - val_loss: 0.0175\n",
      "Epoch 107/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 1.7300e-04 - val_loss: 0.0174\n",
      "Epoch 108/300\n",
      "1045/1045 [==============================] - 0s 48us/step - loss: 1.7131e-04 - val_loss: 0.0173\n",
      "Epoch 109/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 1.6964e-04 - val_loss: 0.0173\n",
      "Epoch 110/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 1.6799e-04 - val_loss: 0.0172\n",
      "Epoch 111/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 1.6637e-04 - val_loss: 0.0171\n",
      "Epoch 112/300\n",
      "1045/1045 [==============================] - 0s 46us/step - loss: 1.6476e-04 - val_loss: 0.0170\n",
      "Epoch 113/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 1.6318e-04 - val_loss: 0.0169\n",
      "Epoch 114/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.6162e-04 - val_loss: 0.0168\n",
      "Epoch 115/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.6008e-04 - val_loss: 0.0168\n",
      "Epoch 116/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.5856e-04 - val_loss: 0.0167\n",
      "Epoch 117/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 1.5706e-04 - val_loss: 0.0166\n",
      "Epoch 118/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 1.5557e-04 - val_loss: 0.0165\n",
      "Epoch 119/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.5411e-04 - val_loss: 0.0164\n",
      "Epoch 120/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.5267e-04 - val_loss: 0.0164\n",
      "Epoch 121/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.5124e-04 - val_loss: 0.0163\n",
      "Epoch 122/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4983e-04 - val_loss: 0.0162\n",
      "Epoch 123/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 1.4844e-04 - val_loss: 0.0161\n",
      "Epoch 124/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4707e-04 - val_loss: 0.0161\n",
      "Epoch 125/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4571e-04 - val_loss: 0.0160\n",
      "Epoch 126/300\n",
      "1045/1045 [==============================] - 0s 48us/step - loss: 1.4437e-04 - val_loss: 0.0159\n",
      "Epoch 127/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4305e-04 - val_loss: 0.0158\n",
      "Epoch 128/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4174e-04 - val_loss: 0.0158\n",
      "Epoch 129/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.4045e-04 - val_loss: 0.0157\n",
      "Epoch 130/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.3917e-04 - val_loss: 0.0156\n",
      "Epoch 131/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.3791e-04 - val_loss: 0.0156\n",
      "Epoch 132/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 1.3666e-04 - val_loss: 0.0155\n",
      "Epoch 133/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.3543e-04 - val_loss: 0.0154\n",
      "Epoch 134/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 1.3421e-04 - val_loss: 0.0154\n",
      "Epoch 135/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 1.3301e-04 - val_loss: 0.0153\n",
      "Epoch 136/300\n",
      "1045/1045 [==============================] - 0s 20us/step - loss: 1.3181e-04 - val_loss: 0.0152\n",
      "Epoch 137/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.3064e-04 - val_loss: 0.0152\n",
      "Epoch 138/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.2947e-04 - val_loss: 0.0151\n",
      "Epoch 139/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.2832e-04 - val_loss: 0.0150\n",
      "Epoch 140/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 1.2718e-04 - val_loss: 0.0150\n",
      "Epoch 141/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 1.2605e-04 - val_loss: 0.0149\n",
      "Epoch 142/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 1.2493e-04 - val_loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 1.2383e-04 - val_loss: 0.0148\n",
      "Epoch 144/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 1.2273e-04 - val_loss: 0.0147\n",
      "Epoch 145/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 1.2165e-04 - val_loss: 0.0147\n",
      "Epoch 146/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 1.2058e-04 - val_loss: 0.0146\n",
      "Epoch 147/300\n",
      "1045/1045 [==============================] - 0s 46us/step - loss: 1.1952e-04 - val_loss: 0.0146\n",
      "Epoch 148/300\n",
      "1045/1045 [==============================] - 0s 54us/step - loss: 1.1847e-04 - val_loss: 0.0145\n",
      "Epoch 149/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 1.1744e-04 - val_loss: 0.0145\n",
      "Epoch 150/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 1.1641e-04 - val_loss: 0.0144\n",
      "Epoch 151/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.1539e-04 - val_loss: 0.0143\n",
      "Epoch 152/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 1.1438e-04 - val_loss: 0.0143\n",
      "Epoch 153/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 1.1339e-04 - val_loss: 0.0142\n",
      "Epoch 154/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 1.1240e-04 - val_loss: 0.0142\n",
      "Epoch 155/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 1.1142e-04 - val_loss: 0.0141\n",
      "Epoch 156/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.1045e-04 - val_loss: 0.0141\n",
      "Epoch 157/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0949e-04 - val_loss: 0.0140\n",
      "Epoch 158/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 1.0854e-04 - val_loss: 0.0140\n",
      "Epoch 159/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 1.0760e-04 - val_loss: 0.0139\n",
      "Epoch 160/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 1.0667e-04 - val_loss: 0.0139\n",
      "Epoch 161/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0575e-04 - val_loss: 0.0138\n",
      "Epoch 162/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0483e-04 - val_loss: 0.0138\n",
      "Epoch 163/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0393e-04 - val_loss: 0.0138\n",
      "Epoch 164/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0303e-04 - val_loss: 0.0137\n",
      "Epoch 165/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 1.0214e-04 - val_loss: 0.0137\n",
      "Epoch 166/300\n",
      "1045/1045 [==============================] - 0s 49us/step - loss: 1.0126e-04 - val_loss: 0.0136\n",
      "Epoch 167/300\n",
      "1045/1045 [==============================] - 0s 54us/step - loss: 1.0039e-04 - val_loss: 0.0136\n",
      "Epoch 168/300\n",
      "1045/1045 [==============================] - 0s 27us/step - loss: 9.9524e-05 - val_loss: 0.0135\n",
      "Epoch 169/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.8668e-05 - val_loss: 0.0135\n",
      "Epoch 170/300\n",
      "1045/1045 [==============================] - 0s 26us/step - loss: 9.7819e-05 - val_loss: 0.0135\n",
      "Epoch 171/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.6979e-05 - val_loss: 0.0134\n",
      "Epoch 172/300\n",
      "1045/1045 [==============================] - 0s 49us/step - loss: 9.6146e-05 - val_loss: 0.0134\n",
      "Epoch 173/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 9.5321e-05 - val_loss: 0.0134\n",
      "Epoch 174/300\n",
      "1045/1045 [==============================] - 0s 20us/step - loss: 9.4503e-05 - val_loss: 0.0133\n",
      "Epoch 175/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.3693e-05 - val_loss: 0.0133\n",
      "Epoch 176/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.2890e-05 - val_loss: 0.0132\n",
      "Epoch 177/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.2095e-05 - val_loss: 0.0132\n",
      "Epoch 178/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.1307e-05 - val_loss: 0.0132\n",
      "Epoch 179/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 9.0526e-05 - val_loss: 0.0131\n",
      "Epoch 180/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 8.9752e-05 - val_loss: 0.0131\n",
      "Epoch 181/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.8986e-05 - val_loss: 0.0131\n",
      "Epoch 182/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.8226e-05 - val_loss: 0.0131\n",
      "Epoch 183/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.7474e-05 - val_loss: 0.0130\n",
      "Epoch 184/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.6728e-05 - val_loss: 0.0130\n",
      "Epoch 185/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.5989e-05 - val_loss: 0.0130\n",
      "Epoch 186/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.5257e-05 - val_loss: 0.0129\n",
      "Epoch 187/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 8.4532e-05 - val_loss: 0.0129\n",
      "Epoch 188/300\n",
      "1045/1045 [==============================] - 0s 28us/step - loss: 8.3813e-05 - val_loss: 0.0129\n",
      "Epoch 189/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.3101e-05 - val_loss: 0.0129\n",
      "Epoch 190/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.2396e-05 - val_loss: 0.0128\n",
      "Epoch 191/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.1697e-05 - val_loss: 0.0128\n",
      "Epoch 192/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.1005e-05 - val_loss: 0.0128\n",
      "Epoch 193/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 8.0319e-05 - val_loss: 0.0128\n",
      "Epoch 194/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 7.9640e-05 - val_loss: 0.0127\n",
      "Epoch 195/300\n",
      "1045/1045 [==============================] - 0s 20us/step - loss: 7.8967e-05 - val_loss: 0.0127\n",
      "Epoch 196/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 7.8300e-05 - val_loss: 0.0127\n",
      "Epoch 197/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.7639e-05 - val_loss: 0.0127\n",
      "Epoch 198/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.6985e-05 - val_loss: 0.0127\n",
      "Epoch 199/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.6337e-05 - val_loss: 0.0126\n",
      "Epoch 200/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.5695e-05 - val_loss: 0.0126\n",
      "Epoch 201/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.5058e-05 - val_loss: 0.0126\n",
      "Epoch 202/300\n",
      "1045/1045 [==============================] - 0s 29us/step - loss: 7.4428e-05 - val_loss: 0.0126\n",
      "Epoch 203/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.3804e-05 - val_loss: 0.0126\n",
      "Epoch 204/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.3186e-05 - val_loss: 0.0126\n",
      "Epoch 205/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.2574e-05 - val_loss: 0.0125\n",
      "Epoch 206/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.1968e-05 - val_loss: 0.0125\n",
      "Epoch 207/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.1367e-05 - val_loss: 0.0125\n",
      "Epoch 208/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 7.0772e-05 - val_loss: 0.0125\n",
      "Epoch 209/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 7.0183e-05 - val_loss: 0.0125\n",
      "Epoch 210/300\n",
      "1045/1045 [==============================] - 0s 24us/step - loss: 6.9599e-05 - val_loss: 0.0125\n",
      "Epoch 211/300\n",
      "1045/1045 [==============================] - ETA: 0s - loss: 6.4449e-0 - 0s 30us/step - loss: 6.9021e-05 - val_loss: 0.0125\n",
      "Epoch 212/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.8449e-05 - val_loss: 0.0124\n",
      "Epoch 213/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.7882e-05 - val_loss: 0.0124\n",
      "Epoch 214/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.7320e-05 - val_loss: 0.0124\n",
      "Epoch 215/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.6764e-05 - val_loss: 0.0124\n",
      "Epoch 216/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 6.6214e-05 - val_loss: 0.0124\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - 0s 33us/step - loss: 6.5668e-05 - val_loss: 0.0124\n",
      "Epoch 218/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.5128e-05 - val_loss: 0.0124\n",
      "Epoch 219/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.4594e-05 - val_loss: 0.0124\n",
      "Epoch 220/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.4064e-05 - val_loss: 0.0124\n",
      "Epoch 221/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.3539e-05 - val_loss: 0.0124\n",
      "Epoch 222/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.3020e-05 - val_loss: 0.0124\n",
      "Epoch 223/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 6.2506e-05 - val_loss: 0.0124\n",
      "Epoch 224/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 6.1996e-05 - val_loss: 0.0124\n",
      "Epoch 225/300\n",
      "1045/1045 [==============================] - 0s 22us/step - loss: 6.1492e-05 - val_loss: 0.0123\n",
      "Epoch 226/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0992e-05 - val_loss: 0.0123\n",
      "Epoch 227/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0498e-05 - val_loss: 0.0123\n",
      "Epoch 228/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 6.0008e-05 - val_loss: 0.0123\n",
      "Epoch 229/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.9523e-05 - val_loss: 0.0123\n",
      "Epoch 230/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.9042e-05 - val_loss: 0.0123\n",
      "Epoch 231/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 5.8566e-05 - val_loss: 0.0123\n",
      "Epoch 232/300\n",
      "1045/1045 [==============================] - 0s 19us/step - loss: 5.8095e-05 - val_loss: 0.0123\n",
      "Epoch 233/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.7629e-05 - val_loss: 0.0123\n",
      "Epoch 234/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.7166e-05 - val_loss: 0.0123\n",
      "Epoch 235/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.6709e-05 - val_loss: 0.0123\n",
      "Epoch 236/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.6256e-05 - val_loss: 0.0123\n",
      "Epoch 237/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.5807e-05 - val_loss: 0.0123\n",
      "Epoch 238/300\n",
      "1045/1045 [==============================] - 0s 51us/step - loss: 5.5362e-05 - val_loss: 0.0123\n",
      "Epoch 239/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 5.4922e-05 - val_loss: 0.0123\n",
      "Epoch 240/300\n",
      "1045/1045 [==============================] - 0s 27us/step - loss: 5.4486e-05 - val_loss: 0.0123\n",
      "Epoch 241/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.4054e-05 - val_loss: 0.0123\n",
      "Epoch 242/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.3626e-05 - val_loss: 0.0123\n",
      "Epoch 243/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 5.3202e-05 - val_loss: 0.0123\n",
      "Epoch 244/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 5.2782e-05 - val_loss: 0.0123\n",
      "Epoch 245/300\n",
      "1045/1045 [==============================] - 0s 31us/step - loss: 5.2367e-05 - val_loss: 0.0123\n",
      "Epoch 246/300\n",
      "1045/1045 [==============================] - 0s 30us/step - loss: 5.1955e-05 - val_loss: 0.0123\n",
      "Epoch 00246: early stopping\n",
      "Entrenamiento f2 completo.\n",
      "[[0.3538152 ]\n",
      " [0.3575969 ]\n",
      " [0.34673533]\n",
      " [0.35259086]\n",
      " [0.34363183]\n",
      " [0.34815624]\n",
      " [0.34015876]\n",
      " [0.3177849 ]\n",
      " [0.27907005]\n",
      " [0.28887272]\n",
      " [0.26909968]\n",
      " [0.25538486]\n",
      " [0.25326312]\n",
      " [0.23596235]\n",
      " [0.23523887]\n",
      " [0.23981042]\n",
      " [0.24315804]\n",
      " [0.2928697 ]\n",
      " [0.26598492]\n",
      " [0.27691388]\n",
      " [0.2565289 ]\n",
      " [0.26659477]\n",
      " [0.25635794]\n",
      " [0.26242244]\n",
      " [0.26388967]\n",
      " [0.26450327]\n",
      " [0.26019883]\n",
      " [0.27348953]\n",
      " [0.28780705]\n",
      " [0.28740785]]\n",
      "30\n",
      "Simulación f2 completa.\n",
      "Train on 1044 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.1676\n",
      "Epoch 2/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0026 - val_loss: 0.1602\n",
      "Epoch 3/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 0.0024 - val_loss: 0.1536\n",
      "Epoch 4/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.1478\n",
      "Epoch 5/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.1429\n",
      "Epoch 6/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0022 - val_loss: 0.1387\n",
      "Epoch 7/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0022 - val_loss: 0.1352\n",
      "Epoch 8/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.1322\n",
      "Epoch 9/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.1296\n",
      "Epoch 10/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 0.0021 - val_loss: 0.1272\n",
      "Epoch 11/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 0.0021 - val_loss: 0.1250\n",
      "Epoch 12/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.1231\n",
      "Epoch 13/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.1212\n",
      "Epoch 14/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0020 - val_loss: 0.1195\n",
      "Epoch 15/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0019 - val_loss: 0.1178\n",
      "Epoch 16/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0019 - val_loss: 0.1163\n",
      "Epoch 17/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.1148\n",
      "Epoch 18/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.1133\n",
      "Epoch 19/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.1119\n",
      "Epoch 20/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.1106\n",
      "Epoch 21/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0017 - val_loss: 0.1093\n",
      "Epoch 22/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.1080\n",
      "Epoch 23/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.1068\n",
      "Epoch 24/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 0.0016 - val_loss: 0.1056\n",
      "Epoch 25/300\n",
      "1044/1044 [==============================] - 0s 57us/step - loss: 0.0016 - val_loss: 0.1044\n",
      "Epoch 26/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 0.0016 - val_loss: 0.1033\n",
      "Epoch 27/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0016 - val_loss: 0.1023\n",
      "Epoch 28/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 0.0015 - val_loss: 0.1012\n",
      "Epoch 29/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 0.0015 - val_loss: 0.1002\n",
      "Epoch 30/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 0.0992\n",
      "Epoch 31/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 0.0015 - val_loss: 0.0983\n",
      "Epoch 32/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 0.0014 - val_loss: 0.0974\n",
      "Epoch 33/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 0.0014 - val_loss: 0.0965\n",
      "Epoch 34/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0014 - val_loss: 0.0956\n",
      "Epoch 35/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 0.0947\n",
      "Epoch 36/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 0.0939\n",
      "Epoch 37/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0013 - val_loss: 0.0931\n",
      "Epoch 38/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 0.0924\n",
      "Epoch 39/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0013 - val_loss: 0.0916\n",
      "Epoch 40/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 0.0909\n",
      "Epoch 41/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 0.0902\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 0.0895\n",
      "Epoch 43/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 0.0888\n",
      "Epoch 44/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0012 - val_loss: 0.0882\n",
      "Epoch 45/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 0.0875\n",
      "Epoch 46/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 0.0012 - val_loss: 0.0869\n",
      "Epoch 47/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 0.0011 - val_loss: 0.0863\n",
      "Epoch 48/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0011 - val_loss: 0.0857\n",
      "Epoch 49/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 0.0011 - val_loss: 0.0852\n",
      "Epoch 50/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 0.0011 - val_loss: 0.0846\n",
      "Epoch 51/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 0.0011 - val_loss: 0.0841\n",
      "Epoch 52/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0011 - val_loss: 0.0835\n",
      "Epoch 53/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0011 - val_loss: 0.0830\n",
      "Epoch 54/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0011 - val_loss: 0.0825\n",
      "Epoch 55/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 0.0010 - val_loss: 0.0820\n",
      "Epoch 56/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 0.0010 - val_loss: 0.0815\n",
      "Epoch 57/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 0.0010 - val_loss: 0.0811\n",
      "Epoch 58/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 0.0010 - val_loss: 0.0806\n",
      "Epoch 59/300\n",
      "1044/1044 [==============================] - 0s 53us/step - loss: 9.9372e-04 - val_loss: 0.0802\n",
      "Epoch 60/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 9.8257e-04 - val_loss: 0.0797\n",
      "Epoch 61/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 9.7167e-04 - val_loss: 0.0793\n",
      "Epoch 62/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 9.6099e-04 - val_loss: 0.0789\n",
      "Epoch 63/300\n",
      "1044/1044 [==============================] - 0s 61us/step - loss: 9.5054e-04 - val_loss: 0.0785\n",
      "Epoch 64/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 9.4031e-04 - val_loss: 0.0781\n",
      "Epoch 65/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 9.3029e-04 - val_loss: 0.0777\n",
      "Epoch 66/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 9.2046e-04 - val_loss: 0.0773\n",
      "Epoch 67/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 9.1083e-04 - val_loss: 0.0769\n",
      "Epoch 68/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.0139e-04 - val_loss: 0.0765\n",
      "Epoch 69/300\n",
      "1044/1044 [==============================] - 0s 58us/step - loss: 8.9213e-04 - val_loss: 0.0762\n",
      "Epoch 70/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.8305e-04 - val_loss: 0.0758\n",
      "Epoch 71/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 8.7413e-04 - val_loss: 0.0755\n",
      "Epoch 72/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 8.6538e-04 - val_loss: 0.0751\n",
      "Epoch 73/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 8.5678e-04 - val_loss: 0.0748\n",
      "Epoch 74/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 8.4834e-04 - val_loss: 0.0744\n",
      "Epoch 75/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.4004e-04 - val_loss: 0.0741\n",
      "Epoch 76/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.3189e-04 - val_loss: 0.0738\n",
      "Epoch 77/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 8.2387e-04 - val_loss: 0.0735\n",
      "Epoch 78/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.1598e-04 - val_loss: 0.0732\n",
      "Epoch 79/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 8.0822e-04 - val_loss: 0.0729\n",
      "Epoch 80/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 8.0059e-04 - val_loss: 0.0726\n",
      "Epoch 81/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 7.9307e-04 - val_loss: 0.0723\n",
      "Epoch 82/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 7.8567e-04 - val_loss: 0.0720\n",
      "Epoch 83/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 7.7837e-04 - val_loss: 0.0717\n",
      "Epoch 84/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 7.7119e-04 - val_loss: 0.0714\n",
      "Epoch 85/300\n",
      "1044/1044 [==============================] - 0s 31us/step - loss: 7.6410e-04 - val_loss: 0.0711\n",
      "Epoch 86/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 7.5711e-04 - val_loss: 0.0708\n",
      "Epoch 87/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 7.5022e-04 - val_loss: 0.0705\n",
      "Epoch 88/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 7.4343e-04 - val_loss: 0.0703\n",
      "Epoch 89/300\n",
      "1044/1044 [==============================] - 0s 16us/step - loss: 7.3671e-04 - val_loss: 0.0700\n",
      "Epoch 90/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 7.3009e-04 - val_loss: 0.0697\n",
      "Epoch 91/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 7.2354e-04 - val_loss: 0.0695\n",
      "Epoch 92/300\n",
      "1044/1044 [==============================] - 0s 64us/step - loss: 7.1708e-04 - val_loss: 0.0692\n",
      "Epoch 93/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 7.1069e-04 - val_loss: 0.0689\n",
      "Epoch 94/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 7.0437e-04 - val_loss: 0.0687\n",
      "Epoch 95/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 6.9813e-04 - val_loss: 0.0684\n",
      "Epoch 96/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 6.9195e-04 - val_loss: 0.0682\n",
      "Epoch 97/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 6.8583e-04 - val_loss: 0.0679\n",
      "Epoch 98/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 6.7978e-04 - val_loss: 0.0677\n",
      "Epoch 99/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 6.7378e-04 - val_loss: 0.0674\n",
      "Epoch 100/300\n",
      "1044/1044 [==============================] - 0s 67us/step - loss: 6.6784e-04 - val_loss: 0.0672\n",
      "Epoch 101/300\n",
      "1044/1044 [==============================] - 0s 61us/step - loss: 6.6196e-04 - val_loss: 0.0669\n",
      "Epoch 102/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 6.5613e-04 - val_loss: 0.0667\n",
      "Epoch 103/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 6.5034e-04 - val_loss: 0.0664\n",
      "Epoch 104/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 6.4461e-04 - val_loss: 0.0662\n",
      "Epoch 105/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 6.3892e-04 - val_loss: 0.0659\n",
      "Epoch 106/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 6.3327e-04 - val_loss: 0.0657\n",
      "Epoch 107/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 6.2767e-04 - val_loss: 0.0655\n",
      "Epoch 108/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 6.2210e-04 - val_loss: 0.0652\n",
      "Epoch 109/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 6.1657e-04 - val_loss: 0.0650\n",
      "Epoch 110/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 6.1107e-04 - val_loss: 0.0647\n",
      "Epoch 111/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 6.0561e-04 - val_loss: 0.0645\n",
      "Epoch 112/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 6.0018e-04 - val_loss: 0.0643\n",
      "Epoch 113/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 5.9478e-04 - val_loss: 0.0640\n",
      "Epoch 114/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 5.8941e-04 - val_loss: 0.0638\n",
      "Epoch 115/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 5.8406e-04 - val_loss: 0.0635\n",
      "Epoch 116/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 5.7874e-04 - val_loss: 0.0633\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 34us/step - loss: 5.7344e-04 - val_loss: 0.0630\n",
      "Epoch 118/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 5.6816e-04 - val_loss: 0.0628\n",
      "Epoch 119/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 5.6291e-04 - val_loss: 0.0626\n",
      "Epoch 120/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 5.5767e-04 - val_loss: 0.0623\n",
      "Epoch 121/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 5.5245e-04 - val_loss: 0.0621\n",
      "Epoch 122/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 5.4724e-04 - val_loss: 0.0618\n",
      "Epoch 123/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 5.4205e-04 - val_loss: 0.0616\n",
      "Epoch 124/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 5.3687e-04 - val_loss: 0.0613\n",
      "Epoch 125/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 5.3171e-04 - val_loss: 0.0611\n",
      "Epoch 126/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 5.2655e-04 - val_loss: 0.0608\n",
      "Epoch 127/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 5.2141e-04 - val_loss: 0.0606\n",
      "Epoch 128/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 5.1627e-04 - val_loss: 0.0603\n",
      "Epoch 129/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 5.1115e-04 - val_loss: 0.0600\n",
      "Epoch 130/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 5.0602e-04 - val_loss: 0.0598\n",
      "Epoch 131/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 5.0091e-04 - val_loss: 0.0595\n",
      "Epoch 132/300\n",
      "1044/1044 [==============================] - 0s 29us/step - loss: 4.9580e-04 - val_loss: 0.0593\n",
      "Epoch 133/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 4.9069e-04 - val_loss: 0.0590\n",
      "Epoch 134/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 4.8559e-04 - val_loss: 0.0587\n",
      "Epoch 135/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.8049e-04 - val_loss: 0.0585\n",
      "Epoch 136/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.7539e-04 - val_loss: 0.0582\n",
      "Epoch 137/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.7030e-04 - val_loss: 0.0579\n",
      "Epoch 138/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.6520e-04 - val_loss: 0.0576\n",
      "Epoch 139/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.6011e-04 - val_loss: 0.0574\n",
      "Epoch 140/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.5501e-04 - val_loss: 0.0571\n",
      "Epoch 141/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.4992e-04 - val_loss: 0.0568\n",
      "Epoch 142/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.4482e-04 - val_loss: 0.0565\n",
      "Epoch 143/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.3972e-04 - val_loss: 0.0562\n",
      "Epoch 144/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 4.3463e-04 - val_loss: 0.0560\n",
      "Epoch 145/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 4.2953e-04 - val_loss: 0.0557\n",
      "Epoch 146/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 4.2443e-04 - val_loss: 0.0554\n",
      "Epoch 147/300\n",
      "1044/1044 [==============================] - 0s 28us/step - loss: 4.1932e-04 - val_loss: 0.0551\n",
      "Epoch 148/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.1422e-04 - val_loss: 0.0548\n",
      "Epoch 149/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 4.0912e-04 - val_loss: 0.0545\n",
      "Epoch 150/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 4.0401e-04 - val_loss: 0.0542\n",
      "Epoch 151/300\n",
      "1044/1044 [==============================] - 0s 29us/step - loss: 3.9890e-04 - val_loss: 0.0539\n",
      "Epoch 152/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 3.9380e-04 - val_loss: 0.0535\n",
      "Epoch 153/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.8869e-04 - val_loss: 0.0532\n",
      "Epoch 154/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.8359e-04 - val_loss: 0.0529\n",
      "Epoch 155/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.7848e-04 - val_loss: 0.0526\n",
      "Epoch 156/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.7338e-04 - val_loss: 0.0523\n",
      "Epoch 157/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.6828e-04 - val_loss: 0.0519\n",
      "Epoch 158/300\n",
      "1044/1044 [==============================] - 0s 18us/step - loss: 3.6319e-04 - val_loss: 0.0516\n",
      "Epoch 159/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.5810e-04 - val_loss: 0.0513\n",
      "Epoch 160/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.5301e-04 - val_loss: 0.0509\n",
      "Epoch 161/300\n",
      "1044/1044 [==============================] - 0s 29us/step - loss: 3.4794e-04 - val_loss: 0.0506\n",
      "Epoch 162/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.4287e-04 - val_loss: 0.0503\n",
      "Epoch 163/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.3781e-04 - val_loss: 0.0499\n",
      "Epoch 164/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.3276e-04 - val_loss: 0.0496\n",
      "Epoch 165/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.2772e-04 - val_loss: 0.0492\n",
      "Epoch 166/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 3.2270e-04 - val_loss: 0.0489\n",
      "Epoch 167/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 3.1769e-04 - val_loss: 0.0485\n",
      "Epoch 168/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.1269e-04 - val_loss: 0.0482\n",
      "Epoch 169/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.0772e-04 - val_loss: 0.0478\n",
      "Epoch 170/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 3.0277e-04 - val_loss: 0.0475\n",
      "Epoch 171/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.9784e-04 - val_loss: 0.0471\n",
      "Epoch 172/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 2.9293e-04 - val_loss: 0.0467\n",
      "Epoch 173/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 2.8805e-04 - val_loss: 0.0464\n",
      "Epoch 174/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 2.8320e-04 - val_loss: 0.0460\n",
      "Epoch 175/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.7838e-04 - val_loss: 0.0456\n",
      "Epoch 176/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.7359e-04 - val_loss: 0.0453\n",
      "Epoch 177/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.6883e-04 - val_loss: 0.0449\n",
      "Epoch 178/300\n",
      "1044/1044 [==============================] - 0s 43us/step - loss: 2.6412e-04 - val_loss: 0.0445\n",
      "Epoch 179/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 2.5944e-04 - val_loss: 0.0442\n",
      "Epoch 180/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 2.5480e-04 - val_loss: 0.0438\n",
      "Epoch 181/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 2.5021e-04 - val_loss: 0.0434\n",
      "Epoch 182/300\n",
      "1044/1044 [==============================] - 0s 18us/step - loss: 2.4567e-04 - val_loss: 0.0430\n",
      "Epoch 183/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.4117e-04 - val_loss: 0.0427\n",
      "Epoch 184/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.3672e-04 - val_loss: 0.0423\n",
      "Epoch 185/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 2.3233e-04 - val_loss: 0.0419\n",
      "Epoch 186/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 2.2800e-04 - val_loss: 0.0415\n",
      "Epoch 187/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.2372e-04 - val_loss: 0.0412\n",
      "Epoch 188/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.1950e-04 - val_loss: 0.0408\n",
      "Epoch 189/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 2.1535e-04 - val_loss: 0.0404\n",
      "Epoch 190/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 2.1126e-04 - val_loss: 0.0400\n",
      "Epoch 191/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 38us/step - loss: 2.0724e-04 - val_loss: 0.0397\n",
      "Epoch 192/300\n",
      "1044/1044 [==============================] - 0s 25us/step - loss: 2.0328e-04 - val_loss: 0.0393\n",
      "Epoch 193/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.9940e-04 - val_loss: 0.0389\n",
      "Epoch 194/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 1.9559e-04 - val_loss: 0.0386\n",
      "Epoch 195/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 1.9185e-04 - val_loss: 0.0382\n",
      "Epoch 196/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.8819e-04 - val_loss: 0.0378\n",
      "Epoch 197/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.8461e-04 - val_loss: 0.0375\n",
      "Epoch 198/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.8111e-04 - val_loss: 0.0371\n",
      "Epoch 199/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 1.7769e-04 - val_loss: 0.0368\n",
      "Epoch 200/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 1.7435e-04 - val_loss: 0.0364\n",
      "Epoch 201/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.7109e-04 - val_loss: 0.0361\n",
      "Epoch 202/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.6792e-04 - val_loss: 0.0357\n",
      "Epoch 203/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.6483e-04 - val_loss: 0.0354\n",
      "Epoch 204/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.6182e-04 - val_loss: 0.0350\n",
      "Epoch 205/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 1.5890e-04 - val_loss: 0.0347\n",
      "Epoch 206/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 1.5606e-04 - val_loss: 0.0344\n",
      "Epoch 207/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 1.5332e-04 - val_loss: 0.0340\n",
      "Epoch 208/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 1.5065e-04 - val_loss: 0.0337\n",
      "Epoch 209/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.4807e-04 - val_loss: 0.0334\n",
      "Epoch 210/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.4558e-04 - val_loss: 0.0331\n",
      "Epoch 211/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.4317e-04 - val_loss: 0.0328\n",
      "Epoch 212/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.4084e-04 - val_loss: 0.0325\n",
      "Epoch 213/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 1.3860e-04 - val_loss: 0.0322\n",
      "Epoch 214/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 1.3644e-04 - val_loss: 0.0319\n",
      "Epoch 215/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 1.3435e-04 - val_loss: 0.0316\n",
      "Epoch 216/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 1.3235e-04 - val_loss: 0.0313\n",
      "Epoch 217/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 1.3043e-04 - val_loss: 0.0311\n",
      "Epoch 218/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 1.2858e-04 - val_loss: 0.0308\n",
      "Epoch 219/300\n",
      "1044/1044 [==============================] - 0s 19us/step - loss: 1.2681e-04 - val_loss: 0.0305\n",
      "Epoch 220/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.2511e-04 - val_loss: 0.0303\n",
      "Epoch 221/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.2348e-04 - val_loss: 0.0300\n",
      "Epoch 222/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 1.2192e-04 - val_loss: 0.0298\n",
      "Epoch 223/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 1.2043e-04 - val_loss: 0.0296\n",
      "Epoch 224/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 1.1900e-04 - val_loss: 0.0293\n",
      "Epoch 225/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 1.1764e-04 - val_loss: 0.0291\n",
      "Epoch 226/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 1.1633e-04 - val_loss: 0.0289\n",
      "Epoch 227/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 1.1509e-04 - val_loss: 0.0287\n",
      "Epoch 228/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 1.1391e-04 - val_loss: 0.0285\n",
      "Epoch 229/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 1.1277e-04 - val_loss: 0.0283\n",
      "Epoch 230/300\n",
      "1044/1044 [==============================] - ETA: 0s - loss: 5.5647e-0 - 0s 34us/step - loss: 1.1170e-04 - val_loss: 0.0281\n",
      "Epoch 231/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 1.1067e-04 - val_loss: 0.0279\n",
      "Epoch 232/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0969e-04 - val_loss: 0.0277\n",
      "Epoch 233/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 1.0875e-04 - val_loss: 0.0275\n",
      "Epoch 234/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0786e-04 - val_loss: 0.0273\n",
      "Epoch 235/300\n",
      "1044/1044 [==============================] - 0s 55us/step - loss: 1.0701e-04 - val_loss: 0.0272\n",
      "Epoch 236/300\n",
      "1044/1044 [==============================] - 0s 25us/step - loss: 1.0620e-04 - val_loss: 0.0270\n",
      "Epoch 237/300\n",
      "1044/1044 [==============================] - ETA: 0s - loss: 3.4004e-0 - 0s 30us/step - loss: 1.0543e-04 - val_loss: 0.0269\n",
      "Epoch 238/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0469e-04 - val_loss: 0.0267\n",
      "Epoch 239/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0399e-04 - val_loss: 0.0266\n",
      "Epoch 240/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0332e-04 - val_loss: 0.0264\n",
      "Epoch 241/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0268e-04 - val_loss: 0.0263\n",
      "Epoch 242/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 1.0207e-04 - val_loss: 0.0261\n",
      "Epoch 243/300\n",
      "1044/1044 [==============================] - 0s 20us/step - loss: 1.0148e-04 - val_loss: 0.0260\n",
      "Epoch 244/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0092e-04 - val_loss: 0.0259\n",
      "Epoch 245/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 1.0038e-04 - val_loss: 0.0258\n",
      "Epoch 246/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.9863e-05 - val_loss: 0.0257\n",
      "Epoch 247/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.9367e-05 - val_loss: 0.0255\n",
      "Epoch 248/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.8890e-05 - val_loss: 0.0254\n",
      "Epoch 249/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.8431e-05 - val_loss: 0.0253\n",
      "Epoch 250/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.7988e-05 - val_loss: 0.0252\n",
      "Epoch 251/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.7560e-05 - val_loss: 0.0251\n",
      "Epoch 252/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.7146e-05 - val_loss: 0.0250\n",
      "Epoch 253/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 9.6746e-05 - val_loss: 0.0250\n",
      "Epoch 254/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 9.6357e-05 - val_loss: 0.0249\n",
      "Epoch 255/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.5980e-05 - val_loss: 0.0248\n",
      "Epoch 256/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 9.5613e-05 - val_loss: 0.0247\n",
      "Epoch 257/300\n",
      "1044/1044 [==============================] - 0s 47us/step - loss: 9.5256e-05 - val_loss: 0.0246\n",
      "Epoch 258/300\n",
      "1044/1044 [==============================] - 0s 22us/step - loss: 9.4907e-05 - val_loss: 0.0246\n",
      "Epoch 259/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 9.4567e-05 - val_loss: 0.0245\n",
      "Epoch 260/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.4234e-05 - val_loss: 0.0244\n",
      "Epoch 261/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 9.3907e-05 - val_loss: 0.0244\n",
      "Epoch 262/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.3587e-05 - val_loss: 0.0243\n",
      "Epoch 263/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 9.3273e-05 - val_loss: 0.0243\n",
      "Epoch 264/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 9.2963e-05 - val_loss: 0.0242\n",
      "Epoch 265/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 18us/step - loss: 9.2659e-05 - val_loss: 0.0241\n",
      "Epoch 266/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 9.2358e-05 - val_loss: 0.0241\n",
      "Epoch 267/300\n",
      "1044/1044 [==============================] - 0s 27us/step - loss: 9.2062e-05 - val_loss: 0.0240\n",
      "Epoch 268/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.1769e-05 - val_loss: 0.0240\n",
      "Epoch 269/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.1479e-05 - val_loss: 0.0240\n",
      "Epoch 270/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 9.1192e-05 - val_loss: 0.0239\n",
      "Epoch 271/300\n",
      "1044/1044 [==============================] - 0s 22us/step - loss: 9.0908e-05 - val_loss: 0.0239\n",
      "Epoch 272/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.0626e-05 - val_loss: 0.0238\n",
      "Epoch 273/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 9.0346e-05 - val_loss: 0.0238\n",
      "Epoch 274/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 9.0068e-05 - val_loss: 0.0238\n",
      "Epoch 275/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.9792e-05 - val_loss: 0.0237\n",
      "Epoch 276/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.9517e-05 - val_loss: 0.0237\n",
      "Epoch 277/300\n",
      "1044/1044 [==============================] - 0s 23us/step - loss: 8.9244e-05 - val_loss: 0.0237\n",
      "Epoch 278/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.8972e-05 - val_loss: 0.0236\n",
      "Epoch 279/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.8701e-05 - val_loss: 0.0236\n",
      "Epoch 280/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 8.8431e-05 - val_loss: 0.0236\n",
      "Epoch 281/300\n",
      "1044/1044 [==============================] - 0s 24us/step - loss: 8.8161e-05 - val_loss: 0.0235\n",
      "Epoch 282/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.7892e-05 - val_loss: 0.0235\n",
      "Epoch 283/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 8.7624e-05 - val_loss: 0.0235\n",
      "Epoch 284/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 8.7357e-05 - val_loss: 0.0235\n",
      "Epoch 285/300\n",
      "1044/1044 [==============================] - 0s 29us/step - loss: 8.7090e-05 - val_loss: 0.0234\n",
      "Epoch 286/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6823e-05 - val_loss: 0.0234\n",
      "Epoch 287/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6557e-05 - val_loss: 0.0234\n",
      "Epoch 288/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 8.6291e-05 - val_loss: 0.0234\n",
      "Epoch 289/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.6025e-05 - val_loss: 0.0234\n",
      "Epoch 290/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.5759e-05 - val_loss: 0.0233\n",
      "Epoch 291/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 8.5494e-05 - val_loss: 0.0233\n",
      "Epoch 292/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.5228e-05 - val_loss: 0.0233\n",
      "Epoch 293/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.4963e-05 - val_loss: 0.0233\n",
      "Epoch 294/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 8.4697e-05 - val_loss: 0.0233\n",
      "Epoch 295/300\n",
      "1044/1044 [==============================] - 0s 23us/step - loss: 8.4432e-05 - val_loss: 0.0233\n",
      "Epoch 296/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.4166e-05 - val_loss: 0.0232\n",
      "Epoch 297/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 8.3901e-05 - val_loss: 0.0232\n",
      "Epoch 298/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 8.3635e-05 - val_loss: 0.0232\n",
      "Epoch 299/300\n",
      "1044/1044 [==============================] - 0s 26us/step - loss: 8.3370e-05 - val_loss: 0.0232\n",
      "Epoch 300/300\n",
      "1044/1044 [==============================] - 0s 30us/step - loss: 8.3104e-05 - val_loss: 0.0232\n",
      "Entrenamiento f3 completo.\n",
      "[[0.40630066]\n",
      " [0.394321  ]\n",
      " [0.39477286]\n",
      " [0.38400686]\n",
      " [0.38914764]\n",
      " [0.38046166]\n",
      " [0.384506  ]\n",
      " [0.37799093]\n",
      " [0.35710096]\n",
      " [0.31690383]\n",
      " [0.3283286 ]\n",
      " [0.30604255]\n",
      " [0.29259485]\n",
      " [0.29057223]\n",
      " [0.27145448]\n",
      " [0.26908764]\n",
      " [0.27361578]\n",
      " [0.2755945 ]\n",
      " [0.3263246 ]\n",
      " [0.30086854]\n",
      " [0.31152377]\n",
      " [0.28820845]\n",
      " [0.29824147]\n",
      " [0.2873874 ]\n",
      " [0.29481092]\n",
      " [0.2985811 ]\n",
      " [0.2985846 ]\n",
      " [0.29420188]\n",
      " [0.3100429 ]\n",
      " [0.3272829 ]]\n",
      "30\n",
      "Simulación f3 completa.\n",
      "            Close ripple        f1        f2        f3\n",
      "Date                                                  \n",
      "2015-01-01      0.024390       NaN       NaN       NaN\n",
      "2015-01-02      0.024318       NaN       NaN       NaN\n",
      "2015-01-03      0.022106       NaN       NaN       NaN\n",
      "2015-01-04      0.018928       NaN       NaN       NaN\n",
      "2015-01-05      0.020316       NaN       NaN       NaN\n",
      "2015-01-06      0.020732       NaN       NaN       NaN\n",
      "2015-01-07      0.020843       NaN       NaN       NaN\n",
      "2015-01-08      0.020676       NaN       NaN       NaN\n",
      "2015-01-09      0.020576       NaN       NaN       NaN\n",
      "2015-01-10      0.019233       NaN       NaN       NaN\n",
      "2015-01-11      0.018765       NaN       NaN       NaN\n",
      "2015-01-12      0.018434       NaN       NaN       NaN\n",
      "2015-01-13      0.015648       NaN       NaN       NaN\n",
      "2015-01-14      0.014233       NaN       NaN       NaN\n",
      "2015-01-15      0.016444       NaN       NaN       NaN\n",
      "2015-01-16      0.016403       NaN       NaN       NaN\n",
      "2015-01-17      0.015361       NaN       NaN       NaN\n",
      "2015-01-18      0.015622       NaN       NaN       NaN\n",
      "2015-01-19      0.015991       NaN       NaN       NaN\n",
      "2015-01-20      0.016112       NaN       NaN       NaN\n",
      "2015-01-21      0.016653       NaN       NaN       NaN\n",
      "2015-01-22      0.017010       NaN       NaN       NaN\n",
      "2015-01-23      0.016734       NaN       NaN       NaN\n",
      "2015-01-24      0.016736       NaN       NaN       NaN\n",
      "2015-01-25      0.016578       NaN       NaN       NaN\n",
      "2015-01-26      0.016019       NaN       NaN       NaN\n",
      "2015-01-27      0.015841       NaN       NaN       NaN\n",
      "2015-01-28      0.014970       NaN       NaN       NaN\n",
      "2015-01-29      0.014706       NaN       NaN       NaN\n",
      "2015-01-30      0.014443       NaN       NaN       NaN\n",
      "...                  ...       ...       ...       ...\n",
      "2018-08-02      0.430254  0.377466  0.353815  0.406301\n",
      "2018-08-03      0.440571  0.364004  0.357597  0.394321\n",
      "2018-08-04      0.428507  0.370366  0.346735  0.394773\n",
      "2018-08-05      0.433638  0.359921  0.352591  0.384007\n",
      "2018-08-06      0.414081  0.365347  0.343632  0.389148\n",
      "2018-08-07      0.381006  0.355654  0.348156  0.380462\n",
      "2018-08-08      0.331944  0.329929  0.340159  0.384506\n",
      "2018-08-09      0.346771  0.286118  0.317785  0.377991\n",
      "2018-08-10      0.320426  0.297610  0.279070  0.357101\n",
      "2018-08-11      0.301262  0.275166  0.288873  0.316904\n",
      "2018-08-12      0.297870  0.259910  0.269100  0.328329\n",
      "2018-08-13      0.277466  0.257565  0.255385  0.306043\n",
      "2018-08-14      0.274272  0.238639  0.253263  0.292595\n",
      "2018-08-15      0.282005  0.237389  0.235962  0.290572\n",
      "2018-08-16      0.292436  0.242715  0.235239  0.271454\n",
      "2018-08-17      0.366676  0.246892  0.239810  0.269088\n",
      "2018-08-18      0.327100  0.302154  0.243158  0.273616\n",
      "2018-08-19      0.343978  0.271874  0.292870  0.275595\n",
      "2018-08-20      0.319283  0.284030  0.265985  0.326325\n",
      "2018-08-21      0.335177  0.261649  0.276914  0.300869\n",
      "2018-08-22      0.319803  0.272968  0.256529  0.311524\n",
      "2018-08-23      0.327709  0.261792  0.266595  0.288208\n",
      "2018-08-24      0.327606  0.268256  0.256358  0.298241\n",
      "2018-08-25      0.328230  0.269720  0.262422  0.287387\n",
      "2018-08-26      0.323776  0.270416  0.263890  0.294811\n",
      "2018-08-27      0.336903  0.265681  0.264503  0.298581\n",
      "2018-08-28      0.351837  0.280228  0.260199  0.298585\n",
      "2018-08-29      0.344803  0.295833  0.273490  0.294202\n",
      "2018-08-30      0.335444  0.294905  0.287807  0.310043\n",
      "2018-08-31      0.335332  0.288475  0.287408  0.327283\n",
      "\n",
      "[1339 rows x 4 columns]\n",
      "RMSEs guardados: script/ripple/post/Predicciones entrenamiento rmses.csv\n",
      "Epochs guardados: script/ripple/post/Predicciones entrenamiento rmses.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criptomoneda procesada: bitcoin-cash\n",
      "Criptomoneda procesada: eos\n",
      "Criptomoneda procesada: qtum\n",
      "Criptomoneda procesada: omisego\n",
      "Criptomoneda procesada: zcash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1046 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1046/1046 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.1394\n",
      "Epoch 2/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0020 - val_loss: 0.1358\n",
      "Epoch 3/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.1325\n",
      "Epoch 4/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.1296\n",
      "Epoch 5/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.1271\n",
      "Epoch 6/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.1251\n",
      "Epoch 7/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.1234\n",
      "Epoch 8/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.1220\n",
      "Epoch 9/300\n",
      "1046/1046 [==============================] - 0s 76us/step - loss: 0.0018 - val_loss: 0.1208\n",
      "Epoch 10/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0019 - val_loss: 0.1198\n",
      "Epoch 11/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 0.0019 - val_loss: 0.1190\n",
      "Epoch 12/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.1182\n",
      "Epoch 13/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.1176\n",
      "Epoch 14/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.1171\n",
      "Epoch 15/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.1166\n",
      "Epoch 16/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.1161\n",
      "Epoch 17/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.1157\n",
      "Epoch 18/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.1154\n",
      "Epoch 19/300\n",
      "1046/1046 [==============================] - 0s 59us/step - loss: 0.0019 - val_loss: 0.1150\n",
      "Epoch 20/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.1147\n",
      "Epoch 21/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.1144\n",
      "Epoch 22/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.1140\n",
      "Epoch 23/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.1137\n",
      "Epoch 24/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 0.1134\n",
      "Epoch 25/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 0.0018 - val_loss: 0.1131\n",
      "Epoch 26/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.1127\n",
      "Epoch 27/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.1124\n",
      "Epoch 28/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.1120\n",
      "Epoch 29/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.1116\n",
      "Epoch 30/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.1111\n",
      "Epoch 31/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 0.0018 - val_loss: 0.1107\n",
      "Epoch 32/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.1102\n",
      "Epoch 33/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 0.1097\n",
      "Epoch 34/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0017 - val_loss: 0.1091\n",
      "Epoch 35/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 0.1085\n",
      "Epoch 36/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.1079\n",
      "Epoch 37/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0017 - val_loss: 0.1072\n",
      "Epoch 38/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 0.0017 - val_loss: 0.1065\n",
      "Epoch 39/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 0.0017 - val_loss: 0.1058\n",
      "Epoch 40/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0017 - val_loss: 0.1049\n",
      "Epoch 41/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.1041\n",
      "Epoch 42/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0016 - val_loss: 0.1032\n",
      "Epoch 43/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 0.0016 - val_loss: 0.1022\n",
      "Epoch 44/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.1012\n",
      "Epoch 45/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0016 - val_loss: 0.1002\n",
      "Epoch 46/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0016 - val_loss: 0.0991\n",
      "Epoch 47/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 0.0979\n",
      "Epoch 48/300\n",
      "1046/1046 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0968\n",
      "Epoch 49/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 0.0955\n",
      "Epoch 50/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0015 - val_loss: 0.0942\n",
      "Epoch 51/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0015 - val_loss: 0.0929\n",
      "Epoch 52/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 0.0915\n",
      "Epoch 53/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0014 - val_loss: 0.0901\n",
      "Epoch 54/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0014 - val_loss: 0.0887\n",
      "Epoch 55/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0014 - val_loss: 0.0872\n",
      "Epoch 56/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 0.0013 - val_loss: 0.0856\n",
      "Epoch 57/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 0.0013 - val_loss: 0.0841\n",
      "Epoch 58/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0013 - val_loss: 0.0825\n",
      "Epoch 59/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0013 - val_loss: 0.0809\n",
      "Epoch 60/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 0.0012 - val_loss: 0.0792\n",
      "Epoch 61/300\n",
      "1046/1046 [==============================] - 0s 47us/step - loss: 0.0012 - val_loss: 0.0775\n",
      "Epoch 62/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 0.0012 - val_loss: 0.0758\n",
      "Epoch 63/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 0.0012 - val_loss: 0.0741\n",
      "Epoch 64/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0011 - val_loss: 0.0724\n",
      "Epoch 65/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 0.0011 - val_loss: 0.0706\n",
      "Epoch 66/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 0.0011 - val_loss: 0.0689\n",
      "Epoch 67/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 0.0011 - val_loss: 0.0671\n",
      "Epoch 68/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 0.0010 - val_loss: 0.0654\n",
      "Epoch 69/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 9.9978e-04 - val_loss: 0.0636\n",
      "Epoch 70/300\n",
      "1046/1046 [==============================] - 0s 61us/step - loss: 9.7287e-04 - val_loss: 0.0619\n",
      "Epoch 71/300\n",
      "1046/1046 [==============================] - 0s 62us/step - loss: 9.4616e-04 - val_loss: 0.0601\n",
      "Epoch 72/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 9.1969e-04 - val_loss: 0.0584\n",
      "Epoch 73/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 8.9353e-04 - val_loss: 0.0566\n",
      "Epoch 74/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 8.6773e-04 - val_loss: 0.0549\n",
      "Epoch 75/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 8.4234e-04 - val_loss: 0.0532\n",
      "Epoch 76/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 8.1741e-04 - val_loss: 0.0515\n",
      "Epoch 77/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 7.9298e-04 - val_loss: 0.0499\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 0s 44us/step - loss: 7.6909e-04 - val_loss: 0.0483\n",
      "Epoch 79/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 7.4580e-04 - val_loss: 0.0467\n",
      "Epoch 80/300\n",
      "1046/1046 [==============================] - 0s 52us/step - loss: 7.2314e-04 - val_loss: 0.0451\n",
      "Epoch 81/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 7.0113e-04 - val_loss: 0.0435\n",
      "Epoch 82/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 6.7982e-04 - val_loss: 0.0420\n",
      "Epoch 83/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 6.5925e-04 - val_loss: 0.0406\n",
      "Epoch 84/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 6.3943e-04 - val_loss: 0.0391\n",
      "Epoch 85/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 6.2037e-04 - val_loss: 0.0377\n",
      "Epoch 86/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 6.0210e-04 - val_loss: 0.0364\n",
      "Epoch 87/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 5.8464e-04 - val_loss: 0.0351\n",
      "Epoch 88/300\n",
      "1046/1046 [==============================] - 0s 53us/step - loss: 5.6800e-04 - val_loss: 0.0338\n",
      "Epoch 89/300\n",
      "1046/1046 [==============================] - 0s 49us/step - loss: 5.5218e-04 - val_loss: 0.0326\n",
      "Epoch 90/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 5.3718e-04 - val_loss: 0.0314\n",
      "Epoch 91/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 5.2299e-04 - val_loss: 0.0303\n",
      "Epoch 92/300\n",
      "1046/1046 [==============================] - 0s 84us/step - loss: 5.0963e-04 - val_loss: 0.0292\n",
      "Epoch 93/300\n",
      "1046/1046 [==============================] - 0s 67us/step - loss: 4.9706e-04 - val_loss: 0.0281\n",
      "Epoch 94/300\n",
      "1046/1046 [==============================] - 0s 75us/step - loss: 4.8528e-04 - val_loss: 0.0271\n",
      "Epoch 95/300\n",
      "1046/1046 [==============================] - 0s 55us/step - loss: 4.7428e-04 - val_loss: 0.0261\n",
      "Epoch 96/300\n",
      "1046/1046 [==============================] - 0s 42us/step - loss: 4.6402e-04 - val_loss: 0.0252\n",
      "Epoch 97/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 4.5450e-04 - val_loss: 0.0243\n",
      "Epoch 98/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.4569e-04 - val_loss: 0.0235\n",
      "Epoch 99/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 4.3755e-04 - val_loss: 0.0227\n",
      "Epoch 100/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 4.3006e-04 - val_loss: 0.0219\n",
      "Epoch 101/300\n",
      "1046/1046 [==============================] - 0s 44us/step - loss: 4.2319e-04 - val_loss: 0.0212\n",
      "Epoch 102/300\n",
      "1046/1046 [==============================] - 0s 51us/step - loss: 4.1691e-04 - val_loss: 0.0206\n",
      "Epoch 103/300\n",
      "1046/1046 [==============================] - 0s 48us/step - loss: 4.1118e-04 - val_loss: 0.0199\n",
      "Epoch 104/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 4.0598e-04 - val_loss: 0.0193\n",
      "Epoch 105/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 4.0126e-04 - val_loss: 0.0187\n",
      "Epoch 106/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 3.9700e-04 - val_loss: 0.0182\n",
      "Epoch 107/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.9316e-04 - val_loss: 0.0177\n",
      "Epoch 108/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.8970e-04 - val_loss: 0.0172\n",
      "Epoch 109/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.8660e-04 - val_loss: 0.0168\n",
      "Epoch 110/300\n",
      "1046/1046 [==============================] - 0s 45us/step - loss: 3.8383e-04 - val_loss: 0.0164\n",
      "Epoch 111/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 3.8135e-04 - val_loss: 0.0160\n",
      "Epoch 112/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.7913e-04 - val_loss: 0.0156\n",
      "Epoch 113/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.7715e-04 - val_loss: 0.0152\n",
      "Epoch 114/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.7538e-04 - val_loss: 0.0149\n",
      "Epoch 115/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.7380e-04 - val_loss: 0.0146\n",
      "Epoch 116/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.7237e-04 - val_loss: 0.0143\n",
      "Epoch 117/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.7109e-04 - val_loss: 0.0141\n",
      "Epoch 118/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.6993e-04 - val_loss: 0.0138\n",
      "Epoch 119/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.6886e-04 - val_loss: 0.0136\n",
      "Epoch 120/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.6788e-04 - val_loss: 0.0134\n",
      "Epoch 121/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.6697e-04 - val_loss: 0.0132\n",
      "Epoch 122/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.6612e-04 - val_loss: 0.0130\n",
      "Epoch 123/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 3.6530e-04 - val_loss: 0.0128\n",
      "Epoch 124/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 3.6451e-04 - val_loss: 0.0127\n",
      "Epoch 125/300\n",
      "1046/1046 [==============================] - 0s 54us/step - loss: 3.6375e-04 - val_loss: 0.0125\n",
      "Epoch 126/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 3.6299e-04 - val_loss: 0.0124\n",
      "Epoch 127/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.6224e-04 - val_loss: 0.0123\n",
      "Epoch 128/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.6149e-04 - val_loss: 0.0122\n",
      "Epoch 129/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.6073e-04 - val_loss: 0.0120\n",
      "Epoch 130/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.5995e-04 - val_loss: 0.0119\n",
      "Epoch 131/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.5916e-04 - val_loss: 0.0118\n",
      "Epoch 132/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.5834e-04 - val_loss: 0.0117\n",
      "Epoch 133/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 3.5751e-04 - val_loss: 0.0117\n",
      "Epoch 134/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.5664e-04 - val_loss: 0.0116\n",
      "Epoch 135/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.5575e-04 - val_loss: 0.0115\n",
      "Epoch 136/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.5483e-04 - val_loss: 0.0114\n",
      "Epoch 137/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.5389e-04 - val_loss: 0.0114\n",
      "Epoch 138/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.5291e-04 - val_loss: 0.0113\n",
      "Epoch 139/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.5191e-04 - val_loss: 0.0112\n",
      "Epoch 140/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.5087e-04 - val_loss: 0.0112\n",
      "Epoch 141/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.4981e-04 - val_loss: 0.0111\n",
      "Epoch 142/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.4872e-04 - val_loss: 0.0111\n",
      "Epoch 143/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.4761e-04 - val_loss: 0.0110\n",
      "Epoch 144/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.4647e-04 - val_loss: 0.0110\n",
      "Epoch 145/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.4530e-04 - val_loss: 0.0110\n",
      "Epoch 146/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.4412e-04 - val_loss: 0.0109\n",
      "Epoch 147/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.4291e-04 - val_loss: 0.0109\n",
      "Epoch 148/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.4168e-04 - val_loss: 0.0108\n",
      "Epoch 149/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.4043e-04 - val_loss: 0.0108\n",
      "Epoch 150/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.3916e-04 - val_loss: 0.0108\n",
      "Epoch 151/300\n",
      "1046/1046 [==============================] - 0s 36us/step - loss: 3.3788e-04 - val_loss: 0.0107\n",
      "Epoch 152/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.3658e-04 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 3.3527e-04 - val_loss: 0.0107\n",
      "Epoch 154/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.3394e-04 - val_loss: 0.0107\n",
      "Epoch 155/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.3261e-04 - val_loss: 0.0106\n",
      "Epoch 156/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.3126e-04 - val_loss: 0.0106\n",
      "Epoch 157/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.2990e-04 - val_loss: 0.0106\n",
      "Epoch 158/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.2854e-04 - val_loss: 0.0106\n",
      "Epoch 159/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.2716e-04 - val_loss: 0.0105\n",
      "Epoch 160/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.2579e-04 - val_loss: 0.0105\n",
      "Epoch 161/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.2440e-04 - val_loss: 0.0105\n",
      "Epoch 162/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.2301e-04 - val_loss: 0.0105\n",
      "Epoch 163/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 3.2162e-04 - val_loss: 0.0105\n",
      "Epoch 164/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.2022e-04 - val_loss: 0.0105\n",
      "Epoch 165/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.1883e-04 - val_loss: 0.0104\n",
      "Epoch 166/300\n",
      "1046/1046 [==============================] - 0s 41us/step - loss: 3.1743e-04 - val_loss: 0.0104\n",
      "Epoch 167/300\n",
      "1046/1046 [==============================] - 0s 43us/step - loss: 3.1603e-04 - val_loss: 0.0104\n",
      "Epoch 168/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.1463e-04 - val_loss: 0.0104\n",
      "Epoch 169/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.1323e-04 - val_loss: 0.0104\n",
      "Epoch 170/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.1183e-04 - val_loss: 0.0104\n",
      "Epoch 171/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 3.1044e-04 - val_loss: 0.0104\n",
      "Epoch 172/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 3.0904e-04 - val_loss: 0.0104\n",
      "Epoch 173/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.0765e-04 - val_loss: 0.0104\n",
      "Epoch 174/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 3.0626e-04 - val_loss: 0.0103\n",
      "Epoch 175/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 3.0488e-04 - val_loss: 0.0103\n",
      "Epoch 176/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 3.0349e-04 - val_loss: 0.0103\n",
      "Epoch 177/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.0212e-04 - val_loss: 0.0103\n",
      "Epoch 178/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 3.0074e-04 - val_loss: 0.0103\n",
      "Epoch 179/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.9937e-04 - val_loss: 0.0103\n",
      "Epoch 180/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.9801e-04 - val_loss: 0.0103\n",
      "Epoch 181/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.9665e-04 - val_loss: 0.0103\n",
      "Epoch 182/300\n",
      "1046/1046 [==============================] - 0s 37us/step - loss: 2.9530e-04 - val_loss: 0.0103\n",
      "Epoch 183/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 2.9395e-04 - val_loss: 0.0103\n",
      "Epoch 184/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 2.9261e-04 - val_loss: 0.0103\n",
      "Epoch 185/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.9127e-04 - val_loss: 0.0103\n",
      "Epoch 186/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 2.8994e-04 - val_loss: 0.0103\n",
      "Epoch 187/300\n",
      "1046/1046 [==============================] - 0s 32us/step - loss: 2.8861e-04 - val_loss: 0.0103\n",
      "Epoch 188/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 2.8730e-04 - val_loss: 0.0103\n",
      "Epoch 189/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.8598e-04 - val_loss: 0.0103\n",
      "Epoch 190/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.8468e-04 - val_loss: 0.0103\n",
      "Epoch 191/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.8338e-04 - val_loss: 0.0103\n",
      "Epoch 192/300\n",
      "1046/1046 [==============================] - 0s 40us/step - loss: 2.8209e-04 - val_loss: 0.0103\n",
      "Epoch 193/300\n",
      "1046/1046 [==============================] - 0s 33us/step - loss: 2.8080e-04 - val_loss: 0.0103\n",
      "Epoch 194/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.7952e-04 - val_loss: 0.0103\n",
      "Epoch 195/300\n",
      "1046/1046 [==============================] - 0s 35us/step - loss: 2.7825e-04 - val_loss: 0.0103\n",
      "Epoch 196/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.7698e-04 - val_loss: 0.0103\n",
      "Epoch 197/300\n",
      "1046/1046 [==============================] - 0s 39us/step - loss: 2.7572e-04 - val_loss: 0.0103\n",
      "Epoch 198/300\n",
      "1046/1046 [==============================] - 0s 34us/step - loss: 2.7447e-04 - val_loss: 0.0103\n",
      "Epoch 199/300\n",
      "1046/1046 [==============================] - 0s 38us/step - loss: 2.7322e-04 - val_loss: 0.0103\n",
      "Epoch 200/300\n",
      "1046/1046 [==============================] - 0s 46us/step - loss: 2.7198e-04 - val_loss: 0.0103\n",
      "Epoch 00200: early stopping\n",
      "Entrenamiento f1 completo.\n",
      "[[898.4828 ]\n",
      " [860.12006]\n",
      " [860.816  ]\n",
      " [834.4966 ]\n",
      " [848.1602 ]\n",
      " [836.8888 ]\n",
      " [788.85815]\n",
      " [679.92456]\n",
      " [717.18933]\n",
      " [652.97125]\n",
      " [627.69135]\n",
      " [623.6691 ]\n",
      " [568.4713 ]\n",
      " [554.056  ]\n",
      " [559.9861 ]\n",
      " [559.2496 ]\n",
      " [674.3397 ]\n",
      " [619.5357 ]\n",
      " [639.92114]\n",
      " [567.89856]\n",
      " [590.4726 ]\n",
      " [561.98615]\n",
      " [583.21106]\n",
      " [603.29333]\n",
      " [600.2413 ]\n",
      " [587.5339 ]\n",
      " [636.4329 ]\n",
      " [686.74316]\n",
      " [693.3651 ]\n",
      " [680.16187]]\n",
      "30\n",
      "Simulación f1 completa.\n",
      "Train on 1045 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1045/1045 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.1842\n",
      "Epoch 2/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 0.0019 - val_loss: 0.1777\n",
      "Epoch 3/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.1717\n",
      "Epoch 4/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.1665\n",
      "Epoch 5/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 0.1620\n",
      "Epoch 6/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.1581\n",
      "Epoch 7/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.1548\n",
      "Epoch 8/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.1520\n",
      "Epoch 9/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.1494\n",
      "Epoch 10/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.1471\n",
      "Epoch 11/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.1450\n",
      "Epoch 12/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.1431\n",
      "Epoch 13/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.1413\n",
      "Epoch 14/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.1395\n",
      "Epoch 15/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.1379\n",
      "Epoch 16/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.1363\n",
      "Epoch 17/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.1347\n",
      "Epoch 18/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0016 - val_loss: 0.1332\n",
      "Epoch 19/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.1316\n",
      "Epoch 20/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.1301\n",
      "Epoch 21/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.1286\n",
      "Epoch 22/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0016 - val_loss: 0.1271\n",
      "Epoch 23/300\n",
      "1045/1045 [==============================] - 0s 46us/step - loss: 0.0015 - val_loss: 0.1257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/300\n",
      "1045/1045 [==============================] - 0s 65us/step - loss: 0.0015 - val_loss: 0.1242\n",
      "Epoch 25/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 0.1226\n",
      "Epoch 26/300\n",
      "1045/1045 [==============================] - 0s 48us/step - loss: 0.0015 - val_loss: 0.1211\n",
      "Epoch 27/300\n",
      "1045/1045 [==============================] - 0s 47us/step - loss: 0.0014 - val_loss: 0.1196\n",
      "Epoch 28/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0014 - val_loss: 0.1180\n",
      "Epoch 29/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0014 - val_loss: 0.1164\n",
      "Epoch 30/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0014 - val_loss: 0.1148\n",
      "Epoch 31/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0013 - val_loss: 0.1131\n",
      "Epoch 32/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0013 - val_loss: 0.1114\n",
      "Epoch 33/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0013 - val_loss: 0.1097\n",
      "Epoch 34/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 0.0013 - val_loss: 0.1079\n",
      "Epoch 35/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0012 - val_loss: 0.1062\n",
      "Epoch 36/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 0.1043\n",
      "Epoch 37/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 0.1025\n",
      "Epoch 38/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 0.0012 - val_loss: 0.1006\n",
      "Epoch 39/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 0.0011 - val_loss: 0.0986\n",
      "Epoch 40/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 0.0011 - val_loss: 0.0967\n",
      "Epoch 41/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 0.0011 - val_loss: 0.0947\n",
      "Epoch 42/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 0.0926\n",
      "Epoch 43/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 0.0010 - val_loss: 0.0906\n",
      "Epoch 44/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 9.9601e-04 - val_loss: 0.0885\n",
      "Epoch 45/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 9.6854e-04 - val_loss: 0.0863\n",
      "Epoch 46/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 9.4110e-04 - val_loss: 0.0842\n",
      "Epoch 47/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 9.1370e-04 - val_loss: 0.0820\n",
      "Epoch 48/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 8.8639e-04 - val_loss: 0.0799\n",
      "Epoch 49/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 8.5921e-04 - val_loss: 0.0777\n",
      "Epoch 50/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 8.3222e-04 - val_loss: 0.0755\n",
      "Epoch 51/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 8.0543e-04 - val_loss: 0.0733\n",
      "Epoch 52/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 7.7892e-04 - val_loss: 0.0710\n",
      "Epoch 53/300\n",
      "1045/1045 [==============================] - 0s 43us/step - loss: 7.5272e-04 - val_loss: 0.0688\n",
      "Epoch 54/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 7.2689e-04 - val_loss: 0.0666\n",
      "Epoch 55/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 7.0146e-04 - val_loss: 0.0644\n",
      "Epoch 56/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 6.7648e-04 - val_loss: 0.0622\n",
      "Epoch 57/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 6.5199e-04 - val_loss: 0.0600\n",
      "Epoch 58/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 6.2802e-04 - val_loss: 0.0579\n",
      "Epoch 59/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 6.0462e-04 - val_loss: 0.0558\n",
      "Epoch 60/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 5.8183e-04 - val_loss: 0.0536\n",
      "Epoch 61/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 5.5968e-04 - val_loss: 0.0516\n",
      "Epoch 62/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 5.3821e-04 - val_loss: 0.0495\n",
      "Epoch 63/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 5.1744e-04 - val_loss: 0.0475\n",
      "Epoch 64/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 4.9740e-04 - val_loss: 0.0455\n",
      "Epoch 65/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 4.7813e-04 - val_loss: 0.0436\n",
      "Epoch 66/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.5963e-04 - val_loss: 0.0417\n",
      "Epoch 67/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 4.4193e-04 - val_loss: 0.0399\n",
      "Epoch 68/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 4.2504e-04 - val_loss: 0.0381\n",
      "Epoch 69/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 4.0897e-04 - val_loss: 0.0364\n",
      "Epoch 70/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 3.9373e-04 - val_loss: 0.0347\n",
      "Epoch 71/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 3.7933e-04 - val_loss: 0.0331\n",
      "Epoch 72/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 3.6575e-04 - val_loss: 0.0315\n",
      "Epoch 73/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 3.5300e-04 - val_loss: 0.0300\n",
      "Epoch 74/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 3.4107e-04 - val_loss: 0.0286\n",
      "Epoch 75/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 3.2994e-04 - val_loss: 0.0272\n",
      "Epoch 76/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 3.1961e-04 - val_loss: 0.0258\n",
      "Epoch 77/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 3.1006e-04 - val_loss: 0.0245\n",
      "Epoch 78/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 3.0125e-04 - val_loss: 0.0233\n",
      "Epoch 79/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.9318e-04 - val_loss: 0.0222\n",
      "Epoch 80/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 2.8581e-04 - val_loss: 0.0211\n",
      "Epoch 81/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.7912e-04 - val_loss: 0.0200\n",
      "Epoch 82/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.7308e-04 - val_loss: 0.0190\n",
      "Epoch 83/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.6766e-04 - val_loss: 0.0181\n",
      "Epoch 84/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.6282e-04 - val_loss: 0.0172\n",
      "Epoch 85/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.5854e-04 - val_loss: 0.0164\n",
      "Epoch 86/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.5477e-04 - val_loss: 0.0156\n",
      "Epoch 87/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.5148e-04 - val_loss: 0.0148\n",
      "Epoch 88/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.4865e-04 - val_loss: 0.0141\n",
      "Epoch 89/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 2.4623e-04 - val_loss: 0.0135\n",
      "Epoch 90/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4419e-04 - val_loss: 0.0129\n",
      "Epoch 91/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4250e-04 - val_loss: 0.0123\n",
      "Epoch 92/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4113e-04 - val_loss: 0.0117\n",
      "Epoch 93/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4005e-04 - val_loss: 0.0112\n",
      "Epoch 94/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.3922e-04 - val_loss: 0.0108\n",
      "Epoch 95/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.3862e-04 - val_loss: 0.0103\n",
      "Epoch 96/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 2.3823e-04 - val_loss: 0.0099\n",
      "Epoch 97/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.3801e-04 - val_loss: 0.0096\n",
      "Epoch 98/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.3795e-04 - val_loss: 0.0092\n",
      "Epoch 99/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 2.3802e-04 - val_loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.3820e-04 - val_loss: 0.0086\n",
      "Epoch 101/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.3847e-04 - val_loss: 0.0083\n",
      "Epoch 102/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.3882e-04 - val_loss: 0.0080\n",
      "Epoch 103/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.3923e-04 - val_loss: 0.0078\n",
      "Epoch 104/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 2.3968e-04 - val_loss: 0.0076\n",
      "Epoch 105/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.4017e-04 - val_loss: 0.0074\n",
      "Epoch 106/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.4069e-04 - val_loss: 0.0072\n",
      "Epoch 107/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.4121e-04 - val_loss: 0.0070\n",
      "Epoch 108/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4174e-04 - val_loss: 0.0068\n",
      "Epoch 109/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4227e-04 - val_loss: 0.0067\n",
      "Epoch 110/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4278e-04 - val_loss: 0.0065\n",
      "Epoch 111/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 2.4328e-04 - val_loss: 0.0064\n",
      "Epoch 112/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.4376e-04 - val_loss: 0.0063\n",
      "Epoch 113/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4422e-04 - val_loss: 0.0062\n",
      "Epoch 114/300\n",
      "1045/1045 [==============================] - 0s 45us/step - loss: 2.4465e-04 - val_loss: 0.0061\n",
      "Epoch 115/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.4505e-04 - val_loss: 0.0060\n",
      "Epoch 116/300\n",
      "1045/1045 [==============================] - 0s 42us/step - loss: 2.4542e-04 - val_loss: 0.0059\n",
      "Epoch 117/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.4576e-04 - val_loss: 0.0058\n",
      "Epoch 118/300\n",
      "1045/1045 [==============================] - 0s 38us/step - loss: 2.4606e-04 - val_loss: 0.0057\n",
      "Epoch 119/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4633e-04 - val_loss: 0.0057\n",
      "Epoch 120/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.4657e-04 - val_loss: 0.0056\n",
      "Epoch 121/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4677e-04 - val_loss: 0.0055\n",
      "Epoch 122/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 2.4694e-04 - val_loss: 0.0055\n",
      "Epoch 123/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4707e-04 - val_loss: 0.0054\n",
      "Epoch 124/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4718e-04 - val_loss: 0.0054\n",
      "Epoch 125/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.4725e-04 - val_loss: 0.0053\n",
      "Epoch 126/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4729e-04 - val_loss: 0.0053\n",
      "Epoch 127/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.4730e-04 - val_loss: 0.0052\n",
      "Epoch 128/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4728e-04 - val_loss: 0.0052\n",
      "Epoch 129/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4723e-04 - val_loss: 0.0052\n",
      "Epoch 130/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4716e-04 - val_loss: 0.0051\n",
      "Epoch 131/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4707e-04 - val_loss: 0.0051\n",
      "Epoch 132/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4695e-04 - val_loss: 0.0051\n",
      "Epoch 133/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.4681e-04 - val_loss: 0.0050\n",
      "Epoch 134/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4665e-04 - val_loss: 0.0050\n",
      "Epoch 135/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4647e-04 - val_loss: 0.0050\n",
      "Epoch 136/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4626e-04 - val_loss: 0.0050\n",
      "Epoch 137/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.4605e-04 - val_loss: 0.0050\n",
      "Epoch 138/300\n",
      "1045/1045 [==============================] - 0s 41us/step - loss: 2.4581e-04 - val_loss: 0.0049\n",
      "Epoch 139/300\n",
      "1045/1045 [==============================] - 0s 32us/step - loss: 2.4556e-04 - val_loss: 0.0049\n",
      "Epoch 140/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4530e-04 - val_loss: 0.0049\n",
      "Epoch 141/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.4502e-04 - val_loss: 0.0049\n",
      "Epoch 142/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.4473e-04 - val_loss: 0.0049\n",
      "Epoch 143/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4443e-04 - val_loss: 0.0049\n",
      "Epoch 144/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.4411e-04 - val_loss: 0.0049\n",
      "Epoch 145/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4379e-04 - val_loss: 0.0049\n",
      "Epoch 146/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4346e-04 - val_loss: 0.0049\n",
      "Epoch 147/300\n",
      "1045/1045 [==============================] - 0s 44us/step - loss: 2.4312e-04 - val_loss: 0.0048\n",
      "Epoch 148/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4277e-04 - val_loss: 0.0048\n",
      "Epoch 149/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.4241e-04 - val_loss: 0.0048\n",
      "Epoch 150/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4205e-04 - val_loss: 0.0048\n",
      "Epoch 151/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.4168e-04 - val_loss: 0.0048\n",
      "Epoch 152/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.4131e-04 - val_loss: 0.0048\n",
      "Epoch 153/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.4093e-04 - val_loss: 0.0048\n",
      "Epoch 154/300\n",
      "1045/1045 [==============================] - 0s 39us/step - loss: 2.4054e-04 - val_loss: 0.0048\n",
      "Epoch 155/300\n",
      "1045/1045 [==============================] - 0s 40us/step - loss: 2.4015e-04 - val_loss: 0.0048\n",
      "Epoch 156/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.3976e-04 - val_loss: 0.0048\n",
      "Epoch 157/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.3937e-04 - val_loss: 0.0048\n",
      "Epoch 158/300\n",
      "1045/1045 [==============================] - 0s 35us/step - loss: 2.3897e-04 - val_loss: 0.0048\n",
      "Epoch 159/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.3857e-04 - val_loss: 0.0048\n",
      "Epoch 160/300\n",
      "1045/1045 [==============================] - 0s 33us/step - loss: 2.3816e-04 - val_loss: 0.0049\n",
      "Epoch 161/300\n",
      "1045/1045 [==============================] - 0s 36us/step - loss: 2.3775e-04 - val_loss: 0.0049\n",
      "Epoch 162/300\n",
      "1045/1045 [==============================] - 0s 37us/step - loss: 2.3735e-04 - val_loss: 0.0049\n",
      "Epoch 163/300\n",
      "1045/1045 [==============================] - 0s 34us/step - loss: 2.3694e-04 - val_loss: 0.0049\n",
      "Epoch 00163: early stopping\n",
      "Entrenamiento f2 completo.\n",
      "[[708.8246 ]\n",
      " [691.0659 ]\n",
      " [652.19666]\n",
      " [643.7569 ]\n",
      " [621.11285]\n",
      " [633.7465 ]\n",
      " [614.6514 ]\n",
      " [581.2149 ]\n",
      " [507.50146]\n",
      " [541.5068 ]\n",
      " [493.6454 ]\n",
      " [480.555  ]\n",
      " [477.36572]\n",
      " [435.42813]\n",
      " [417.06342]\n",
      " [420.23694]\n",
      " [427.10312]\n",
      " [510.61273]\n",
      " [469.11172]\n",
      " [482.14722]\n",
      " [426.67163]\n",
      " [445.66794]\n",
      " [422.1309 ]\n",
      " [436.58017]\n",
      " [452.58478]\n",
      " [448.8809 ]\n",
      " [439.52228]\n",
      " [471.84848]\n",
      " [499.7718 ]\n",
      " [491.9424 ]]\n",
      "30\n",
      "Simulación f2 completa.\n",
      "Train on 1044 samples, validate on 262 samples\n",
      "Epoch 1/300\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 3.1186e-04 - val_loss: 0.0292\n",
      "Epoch 2/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.0546e-04 - val_loss: 0.0276\n",
      "Epoch 3/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.1913e-04 - val_loss: 0.0264\n",
      "Epoch 4/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 3.3674e-04 - val_loss: 0.0256\n",
      "Epoch 5/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.4074e-04 - val_loss: 0.0250\n",
      "Epoch 6/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3525e-04 - val_loss: 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 3.2863e-04 - val_loss: 0.0241\n",
      "Epoch 8/300\n",
      "1044/1044 [==============================] - 0s 54us/step - loss: 3.2457e-04 - val_loss: 0.0236\n",
      "Epoch 9/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 3.2306e-04 - val_loss: 0.0231\n",
      "Epoch 10/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.2306e-04 - val_loss: 0.0227\n",
      "Epoch 11/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2358e-04 - val_loss: 0.0223\n",
      "Epoch 12/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2409e-04 - val_loss: 0.0219\n",
      "Epoch 13/300\n",
      "1044/1044 [==============================] - 0s 49us/step - loss: 3.2449e-04 - val_loss: 0.0215\n",
      "Epoch 14/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2488e-04 - val_loss: 0.0212\n",
      "Epoch 15/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2535e-04 - val_loss: 0.0209\n",
      "Epoch 16/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2596e-04 - val_loss: 0.0206\n",
      "Epoch 17/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2670e-04 - val_loss: 0.0204\n",
      "Epoch 18/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 3.2754e-04 - val_loss: 0.0201\n",
      "Epoch 19/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2842e-04 - val_loss: 0.0199\n",
      "Epoch 20/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2934e-04 - val_loss: 0.0197\n",
      "Epoch 21/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.3026e-04 - val_loss: 0.0195\n",
      "Epoch 22/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3119e-04 - val_loss: 0.0193\n",
      "Epoch 23/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3211e-04 - val_loss: 0.0192\n",
      "Epoch 24/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3302e-04 - val_loss: 0.0190\n",
      "Epoch 25/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 3.3390e-04 - val_loss: 0.0189\n",
      "Epoch 26/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.3476e-04 - val_loss: 0.0188\n",
      "Epoch 27/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.3557e-04 - val_loss: 0.0186\n",
      "Epoch 28/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.3635e-04 - val_loss: 0.0185\n",
      "Epoch 29/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.3708e-04 - val_loss: 0.0184\n",
      "Epoch 30/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.3777e-04 - val_loss: 0.0183\n",
      "Epoch 31/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 3.3841e-04 - val_loss: 0.0182\n",
      "Epoch 32/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3899e-04 - val_loss: 0.0181\n",
      "Epoch 33/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.3953e-04 - val_loss: 0.0181\n",
      "Epoch 34/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 3.4002e-04 - val_loss: 0.0180\n",
      "Epoch 35/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.4045e-04 - val_loss: 0.0179\n",
      "Epoch 36/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.4084e-04 - val_loss: 0.0179\n",
      "Epoch 37/300\n",
      "1044/1044 [==============================] - 0s 41us/step - loss: 3.4118e-04 - val_loss: 0.0178\n",
      "Epoch 38/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.4148e-04 - val_loss: 0.0178\n",
      "Epoch 39/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.4172e-04 - val_loss: 0.0177\n",
      "Epoch 40/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.4193e-04 - val_loss: 0.0177\n",
      "Epoch 41/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.4209e-04 - val_loss: 0.0176\n",
      "Epoch 42/300\n",
      "1044/1044 [==============================] - 0s 45us/step - loss: 3.4221e-04 - val_loss: 0.0176\n",
      "Epoch 43/300\n",
      "1044/1044 [==============================] - 0s 40us/step - loss: 3.4229e-04 - val_loss: 0.0175\n",
      "Epoch 44/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.4234e-04 - val_loss: 0.0175\n",
      "Epoch 45/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.4236e-04 - val_loss: 0.0175\n",
      "Epoch 46/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.4234e-04 - val_loss: 0.0174\n",
      "Epoch 47/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.4229e-04 - val_loss: 0.0174\n",
      "Epoch 48/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.4221e-04 - val_loss: 0.0174\n",
      "Epoch 49/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.4210e-04 - val_loss: 0.0173\n",
      "Epoch 50/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.4197e-04 - val_loss: 0.0173\n",
      "Epoch 51/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.4182e-04 - val_loss: 0.0173\n",
      "Epoch 52/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.4165e-04 - val_loss: 0.0173\n",
      "Epoch 53/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.4145e-04 - val_loss: 0.0172\n",
      "Epoch 54/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.4124e-04 - val_loss: 0.0172\n",
      "Epoch 55/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.4101e-04 - val_loss: 0.0172\n",
      "Epoch 56/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 3.4076e-04 - val_loss: 0.0172\n",
      "Epoch 57/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 3.4050e-04 - val_loss: 0.0171\n",
      "Epoch 58/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 3.4023e-04 - val_loss: 0.0171\n",
      "Epoch 59/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.3994e-04 - val_loss: 0.0171\n",
      "Epoch 60/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.3964e-04 - val_loss: 0.0171\n",
      "Epoch 61/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 3.3933e-04 - val_loss: 0.0171\n",
      "Epoch 62/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3902e-04 - val_loss: 0.0171\n",
      "Epoch 63/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.3869e-04 - val_loss: 0.0170\n",
      "Epoch 64/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3836e-04 - val_loss: 0.0170\n",
      "Epoch 65/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3802e-04 - val_loss: 0.0170\n",
      "Epoch 66/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 3.3767e-04 - val_loss: 0.0170\n",
      "Epoch 67/300\n",
      "1044/1044 [==============================] - 0s 56us/step - loss: 3.3732e-04 - val_loss: 0.0170\n",
      "Epoch 68/300\n",
      "1044/1044 [==============================] - 0s 61us/step - loss: 3.3697e-04 - val_loss: 0.0170\n",
      "Epoch 69/300\n",
      "1044/1044 [==============================] - 0s 58us/step - loss: 3.3661e-04 - val_loss: 0.0170\n",
      "Epoch 70/300\n",
      "1044/1044 [==============================] - 0s 53us/step - loss: 3.3624e-04 - val_loss: 0.0170\n",
      "Epoch 71/300\n",
      "1044/1044 [==============================] - 0s 53us/step - loss: 3.3588e-04 - val_loss: 0.0169\n",
      "Epoch 72/300\n",
      "1044/1044 [==============================] - 0s 60us/step - loss: 3.3551e-04 - val_loss: 0.0169\n",
      "Epoch 73/300\n",
      "1044/1044 [==============================] - 0s 59us/step - loss: 3.3514e-04 - val_loss: 0.0169\n",
      "Epoch 74/300\n",
      "1044/1044 [==============================] - 0s 64us/step - loss: 3.3477e-04 - val_loss: 0.0169\n",
      "Epoch 75/300\n",
      "1044/1044 [==============================] - 0s 48us/step - loss: 3.3439e-04 - val_loss: 0.0169\n",
      "Epoch 76/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 3.3402e-04 - val_loss: 0.0169\n",
      "Epoch 77/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3364e-04 - val_loss: 0.0169\n",
      "Epoch 78/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3327e-04 - val_loss: 0.0169\n",
      "Epoch 79/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3289e-04 - val_loss: 0.0169\n",
      "Epoch 80/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.3252e-04 - val_loss: 0.0169\n",
      "Epoch 81/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3214e-04 - val_loss: 0.0169\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3177e-04 - val_loss: 0.0168\n",
      "Epoch 83/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.3139e-04 - val_loss: 0.0168\n",
      "Epoch 84/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3102e-04 - val_loss: 0.0168\n",
      "Epoch 85/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.3065e-04 - val_loss: 0.0168\n",
      "Epoch 86/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.3028e-04 - val_loss: 0.0168\n",
      "Epoch 87/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2991e-04 - val_loss: 0.0168\n",
      "Epoch 88/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2954e-04 - val_loss: 0.0168\n",
      "Epoch 89/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.2917e-04 - val_loss: 0.0168\n",
      "Epoch 90/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2881e-04 - val_loss: 0.0168\n",
      "Epoch 91/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2844e-04 - val_loss: 0.0168\n",
      "Epoch 92/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2808e-04 - val_loss: 0.0168\n",
      "Epoch 93/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2772e-04 - val_loss: 0.0168\n",
      "Epoch 94/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 3.2737e-04 - val_loss: 0.0168\n",
      "Epoch 95/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.2701e-04 - val_loss: 0.0168\n",
      "Epoch 96/300\n",
      "1044/1044 [==============================] - 0s 33us/step - loss: 3.2666e-04 - val_loss: 0.0168\n",
      "Epoch 97/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2630e-04 - val_loss: 0.0168\n",
      "Epoch 98/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 3.2595e-04 - val_loss: 0.0168\n",
      "Epoch 99/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.2561e-04 - val_loss: 0.0168\n",
      "Epoch 100/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2526e-04 - val_loss: 0.0168\n",
      "Epoch 101/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2492e-04 - val_loss: 0.0168\n",
      "Epoch 102/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2458e-04 - val_loss: 0.0167\n",
      "Epoch 103/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2424e-04 - val_loss: 0.0167\n",
      "Epoch 104/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2390e-04 - val_loss: 0.0167\n",
      "Epoch 105/300\n",
      "1044/1044 [==============================] - 0s 32us/step - loss: 3.2357e-04 - val_loss: 0.0167\n",
      "Epoch 106/300\n",
      "1044/1044 [==============================] - 0s 38us/step - loss: 3.2323e-04 - val_loss: 0.0167\n",
      "Epoch 107/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2290e-04 - val_loss: 0.0167\n",
      "Epoch 108/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2258e-04 - val_loss: 0.0167\n",
      "Epoch 109/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.2225e-04 - val_loss: 0.0167\n",
      "Epoch 110/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.2193e-04 - val_loss: 0.0167\n",
      "Epoch 111/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2160e-04 - val_loss: 0.0167\n",
      "Epoch 112/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.2128e-04 - val_loss: 0.0167\n",
      "Epoch 113/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.2097e-04 - val_loss: 0.0167\n",
      "Epoch 114/300\n",
      "1044/1044 [==============================] - 0s 46us/step - loss: 3.2065e-04 - val_loss: 0.0167\n",
      "Epoch 115/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.2034e-04 - val_loss: 0.0167\n",
      "Epoch 116/300\n",
      "1044/1044 [==============================] - 0s 61us/step - loss: 3.2003e-04 - val_loss: 0.0167\n",
      "Epoch 117/300\n",
      "1044/1044 [==============================] - 0s 50us/step - loss: 3.1972e-04 - val_loss: 0.0167\n",
      "Epoch 118/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.1941e-04 - val_loss: 0.0167\n",
      "Epoch 119/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.1910e-04 - val_loss: 0.0167\n",
      "Epoch 120/300\n",
      "1044/1044 [==============================] - 0s 44us/step - loss: 3.1880e-04 - val_loss: 0.0167\n",
      "Epoch 121/300\n",
      "1044/1044 [==============================] - 0s 39us/step - loss: 3.1850e-04 - val_loss: 0.0167\n",
      "Epoch 122/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.1820e-04 - val_loss: 0.0167\n",
      "Epoch 123/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.1790e-04 - val_loss: 0.0167\n",
      "Epoch 124/300\n",
      "1044/1044 [==============================] - 0s 36us/step - loss: 3.1761e-04 - val_loss: 0.0167\n",
      "Epoch 125/300\n",
      "1044/1044 [==============================] - 0s 42us/step - loss: 3.1731e-04 - val_loss: 0.0167\n",
      "Epoch 126/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.1702e-04 - val_loss: 0.0167\n",
      "Epoch 127/300\n",
      "1044/1044 [==============================] - 0s 34us/step - loss: 3.1673e-04 - val_loss: 0.0167\n",
      "Epoch 128/300\n",
      "1044/1044 [==============================] - 0s 37us/step - loss: 3.1644e-04 - val_loss: 0.0167\n",
      "Epoch 129/300\n",
      "1044/1044 [==============================] - 0s 35us/step - loss: 3.1615e-04 - val_loss: 0.0167\n",
      "Epoch 00129: early stopping\n",
      "Entrenamiento f3 completo.\n",
      "[[971.5592 ]\n",
      " [915.5777 ]\n",
      " [895.3329 ]\n",
      " [857.868  ]\n",
      " [859.38324]\n",
      " [836.5889 ]\n",
      " [848.28534]\n",
      " [834.1835 ]\n",
      " [787.87085]\n",
      " [684.33545]\n",
      " [722.1347 ]\n",
      " [658.2569 ]\n",
      " [632.571  ]\n",
      " [626.7421 ]\n",
      " [573.1645 ]\n",
      " [561.1567 ]\n",
      " [565.7023 ]\n",
      " [566.1028 ]\n",
      " [679.8121 ]\n",
      " [628.7354 ]\n",
      " [648.3138 ]\n",
      " [578.6212 ]\n",
      " [599.70197]\n",
      " [569.3593 ]\n",
      " [591.8013 ]\n",
      " [614.50256]\n",
      " [609.623  ]\n",
      " [599.4321 ]\n",
      " [647.2522 ]\n",
      " [698.32434]]\n",
      "30\n",
      "Simulación f3 completa.\n",
      "            Close bitcoin-cash          f1          f2          f3\n",
      "Date                                                              \n",
      "2015-01-01                0.00         NaN         NaN         NaN\n",
      "2015-01-02                0.00         NaN         NaN         NaN\n",
      "2015-01-03                0.00         NaN         NaN         NaN\n",
      "2015-01-04                0.00         NaN         NaN         NaN\n",
      "2015-01-05                0.00         NaN         NaN         NaN\n",
      "2015-01-06                0.00         NaN         NaN         NaN\n",
      "2015-01-07                0.00         NaN         NaN         NaN\n",
      "2015-01-08                0.00         NaN         NaN         NaN\n",
      "2015-01-09                0.00         NaN         NaN         NaN\n",
      "2015-01-10                0.00         NaN         NaN         NaN\n",
      "2015-01-11                0.00         NaN         NaN         NaN\n",
      "2015-01-12                0.00         NaN         NaN         NaN\n",
      "2015-01-13                0.00         NaN         NaN         NaN\n",
      "2015-01-14                0.00         NaN         NaN         NaN\n",
      "2015-01-15                0.00         NaN         NaN         NaN\n",
      "2015-01-16                0.00         NaN         NaN         NaN\n",
      "2015-01-17                0.00         NaN         NaN         NaN\n",
      "2015-01-18                0.00         NaN         NaN         NaN\n",
      "2015-01-19                0.00         NaN         NaN         NaN\n",
      "2015-01-20                0.00         NaN         NaN         NaN\n",
      "2015-01-21                0.00         NaN         NaN         NaN\n",
      "2015-01-22                0.00         NaN         NaN         NaN\n",
      "2015-01-23                0.00         NaN         NaN         NaN\n",
      "2015-01-24                0.00         NaN         NaN         NaN\n",
      "2015-01-25                0.00         NaN         NaN         NaN\n",
      "2015-01-26                0.00         NaN         NaN         NaN\n",
      "2015-01-27                0.00         NaN         NaN         NaN\n",
      "2015-01-28                0.00         NaN         NaN         NaN\n",
      "2015-01-29                0.00         NaN         NaN         NaN\n",
      "2015-01-30                0.00         NaN         NaN         NaN\n",
      "...                        ...         ...         ...         ...\n",
      "2018-08-02              734.76  898.482788  708.824585  971.559204\n",
      "2018-08-03              724.71  860.120056  691.065918  915.577698\n",
      "2018-08-04              695.74  860.815979  652.196655  895.332886\n",
      "2018-08-05              709.22  834.496582  643.756897  857.867981\n",
      "2018-08-06              692.63  848.160217  621.112854  859.383240\n",
      "2018-08-07              659.38  836.888794  633.746521  836.588928\n",
      "2018-08-08              585.45  788.858154  614.651428  848.285339\n",
      "2018-08-09              610.78  679.924561  581.214905  834.183472\n",
      "2018-08-10              572.44  717.189331  507.501465  787.870850\n",
      "2018-08-11              566.77  652.971252  541.506775  684.335449\n",
      "2018-08-12              570.96  627.691345  493.645386  722.134705\n",
      "2018-08-13              535.98  623.669128  480.554993  658.256897\n",
      "2018-08-14              509.31  568.471313  477.365723  632.570984\n",
      "2018-08-15              513.67  554.056030  435.428131  626.742126\n",
      "2018-08-16              517.35  559.986084  417.063416  573.164490\n",
      "2018-08-17              597.01  559.249573  420.236938  561.156677\n",
      "2018-08-18              554.92  674.339722  427.103119  565.702271\n",
      "2018-08-19              569.93  619.535706  510.612732  566.102783\n",
      "2018-08-20              515.66  639.921143  469.111725  679.812073\n",
      "2018-08-21              536.57  567.898560  482.147217  628.735413\n",
      "2018-08-22              519.95  590.472595  426.671631  648.313782\n",
      "2018-08-23              530.77  561.986145  445.667938  578.621216\n",
      "2018-08-24              535.40  583.211060  422.130890  599.701965\n",
      "2018-08-25              537.24  603.293335  436.580170  569.359314\n",
      "2018-08-26              522.88  600.241272  452.584778  591.801270\n",
      "2018-08-27              546.36  587.533875  448.880890  614.502563\n",
      "2018-08-28              565.31  636.432922  439.522278  609.622986\n",
      "2018-08-29              554.37  686.743164  471.848480  599.432129\n",
      "2018-08-30              540.02  693.365112  499.771790  647.252197\n",
      "2018-08-31              543.08  680.161865  491.942413  698.324341\n",
      "\n",
      "[1339 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs guardados: script/bitcoin-cash/post/Predicciones entrenamiento rmses.csv\n",
      "Epochs guardados: script/bitcoin-cash/post/Predicciones entrenamiento rmses.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bitcoin': {'RMSE': 500.1889991028144, 'MinimoPrecio': 5474.89892578125, 'MaximoPrecio': 6584.5166015625, 'Performance': -539.033447265625, 'Volatilidad': 515.8030488996876, 'VolatilidadRelativa': 92.96950835548388, 'RMSEHW': 2687.4866430026236}, 'ethereum': {'RMSE': 28.834454912999934, 'MinimoPrecio': 245.43917846679688, 'MaximoPrecio': 300.52642822265625, 'Performance': -27.543624877929688, 'Volatilidad': 22.505054298867254, 'VolatilidadRelativa': 81.70694452384963, 'RMSEHW': 148.79856371127138}, 'ripple': {'RMSE': 0.055534688732142394, 'MinimoPrecio': 0.28514406085014343, 'MaximoPrecio': 0.32998883724212646, 'Performance': 0.019141942262649536, 'Volatilidad': 0.01977584128307318, 'VolatilidadRelativa': 88.19685534928226, 'RMSEHW': 0.17455419502911665}, 'bitcoin-cash': {'RMSE': 108.9210885491567, 'MinimoPrecio': 482.56268310546875, 'MaximoPrecio': 713.5812377929688, 'Performance': 6.070953369140625, 'Volatilidad': 106.15710868887197, 'VolatilidadRelativa': 91.90353461649109, 'RMSEHW': 384.0123260340302}, 'General': {'MaxPerformance': {'Moneda': 'bitcoin-cash', 'Performance': 6.070953369140625}, 'MinPerformance': {'Moneda': 'bitcoin', 'Performance': -539.033447265625}, 'MaxVolatilidad': {'Moneda': 'bitcoin', 'Volatilidad': 515.8030488996876}, 'MinVolatilidad': {'Moneda': 'ripple', 'Volatilidad': 0.01977584128307318}}}\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt # Plots\n",
    "import matplotlib.gridspec as gridspec\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers.core import Dense,Activation,Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "#Manejo de archivos\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import json\n",
    "\n",
    "import DataManager as dm\n",
    "\n",
    "colores_test = ['r','g','b','c']\n",
    "colores_futuro = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "criptomonedas_correlacionadas = ['eos', 'qtum', 'omisego', 'zcash']  \n",
    "\n",
    "# Conf\n",
    "test_size = 30\n",
    "colores = ['r','g','b','c']\n",
    "\n",
    "# Convertir el conjunto de datos como dos conjuntos x e y\n",
    "def create_dataset(dataset,col_target,f):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-f):  \n",
    "        dataX.append(dataset[i,:])  #precio (BHC,ETH,LCT,XRP,...)\n",
    "        dataY.append(dataset[i+f,col_target])  #precio BTC del dia futuro f\n",
    "    return np.asarray(dataX), np.asarray(dataY)\n",
    "\n",
    "# Convertir el conjunto de datos como dos conjuntos x e y, donde x no contiene al target\n",
    "def create_dataset_sintarget(dataset,col_target,f):\n",
    "    dataX, dataY = [], []\n",
    "    dataset_sintarget = np.delete(dataset, col_target, 1)\n",
    "    for i in range(len(dataset)-f):  \n",
    "        dataX.append(dataset_sintarget[i,:])  #precio (BHC,ETH,LCT,XRP,...)\n",
    "        dataY.append(dataset[i+f,col_target])  #precio BTC del dia futuro f\n",
    "    return np.asarray(dataX), np.asarray(dataY)\n",
    "\n",
    "def create_batches(dataset,targets,v):\n",
    "    b = []\n",
    "    t = []\n",
    "    for i in range(len(dataset)-v):\n",
    "        batch = dataset[i:i+v+1]\n",
    "        b.append(batch)\n",
    "        t.append(targets[i+v])\n",
    "    return np.asarray(b),np.asarray(t)\n",
    "\n",
    "# Método para entrenar la red\n",
    "def entrenamiento(dataset, maxf, target):\n",
    "    prediccion = dataset[[target]][-test_size:].copy()\n",
    "    v = 0  \n",
    "    predicciones_f = [0 for f in range(0,maxf-1)] # Arreglo con las maxf predicciones, una por cada iteracion\n",
    "    \n",
    "    for f in range(1,maxf):\n",
    "        # Separar el datset en x e y (predicción para el día f)\n",
    "        x,y = create_dataset(np.asarray(dataset),dataset.columns.get_loc(target),f)\n",
    "        y = y.reshape(-1,1)\n",
    "\n",
    "        # Separar x,y en conjuntos de entrenamiento y testeo (test_size+v para poder hacer ventanas de timesteps después de escalar y que siempre queden 30 puntos de predicción en test)\n",
    "        train_x, train_y = x[:-test_size], y[:-test_size]\n",
    "        test_x, test_y = x[-test_size-v:], y[-test_size-v:]\n",
    "\n",
    "        # Normalización: Escalar los datos entre [0,1]. Hay que escalar con respecto al training set, como si el test set no estuviera.\n",
    "        scalerX = preprocessing.MinMaxScaler(feature_range = (0,1)).fit(train_x)\n",
    "        train_x_scaled = scalerX.transform(train_x)\n",
    "        test_x_scaled = scalerX.transform(test_x)\n",
    "        scalerY = preprocessing.MinMaxScaler(feature_range = (0,1)).fit(train_y)\n",
    "        train_y_scaled = scalerY.transform(train_y)\n",
    "        test_y_scaled = scalerY.transform(test_y)  \n",
    "\n",
    "        # Crear batches de v timesteps (ventana)\n",
    "        input_train,target_train = create_batches(train_x_scaled,train_y_scaled,v)\n",
    "        input_test,target_test = create_batches(test_x_scaled,test_y_scaled,v)\n",
    "\n",
    "        #Construir red neuronal y entrenarla\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 2,\n",
    "                       input_shape=(input_train.shape[1],input_train.shape[2]),\n",
    "                       return_sequences=False, activation = 'tanh'))\n",
    "        model.add(Dense(units = 1, activation = 'linear'))\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        early_stopping_monitor = EarlyStopping(monitor='val_loss',patience=10,verbose=1) # Stop loss después de *patience* epochs consecutivos sin mejora\n",
    "        history = model.fit(input_train, target_train, validation_split=0.2,\n",
    "                            batch_size=128, epochs = 300, callbacks=[early_stopping_monitor],\n",
    "                            shuffle=False,verbose=1)  \n",
    "\n",
    "        # Dataframe de entrenamiento\n",
    "        training_history = pd.DataFrame() \n",
    "        training_history = pd.concat([training_history, pd.DataFrame(data=history.history['loss'], columns=['f' + str(f) +'_loss'])], axis=1)\n",
    "        training_history = pd.concat([training_history, pd.DataFrame(data=history.history['val_loss'], columns=['f' + str(f) + '_val_loss'])], axis=1)\n",
    "        training_history.to_csv(datasetfolder + '/entrenamiento ' + 'f' + str(f) + '.csv')\n",
    "        print('Entrenamiento ' + 'f' + str(f) + ' completo.')\n",
    "        #entrenamientos.append(training_history)   \n",
    "\n",
    "        #Predicción de testeo\n",
    "        predicted_scaled = model.predict(input_test)\n",
    "        predicted_scaled = predicted_scaled.reshape(-1,1)\n",
    "        predicted = scalerY.inverse_transform(predicted_scaled)\n",
    "        \n",
    "        print(predicted)\n",
    "        print(len(predicted))\n",
    "\n",
    "        # Dataframe de prediccion del subset  \n",
    "        prediccion['f' + str(f)] = predicted\n",
    "        print(\"Simulación \"+ 'f' + str(f) +\" completa.\")        \n",
    "        \n",
    "        # HACER LA PREDICCION PARA EL DIA F\n",
    "        x = np.asarray(dataset[-1:])  \n",
    "        x = scalerX.transform(x)\n",
    "        input_test,target_test = create_batches(x,x,0)\n",
    "        prediccionf = model.predict(input_test)\n",
    "        prediccionf = prediccionf.reshape(-1,1)\n",
    "        prediccionf = scalerY.inverse_transform(prediccionf)\n",
    "        predicciones_f[f-1] = prediccionf.flatten()[0]\n",
    "        \n",
    "    # Agregar la predicción al dataframe del dataset\n",
    "    prediccion = pd.merge(dataset[[target]],prediccion.drop(columns=[target]),how=\"left\",left_index=True,right_index=True)            \n",
    "    print(prediccion)\n",
    "    prediccion.to_csv(datasetfolder + '/' + 'resultados.csv')\n",
    "    \n",
    "    # Construir dataframe con la prediccion a f dias a futuro\n",
    "    predicciones_f_dataframe = pd.DataFrame(pd.date_range(start=dataset.index[-1], periods=maxf, freq='D', closed='right'),columns=['Date'])\n",
    "    predicciones_f_dataframe['Prediccion'] = predicciones_f\n",
    "        \n",
    "    # Crear dataframe con precio real + prediccion (con NULLs). Este es el json que va a Angular\n",
    "    dfFinal = pd.merge(prediccion[[target]], predicciones_f_dataframe, how=\"outer\",left_index=True,right_index=True)\n",
    "    \n",
    "    # Holt-Winters lineal (conjunto de entrenamiento fijo)\n",
    "    ciclos = 45; alfa = 0.1; beta = 0.1\n",
    "    prediccionesHW = pd.DataFrame()\n",
    "    datasetHW = dataset[[target]].copy()\n",
    "    testHW = datasetHW[-test_size:]\n",
    "    # Entrenar y obtener RMSE del entrenamiento\n",
    "    testHW['holtwinters'] = np.nan\n",
    "    trainingHW = datasetHW[0:-test_size]\n",
    "    hw_lineal = ExponentialSmoothing(np.asarray(trainingHW), seasonal_periods=ciclos, trend='add', seasonal='add').fit(smoothing_level = alfa,smoothing_slope = beta)\n",
    "    testHW['holtwinters'] = hw_lineal.forecast(test_size)\n",
    "    testHW['holtwinters'] = testHW['holtwinters'] .interpolate().ffill().fillna(0)\n",
    "    prediccionesHW = prediccionesHW.append(testHW)\n",
    "    prediccionesHW = pd.merge(dataset.copy()[[target]],prediccionesHW.drop(columns=[target]), how=\"left\",left_index=True,right_index=True)\n",
    "    subset_moneda = prediccionesHW[[target]][-test_size:]\n",
    "    subset_holtwinters = prediccionesHW[['holtwinters']][-test_size:]              \n",
    "    #RMSE\n",
    "    rmseHW = sqrt(mean_squared_error(subset_moneda, subset_holtwinters))\n",
    "\n",
    "    # Realizar la predicción a maxF días\n",
    "    trainingHW = dataset[[target]].copy()\n",
    "    hw_lineal = ExponentialSmoothing(np.asarray(trainingHW), seasonal_periods=ciclos, trend='add', seasonal='add').fit(smoothing_level = alfa,smoothing_slope = beta)\n",
    "    holtwinters = hw_lineal.forecast(maxf-1)\n",
    "\n",
    "    # Agregar holwinters al dataframe con la prediccion a f dias a futuro\n",
    "    predicciones_f_dataframe['holtwinters'] = holtwinters   \n",
    "    \n",
    "    predicciones_f_dataframe['Date'] = pd.to_datetime(predicciones_f_dataframe['Date'])\n",
    "    predicciones_f_dataframe.set_index('Date', inplace=True)\n",
    "    predicciones_f_dataframe.to_csv(datasetfolder + '/' + 'predicciones_f.csv')\n",
    "    predicciones_f_dataframe.to_json(datasetfolder + '/predicciones_f.json',orient=\"split\")\n",
    "    \n",
    "    # Crear dataframe con precio real + prediccion (con NULLs). Este es el json que va a Angular\n",
    "    dfFinal = pd.merge(data[[target]], predicciones_f_dataframe, how=\"outer\",left_index=True,right_index=True)\n",
    "    dfFinal.to_csv(datasetfolder + '/' + 'toAngular.csv')\n",
    "    dfFinal.to_json(datasetfolder + '/toAngular.json',orient=\"split\")\n",
    "    \n",
    "    return (prediccion, predicciones_f_dataframe, dfFinal, rmseHW)\n",
    "\n",
    "\n",
    "# Construir dataframes con RMSE y epochs por test\n",
    "def postprocesamiento(prediccion, name, name_parametro, referencia = []):\n",
    "    rmse_completo_y = []\n",
    "    rmse_completo_x = []\n",
    "    arreglo_nepochs = []\n",
    "    for simulacion_i in prediccion.columns[1:]:\n",
    "                    dataset_name = simulacion_i; i=1\n",
    "                    prediccionxdataset = pd.DataFrame()\n",
    "                    arreglo_nepochs_simulacion_i = [simulacion_i]\n",
    "                    subset = prediccion\n",
    "                    subset_moneda = subset[subset.columns[0]]\n",
    "                    subset_prediccion = subset[[simulacion_i]][-test_size:]               \n",
    "                                                \n",
    "                    #Cada entrenamiento                        \n",
    "                    entrenamiento = pd.read_csv(datasetfolder + '/entrenamiento ' + dataset_name + '.csv',index_col =0)\n",
    "                    arreglo_nepochs_simulacion_i.append(entrenamiento.shape[0]) # Obtener cantidad de epochs\n",
    "                                              \n",
    "                    #RMSE\n",
    "                    rmse = sqrt(mean_squared_error(subset_moneda[-test_size:], subset_prediccion))\n",
    "                    rmse_completo_y.append(rmse)\n",
    "                    rmse_completo_x.append(simulacion_i)\n",
    "                    \n",
    "                    arreglo_nepochs.append(arreglo_nepochs_simulacion_i) #Agregar la cantidad de epochs para la simulacion i\n",
    "                    \n",
    "                    i+=1\n",
    "                    \n",
    "    # Construir un csv con todos los RMSE\n",
    "    arreglo_rmse = []; i=0\n",
    "    for simulacion_i in prediccion.columns[1:]:\n",
    "        arreglo_rmse.append([simulacion_i] + [rmse_completo_y[i]]); i+=1\n",
    "    dataframe_rmse = pd.DataFrame(arreglo_rmse, columns=['Simulacion','RMSE'])\n",
    "    dataframe_rmse.set_index('Simulacion',inplace=True)\n",
    "    dataframe_rmse.to_csv(datasetfolder + '/post/' + name + ' rmses.csv')\n",
    "    dataframe_rmse.to_json(datasetfolder + '/post/' + name + ' rmses.json',orient=\"columns\")\n",
    "    print('RMSEs guardados: ' + datasetfolder + '/post/' + name + ' rmses.csv')\n",
    "    \n",
    "    # Construir un csv con los epochs \n",
    "    dataframe_epochs = pd.DataFrame(arreglo_nepochs, columns=['Simulacion','Epochs'])\n",
    "    dataframe_epochs.set_index('Simulacion',inplace=True)\n",
    "    dataframe_epochs.to_csv(datasetfolder + '/post/' + name + ' epochs.csv')\n",
    "    print('Epochs guardados: ' + datasetfolder + '/post/' + name + ' rmses.csv')\n",
    "        \n",
    "    # Graficar RMSE en barras\n",
    "    width = 1/1.5\n",
    "    plt.figure(figsize=(25,8))\n",
    "    barplot = plt.bar(rmse_completo_x, rmse_completo_y, width)\n",
    "    col = 0;\n",
    "    for rect in barplot: # Valores en las barras\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2.0, height, '% 6.2f' % height,fontsize=22, ha='center',va='bottom',rotation=90)\n",
    "        rect.set_color(colores_test[col])\n",
    "        col = (col+1)%4\n",
    "    plt.xticks(rotation=60, ha=\"right\")\n",
    "    plt.ylim(ymax=max(rmse_completo_y)*1.2)\n",
    "    plt.ylabel('Error', fontsize=18)\n",
    "    plt.title(\"RMSE\", fontsize=22)\n",
    "    plt.savefig(datasetfolder + '/post/' + name + ' RMSE barra.png', bbox_inches='tight')  \n",
    "    \n",
    "    #Graficar RMSE por variación del parámetro\n",
    "    plt.figure(figsize=(20,8)); col = 0\n",
    "    for i in range(0,len(dataframe_rmse.columns)):\n",
    "        plt.plot(dataframe_rmse.index, dataframe_rmse[dataframe_rmse.columns[i]], label=dataframe_rmse.columns[i], color=colores_test[col]);  col = (col+1)%4\n",
    "    for r in referencia:\n",
    "        plt.axhline(r,linestyle='--', color=colores_test[col], alpha=0.6); col=(col+1)%4\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.ylabel('Error', fontsize=18)\n",
    "    plt.title(\"RMSE vs. \" + name_parametro,fontsize=20)\n",
    "    plt.savefig(datasetfolder + '/post/' + name + ' RMSE lineal.png', bbox_inches='tight') \n",
    "    plt.show()\n",
    "    \n",
    "    #Graficar EPOCHS por variación del parámetro\n",
    "    plt.figure(figsize=(20,8)); col = 0\n",
    "    for i in range(0,len(dataframe_epochs.columns)):\n",
    "        plt.plot(dataframe_epochs.index, dataframe_epochs[dataframe_epochs.columns[i]], label=dataframe_epochs.columns[i], color=colores_test[col]);  col = (col+1)%3\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.ylabel('Epochs', fontsize=18)\n",
    "    plt.title(\"Epochs vs. \" + name_parametro,fontsize=20)\n",
    "    plt.savefig(datasetfolder + '/post/' + name + ' epochs lineal.png', bbox_inches='tight') \n",
    "    plt.show()  \n",
    "    \n",
    "    return (dataframe_rmse,dataframe_epochs)\n",
    "\n",
    "# Graficar la simulacion i para la prediccion \n",
    "def graficarSimulacion(prediccion, dataframe_rmse, dataframe_epochs, name, name_parametro):\n",
    "        for dataset_name in prediccion.columns[1:]:       \n",
    "                    #Visualización de resultados\n",
    "                    fig = plt.figure(figsize=(25,10*2))\n",
    "                    gs = gridspec.GridSpec(2, 5, wspace=0.3, hspace=0.4)\n",
    "                    i = 1\n",
    "\n",
    "                    #Todas los subsets para un dataset\n",
    "                    axPrediccionCompleta = plt.subplot(gs[0, 0:])\n",
    "                    axPrediccionCompleta.plot(prediccion.index, prediccion[prediccion.columns[0]], color='dimgray', label=\"Precio Real\")  \n",
    "                    axPrediccionCompleta.set_ylabel('Precio (USD)', fontsize=18)\n",
    "                    plt.xticks(rotation=30, ha=\"right\")\n",
    "                    axPrediccionCompleta.set_title(\"Predicciones \" + dataset_name,fontsize=22)\n",
    "                    axPrediccionCompleta.grid(color='grey', linestyle='-', linewidth=0.5) \n",
    "                    rmse_general = dataframe_rmse.loc[dataset_name, 'RMSE'] # Obtener el RMSE para la prediccion\n",
    "                    axPrediccionCompleta.text(0.05, 0.1, 'RMSE ' + str('% 6.2f' % rmse_general), \n",
    "                                            horizontalalignment='left',verticalalignment='center', \n",
    "                                            transform=axPrediccionCompleta.transAxes, fontsize=17, bbox=dict(facecolor='red', alpha=0.5))\n",
    "                  \n",
    "                    n_test = 0\n",
    "                    prediccionxdataset = pd.DataFrame()\n",
    "                    subset = prediccion\n",
    "                    subset_moneda = subset[subset.columns[0]]\n",
    "                    subset_prediccion = subset[[dataset_name]][-test_size:]\n",
    "                    prediccionxdataset = prediccionxdataset.append(\n",
    "                            pd.concat([subset_moneda[-test_size:], subset_prediccion], axis=1))\n",
    "                        \n",
    "                    #Graficar la serie completa\n",
    "                    axPrediccionCompleta.plot(subset_prediccion.index, subset_prediccion, color=colores_test[n_test], label='Prediccion (' + str(n_test+1) + ')')\n",
    "                    axPrediccionCompleta.axvspan(subset_prediccion.index[0], subset_prediccion.index[-1], facecolor=colores_test[n_test], alpha=0.1)  \n",
    "                    axPrediccionCompleta.legend(loc='upper left')                        \n",
    "                                                \n",
    "                    #Cada entrenamiento                        \n",
    "                    entrenamiento = pd.read_csv(datasetfolder + '/entrenamiento ' + dataset_name + '.csv',index_col =0)\n",
    "                    axTraining = plt.subplot(gs[i, 0])\n",
    "                    axTraining.plot(entrenamiento[entrenamiento.columns[0]], label='loss')\n",
    "                    axTraining.plot(entrenamiento[entrenamiento.columns[1]], label='val_loss')\n",
    "                    axTraining.set_xlabel('Epochs', fontsize=18)\n",
    "                    axTraining.set_ylabel('Loss', fontsize=18)\n",
    "                    axTraining.legend(loc='upper right')\n",
    "                    axTraining.set_title(\"Entrenamiento\", fontsize=22)\n",
    "                                              \n",
    "                    #Cada prediccion   \n",
    "                    axPrediccion = plt.subplot(gs[i, 1:])\n",
    "                    axPrediccion.plot(subset_moneda.index[-45:], subset_moneda[-45:], color='dimgray', label=\"Precio Real\")\n",
    "                    axPrediccion.plot(subset_prediccion.index, subset_prediccion, color=colores_test[n_test],  label='Prediccion ' + dataset_name)\n",
    "                    axPrediccion.axvspan(subset_prediccion.index[0], subset_prediccion.index[-1], facecolor=colores_test[n_test], alpha=0.1)\n",
    "                    axPrediccion.set_ylabel('Precio (USD)', fontsize=18)\n",
    "                    plt.xticks(rotation=30, ha=\"right\")\n",
    "                    axPrediccion.legend(loc='upper left')\n",
    "                    axPrediccion.set_title(\"Predicciones\",fontsize=22)\n",
    "                    axPrediccion.grid(color='grey', linestyle='-', linewidth=0.5)                         \n",
    "                    rmse_i = dataframe_rmse.loc[dataset_name, 'RMSE'] # Obtener el RMSE para la prediccion\n",
    "                    axPrediccion.text(0.05, 0.1, 'RMSE ' + str('% 6.2f' % rmse_i), \n",
    "                                            horizontalalignment='left',verticalalignment='center', \n",
    "                                            transform=axPrediccion.transAxes, fontsize=17, bbox=dict(facecolor='red', alpha=0.5))\n",
    "                    i+=1\n",
    "                    \n",
    "                    plt.savefig(datasetfolder + '/post/' + name + ' Curvas ' + dataset_name + '.png', bbox_inches='tight') \n",
    "\n",
    "target_list = ['bitcoin', 'ethereum', 'ripple', 'bitcoin-cash']\n",
    "PrediccionMeta = {}\n",
    "for target in target_list:\n",
    "    # Crear carpeta donde se almacenarán las predicciones  \n",
    "    datasetfolder = \"script\" + \"/\"  + target\n",
    "    if not os.path.exists(datasetfolder):\n",
    "        os.makedirs(datasetfolder) # Crear carpeta de predicciones\n",
    "    postfolder = datasetfolder + '/post'\n",
    "    if not os.path.exists(postfolder):\n",
    "        os.makedirs(postfolder) # Crear carpeta de postprocesamiento\n",
    "\n",
    "    if True:\n",
    "        targets_crypto = [target] + criptomonedas_correlacionadas\n",
    "        data = dm.get_crypto(targets_crypto,fecha_comienzo='2015-01-01',fecha_fin='2018-08-31')\n",
    "        data = data.interpolate().ffill().fillna(0) #Completar campos faltantes\n",
    "        data.to_csv(datasetfolder + '/data ' + target +'.csv')\n",
    "\n",
    "    data = pd.read_csv(datasetfolder + '/data ' + target + '.csv', usecols=['Date', 'Close ' + target, 'Close eos', 'Close qtum', 'Close omisego', 'Close zcash'])\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "    data[['Close ' + target]].to_json(datasetfolder + '/data '+ target +'.json',orient=\"split\")\n",
    "\n",
    "    #Graficar la serie completa\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for i in range(0,len(data.columns)):\n",
    "        plt.plot(data.index, data[data.columns[i]], label=data.columns[i])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"Datos\",fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    # ENTRENAR Y OBTENER PREDICCIONES\n",
    "    prediccion_entrenamiento, predicciones_f, dfFinal, rmseHW = entrenamiento(data.copy(), 4, 'Close ' + target)\n",
    "\n",
    "    dataframe_rmse, dataframe_epochs = postprocesamiento(prediccion_entrenamiento,  name='Predicciones entrenamiento', name_parametro='f')\n",
    "    graficarSimulacion(prediccion_entrenamiento, dataframe_rmse, dataframe_epochs, name='Predicciones entrenamiento', name_parametro='f')\n",
    "\n",
    "    # Guardar datos sobre la prediccionF para los gráficos \n",
    "    minP = predicciones_f[['Prediccion']].values.min()\n",
    "    maxP = predicciones_f[['Prediccion']].values.max()\n",
    "    # Calcular la performance: pendiente de la regresion lineal sobre la curva de prediccion.\n",
    "    xi = np.arange(0,len(predicciones_f.index))\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(xi,predicciones_f[['Prediccion']].values.flatten())\n",
    "    line = slope*xi+intercept\n",
    "    # Calcular la volatilidad de la prediccion: deviación estándar de la curva.\n",
    "    volatilidad = np.std(predicciones_f[['Prediccion']].values)\n",
    "\n",
    "    targetMeta = {\n",
    "        'RMSE': dataframe_rmse.values.flatten()[0],\n",
    "        'MinimoPrecio': minP,\n",
    "        'MaximoPrecio': maxP,\n",
    "        'Performance': slope,\n",
    "        'Volatilidad':volatilidad,\n",
    "        'VolatilidadRelativa': 100*volatilidad/abs((maxP-minP)/2),\n",
    "        'RMSEHW': rmseHW\n",
    "    }\n",
    "    PrediccionMeta[target] = targetMeta\n",
    "    \n",
    "# Agregar información general al archivo meta    \n",
    "MaxPerformanceMoneda = MinPerformanceMoneda = MaxVolatilidadMoneda = MinVolatilidadMoneda = target_list[0]\n",
    "MaxPerformance = PrediccionMeta[target_list[0]]['Performance']\n",
    "MinPerformance = PrediccionMeta[target_list[0]]['Performance']\n",
    "MaxVolatilidad = PrediccionMeta[target_list[0]]['Volatilidad']\n",
    "MinVolatilidad = PrediccionMeta[target_list[0]]['Volatilidad']\n",
    "\n",
    "for p in PrediccionMeta:\n",
    "    if(PrediccionMeta[p]['Performance'] > MaxPerformance):\n",
    "        MaxPerformanceMoneda = p\n",
    "        MaxPerformance = PrediccionMeta[p]['Performance']\n",
    "    if(PrediccionMeta[p]['Performance'] < MinPerformance):\n",
    "        MinPerformanceMoneda = p\n",
    "        MinPerformance = PrediccionMeta[p]['Performance']\n",
    "    if(PrediccionMeta[p]['Volatilidad'] > MaxVolatilidad):\n",
    "        MaxVolatilidadMoneda = p\n",
    "        MaxVolatilidad = PrediccionMeta[p]['Volatilidad']\n",
    "    if(PrediccionMeta[p]['Volatilidad'] < MinVolatilidad):\n",
    "        MinVolatilidadMoneda = p\n",
    "        MinVolatilidad = PrediccionMeta[p]['Volatilidad']\n",
    "        \n",
    "PrediccionMeta['General'] = {\n",
    "    'MaxPerformance': {\n",
    "        'Moneda': MaxPerformanceMoneda,\n",
    "        'Performance': MaxPerformance\n",
    "    },\n",
    "    'MinPerformance': {\n",
    "        'Moneda': MinPerformanceMoneda,\n",
    "        'Performance': MinPerformance\n",
    "    },\n",
    "    'MaxVolatilidad': {\n",
    "        'Moneda': MaxVolatilidadMoneda,\n",
    "        'Volatilidad': MaxVolatilidad\n",
    "    },\n",
    "    'MinVolatilidad': {\n",
    "        'Moneda': MinVolatilidadMoneda,\n",
    "        'Volatilidad': MinVolatilidad\n",
    "    }\n",
    "}\n",
    "print(PrediccionMeta)\n",
    "with open(\"script\" + '/PrediccionMeta.json', 'w') as outfile:\n",
    "    json.dump(PrediccionMeta, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
